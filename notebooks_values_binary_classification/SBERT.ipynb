{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c0a524",
   "metadata": {},
   "source": [
    "# Extract embeddings from SBERT and train SVM, LogitBoost, and LogitRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8b606c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf5739",
   "metadata": {},
   "source": [
    "Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32c5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Думаете, что умеете пользоваться фотошопом?...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...Самое страшное - это когда ты стоишь под х...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Друзья мои! Поддержим дочку моей подруги! Про...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Мой новый дневник, читаем, коментим :)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>РУССКИЙ  КРЫМ - МИФ для быдла! (о чем молчат ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0     Думаете, что умеете пользоваться фотошопом?...    0.0\n",
       "1   ...Самое страшное - это когда ты стоишь под х...    1.0\n",
       "2   Друзья мои! Поддержим дочку моей подруги! Про...    1.0\n",
       "3             Мой новый дневник, читаем, коментим :)    0.0\n",
       "4   РУССКИЙ  КРЫМ - МИФ для быдла! (о чем молчат ...    0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fold='../data/data_for_binary_classification/'\n",
    "file_='chatGPT_3_instr0_withEx_temp0_train_all_updated.csv'\n",
    "\n",
    "df=pd.read_csv(fold+file_, sep=\"|\", encoding ='utf-8')[['text', 'final_label']] #'label_crowd', 'gpt_result', \n",
    "df=df.rename(columns={'final_label':'label'})\n",
    "print (df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4d1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3301\n",
       "1    1734\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label = df.label.astype('int')\n",
    "df.label=df.label.replace(3, 0)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d22a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.label.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b1a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.label.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9418eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "import numpy as np\n",
    "\n",
    "def mean_pooling(model_output, attention_mask, norm=True):\n",
    "    token_embeddings = model_output[0]  #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum([1]), min=1e-9)\n",
    "    sums = sum_embeddings / sum_mask\n",
    "    if norm:\n",
    "        sums = torch.nn.functional.normalize(sums)\n",
    "    return sums\n",
    "\n",
    "\n",
    "def embed_bert_pytorch(text, model, tokenizer, emb_type=['cls','mean']):\n",
    "    t = tokenizer(text, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "    t = {k: v.to(model.device) for k, v in t.items()}\n",
    "\n",
    "    with torch.inference_mode():    \n",
    "        model_output = model(**t)\n",
    "    \n",
    "    res_dict = {}\n",
    "   \n",
    "    if 'cls' in emb_type:\n",
    "        e1 = torch.nn.functional.normalize(model_output.last_hidden_state[:, 0, :])\n",
    "        res_dict['cls'] = e1[0].cpu().numpy()\n",
    "\n",
    "    if 'mean' in emb_type:\n",
    "        e2 = mean_pooling(model_output, t['attention_mask'])\n",
    "        res_dict['mean'] = e2[0].cpu().numpy()\n",
    "        \n",
    "        \n",
    "    return res_dict\n",
    "\n",
    "def get_emb(embedder, data):\n",
    "    embs = [embedder(x) for x in tqdm_n(data)] # tqdm\n",
    "    emb = {}\n",
    "    for k in embs[0].keys():\n",
    "        emb[k] = np.stack([row[k] for row in embs])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61fd45f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ede49d72c0c4c84b1b44302ab30b182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5035 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 58min 55s, sys: 52.3 s, total: 3h 59min 47s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embs = get_emb(lambda x: embed_bert_pytorch(x, model, tokenizer), df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "85c1c54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5035, 1024), (5035, 1024))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs['cls'].shape, embs['mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d05fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00929506, -0.01398701,  0.00787013, ..., -0.00742487,\n",
       "         0.02980503,  0.00831383], dtype=float32),\n",
       " array([ 0.00592028, -0.00051701,  0.02079129, ..., -0.00939083,\n",
       "         0.04377579,  0.00758594], dtype=float32))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs['cls'][0], embs['mean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0c8b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cls_train, X_cls_test, y_train, y_test = train_test_split(\n",
    "    embs['cls'], df.label, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "X_mean_train, X_mean_test, _, _ = train_test_split(\n",
    "    embs['mean'], df.label, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b29b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = np.logspace(-5, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "19eecc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 59s, sys: 25min 32s, total: 41min 32s\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_cls  = LogisticRegressionCV(Cs=Cs, max_iter=1_000, n_jobs=1, verbose=0).fit(X_cls_train, y_train)\n",
    "clf_mean = LogisticRegressionCV(Cs=Cs, max_iter=1_000, n_jobs=1, verbose=0).fit(X_mean_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "65ca7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import fbeta_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def get_metrics(y, preds, beta = 5):\n",
    "    round3 = lambda x: round(x*1000)/1000\n",
    "    pre = precision_score(y, preds, zero_division=0)\n",
    "    rec = recall_score(y, preds, zero_division=0)\n",
    "    pro = (1-min(pre,0.9999999999999))/(1-min(rec,0.9999999999999))\n",
    "    pro_loss = math.log(abs(beta - pro)+1)\n",
    "    return {'fbeta':round3(fbeta_score(y, preds, beta=beta, zero_division=0)), \n",
    "            'f1':round3(fbeta_score(y, preds, beta=1, zero_division=0)), \n",
    "            'roc_auc':round3(roc_auc_score(y, preds)), \n",
    "            'precision':round3(pre),\n",
    "            'recall':round3(rec),\n",
    "            'pro': round3(pro),\n",
    "            'pro_loss':pro_loss, \n",
    "            'TP': ((y == 1) & (preds == 1)).sum(),\n",
    "            'TN': ((y == 0) & (preds == 0)).sum(),\n",
    "            'FP': ((y == 0) & (preds == 1)).sum(),\n",
    "            'FN': ((y == 1) & (preds == 0)).sum(),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f507188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6298003072196622"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, clf_cls.predict_proba(X_cls_test)[:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2ad9593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fbeta': 0.636,\n",
       " 'f1': 0.636,\n",
       " 'roc_auc': 0.717,\n",
       " 'precision': 0.658,\n",
       " 'recall': 0.616,\n",
       " 'pro': 0.892,\n",
       " 'pro_loss': 0.10263123063578138,\n",
       " 'TP': 225,\n",
       " 'TN': 525,\n",
       " 'FP': 117,\n",
       " 'FN': 140}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test, clf_cls.predict_proba(X_cls_test)[:,1] > 0.44, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f606a0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fbeta': 0.639,\n",
       " 'f1': 0.639,\n",
       " 'roc_auc': 0.718,\n",
       " 'precision': 0.651,\n",
       " 'recall': 0.627,\n",
       " 'pro': 0.938,\n",
       " 'pro_loss': 0.06032967426580218,\n",
       " 'TP': 229,\n",
       " 'TN': 519,\n",
       " 'FP': 123,\n",
       " 'FN': 136}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test, clf_mean.predict_proba(X_mean_test)[:,1] > 0.434, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0422f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- интересный новый сервис, где можно оставить...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>чет как-то нерадостно все это...особо на фоне...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Repost with . ・・・ жаль что быстро убежала!!!#...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#hellomyearth #дорогажизни #разорванноекольцо</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ВтандемеСМамой#кактампробка#😁</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_test\n",
       "0   - интересный новый сервис, где можно оставить...           1\n",
       "1   чет как-то нерадостно все это...особо на фоне...           0\n",
       "2  #Repost with . ・・・ жаль что быстро убежала!!!#...           0\n",
       "3      #hellomyearth #дорогажизни #разорванноекольцо           0\n",
       "4                     #ВтандемеСМамой#кактампробка#😁           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trial dataset\n",
    "file_test='all_merged_temp0_instr0_withEx_test_final_label.csv'\n",
    "\n",
    "test_data=pd.read_csv(fold+file_test, sep=\"|\", encoding ='utf-8')[['text', 'final_label']]\n",
    "test_data=test_data.rename(columns={'final_label':'label_test'})\n",
    "print (test_data.shape[0])\n",
    "test_data.label_test=test_data.label_test.astype(int)\n",
    "test_data.label_test=test_data.label_test.replace(3, 0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff51e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    532\n",
       "1    272\n",
       "Name: label_test, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.label_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9b1f9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e473e8e6bc004ca09c379c8b1c9cb841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 6s, sys: 11 s, total: 36min 17s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb_test = get_emb(lambda x: embed_bert_pytorch(x, model, tokenizer), test_data.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e988476c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00929506, -0.01398701,  0.00787013, ..., -0.00742487,\n",
       "         0.02980503,  0.00831383],\n",
       "       [-0.04644227, -0.02437294,  0.02493586, ...,  0.04479778,\n",
       "        -0.02900108, -0.00685201],\n",
       "       [-0.05861808, -0.00421491, -0.05079638, ...,  0.00123103,\n",
       "        -0.02409819,  0.03700725],\n",
       "       ...,\n",
       "       [-0.03123325,  0.01808644, -0.02161152, ..., -0.00243144,\n",
       "        -0.00893479, -0.00128236],\n",
       "       [ 0.02588368,  0.0146559 , -0.03030781, ...,  0.00612109,\n",
       "        -0.04469183,  0.02309735],\n",
       "       [-0.00969478, -0.01412101, -0.01880374, ...,  0.01690224,\n",
       "        -0.01349046,  0.00146537]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs['cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6e056f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7574276 , 1.47114682])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75461be",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "941daf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=SVC(class_weight={0: 0.7574276043625423,\n",
       "                                         1: 1.4711468224981739},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [1], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=SVC(class_weight={0: 0.7574276043625423,\n",
       "                                         1: 1.4711468224981739},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [1], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7574276043625423, 1: 1.4711468224981739},\n",
       "    probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7574276043625423, 1: 1.4711468224981739},\n",
       "    probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=SVC(class_weight={0: 0.7574276043625423,\n",
       "                                         1: 1.4711468224981739},\n",
       "                           probability=True),\n",
       "             param_grid={'C': [1], 'gamma': [1], 'kernel': ['poly']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameteres = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "parameteres = {'C': [1], 'gamma': [1],'kernel': ['poly']}\n",
    "clf = GridSearchCV(SVC(class_weight={0:class_weight[0], 1:class_weight[1]}, probability=True), param_grid=parameteres , cv=10, scoring='f1_macro')\n",
    "clf.fit(embs['cls'], df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f0b65b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=clf.predict_proba(emb_test['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9965c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def TestCutoff(df):\n",
    "\n",
    "    cut_off_list_=np.arange(0.005, 0.901, 0.005)\n",
    "#     cut_off_list = itertools.chain([0.01], cut_off_list_)\n",
    "    \n",
    "    f1score_macro_list=[]\n",
    "    f1score_list=[]\n",
    "    recall_list=[]\n",
    "    \n",
    "    predict_list_list=[[]]\n",
    "    for i, cut_off in enumerate(cut_off_list_):\n",
    "        predict_list=np.where(df['predict_1']>cut_off, 1, 0)\n",
    "        predict_list_list.append(predict_list)\n",
    "        print (cut_off)\n",
    "        precision, recall, f1score = precision_recall_fscore_support(df['label_test'], predict_list)[:3]\n",
    "        print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')\n",
    "        f1score_list.append(f1score[1])\n",
    "        recall_list.append(recall[1])\n",
    "        print (\"macro:\")\n",
    "        precision, recall, f1score_macro = precision_recall_fscore_support(df['label_test'], predict_list, average='macro')[:3]\n",
    "        print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score_macro}')\n",
    "        f1score_macro_list.append(f1score_macro)\n",
    "        print (\" \")\n",
    "    \n",
    "    max_ind=f1score_macro_list.index(max(f1score_macro_list))   \n",
    "    print (\"macro\", f1score_macro_list[max_ind])\n",
    "    print (\"F1-valued:\", f1score_list[max_ind])\n",
    "    print (\"recall-valued:\", recall_list[max_ind])\n",
    "    print (cut_off_list_[max_ind])\n",
    "    \n",
    "    df['predict']=predict_list_list[max_ind+1]\n",
    "        \n",
    "    return (df)\n",
    "#         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_predict:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "df433a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.84424779 0.76987448], recall: [0.89661654 0.67647059], f1score: [0.86964448 0.72015656]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4c96e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8070611322990335, recall: 0.7865435647943388, f1score_macro: 0.7949005203659865\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b595e",
   "metadata": {},
   "source": [
    "# LogitBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "891d536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c7c8b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('LogitBoost', LogitBoost())]\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps) # define the pipeline object.\n",
    "\n",
    "parameteres = {'LogitBoost__n_estimators':range(10,100,10)}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "78169602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 1024)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_test['cls'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "83fc3255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogitBoost</label><div class=\"sk-toggleable__content\"><pre>LogitBoost()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('LogitBoost', LogitBoost())]),\n",
       "             param_grid={'LogitBoost__n_estimators': range(10, 100, 10)})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(embs['cls'], df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde61c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(grid.best_params_))\n",
    "print(\"CV score=%0.3f\" % grid.best_score_)\n",
    "cv_results = grid.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d4a87253",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict_proba(emb_test['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce8abc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.84115523 0.736     ], recall: [0.87593985 0.67647059], f1score: [0.85819521 0.70498084]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "38b97191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7885776173285198, recall: 0.7762052189296771, f1score_macro: 0.7815880273491247\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bf0b9",
   "metadata": {},
   "source": [
    "# Logit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d22f6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a7d525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76264768, 1.45184544])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(df.label), y=df.label)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 10, 50), \"penalty\":[\"l1\",\"l2\"]}  #high C means \"Trust this training data a lot\", while a low value says \"This data may not be fully representative of the real world data, so if it's telling you to make a parameter really large, don't listen to it\"\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight={0:class_weight[0], 1:class_weight[1]}), parameters, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(embs['cls'], df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "df418568",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict_proba(emb_test['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de479596",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d593cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.86440678 0.73260073], recall: [0.86278195 0.73529412], f1score: [0.8635936  0.73394495]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "37fa9a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7985037561308748, recall: 0.7990380362671385, f1score_macro: 0.7987692785693943\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
