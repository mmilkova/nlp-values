{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c0a524",
   "metadata": {},
   "source": [
    "# Extract embeddings from SBERT and train SVM, LogitBoost, and LogitRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8b606c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")\n",
    "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_mt_nlu_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf5739",
   "metadata": {},
   "source": [
    "Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32c5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–î—É–º–∞–µ—Ç–µ, —á—Ç–æ —É–º–µ–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ñ–æ—Ç–æ—à–æ–ø–æ–º?...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...–°–∞–º–æ–µ —Å—Ç—Ä–∞—à–Ω–æ–µ - —ç—Ç–æ –∫–æ–≥–¥–∞ —Ç—ã —Å—Ç–æ–∏—à—å –ø–æ–¥ —Ö...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–î—Ä—É–∑—å—è –º–æ–∏! –ü–æ–¥–¥–µ—Ä–∂–∏–º –¥–æ—á–∫—É –º–æ–µ–π –ø–æ–¥—Ä—É–≥–∏! –ü—Ä–æ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ú–æ–π –Ω–æ–≤—ã–π –¥–Ω–µ–≤–Ω–∏–∫, —á–∏—Ç–∞–µ–º, –∫–æ–º–µ–Ω—Ç–∏–º :)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–†–£–°–°–ö–ò–ô  –ö–†–´–ú - –ú–ò–§ –¥–ª—è –±—ã–¥–ª–∞! (–æ —á–µ–º –º–æ–ª—á–∞—Ç ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0     –î—É–º–∞–µ—Ç–µ, —á—Ç–æ —É–º–µ–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ñ–æ—Ç–æ—à–æ–ø–æ–º?...    0.0\n",
       "1   ...–°–∞–º–æ–µ —Å—Ç—Ä–∞—à–Ω–æ–µ - —ç—Ç–æ –∫–æ–≥–¥–∞ —Ç—ã —Å—Ç–æ–∏—à—å –ø–æ–¥ —Ö...    1.0\n",
       "2   –î—Ä—É–∑—å—è –º–æ–∏! –ü–æ–¥–¥–µ—Ä–∂–∏–º –¥–æ—á–∫—É –º–æ–µ–π –ø–æ–¥—Ä—É–≥–∏! –ü—Ä–æ...    1.0\n",
       "3             –ú–æ–π –Ω–æ–≤—ã–π –¥–Ω–µ–≤–Ω–∏–∫, —á–∏—Ç–∞–µ–º, –∫–æ–º–µ–Ω—Ç–∏–º :)    0.0\n",
       "4   –†–£–°–°–ö–ò–ô  –ö–†–´–ú - –ú–ò–§ –¥–ª—è –±—ã–¥–ª–∞! (–æ —á–µ–º –º–æ–ª—á–∞—Ç ...    0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fold='../data/data_for_binary_classification/'\n",
    "file_='chatGPT_3_instr0_withEx_temp0_train_all_updated.csv'\n",
    "\n",
    "df=pd.read_csv(fold+file_, sep=\"|\", encoding ='utf-8')[['text', 'final_label']] #'label_crowd', 'gpt_result', \n",
    "df=df.rename(columns={'final_label':'label'})\n",
    "print (df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4d1836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3301\n",
       "1    1734\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label = df.label.astype('int')\n",
    "df.label=df.label.replace(3, 0)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d22a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.label.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b1a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.label.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9418eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "import numpy as np\n",
    "\n",
    "def mean_pooling(model_output, attention_mask, norm=True):\n",
    "    token_embeddings = model_output[0]  #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum([1]), min=1e-9)\n",
    "    sums = sum_embeddings / sum_mask\n",
    "    if norm:\n",
    "        sums = torch.nn.functional.normalize(sums)\n",
    "    return sums\n",
    "\n",
    "\n",
    "def embed_bert_pytorch(text, model, tokenizer, emb_type=['cls','mean']):\n",
    "    t = tokenizer(text, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "    t = {k: v.to(model.device) for k, v in t.items()}\n",
    "\n",
    "    with torch.inference_mode():    \n",
    "        model_output = model(**t)\n",
    "    \n",
    "    res_dict = {}\n",
    "   \n",
    "    if 'cls' in emb_type:\n",
    "        e1 = torch.nn.functional.normalize(model_output.last_hidden_state[:, 0, :])\n",
    "        res_dict['cls'] = e1[0].cpu().numpy()\n",
    "\n",
    "    if 'mean' in emb_type:\n",
    "        e2 = mean_pooling(model_output, t['attention_mask'])\n",
    "        res_dict['mean'] = e2[0].cpu().numpy()\n",
    "        \n",
    "        \n",
    "    return res_dict\n",
    "\n",
    "def get_emb(embedder, data):\n",
    "    embs = [embedder(x) for x in tqdm_n(data)] # tqdm\n",
    "    emb = {}\n",
    "    for k in embs[0].keys():\n",
    "        emb[k] = np.stack([row[k] for row in embs])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61fd45f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ede49d72c0c4c84b1b44302ab30b182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5035 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 58min 55s, sys: 52.3 s, total: 3h 59min 47s\n",
      "Wall time: 5min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embs = get_emb(lambda x: embed_bert_pytorch(x, model, tokenizer), df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "85c1c54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5035, 1024), (5035, 1024))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs['cls'].shape, embs['mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d05fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00929506, -0.01398701,  0.00787013, ..., -0.00742487,\n",
       "         0.02980503,  0.00831383], dtype=float32),\n",
       " array([ 0.00592028, -0.00051701,  0.02079129, ..., -0.00939083,\n",
       "         0.04377579,  0.00758594], dtype=float32))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs['cls'][0], embs['mean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c0c8b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_cls_train, X_cls_test, y_train, y_test = train_test_split(\n",
    "    embs['cls'], df.label, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "X_mean_train, X_mean_test, _, _ = train_test_split(\n",
    "    embs['mean'], df.label, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b29b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "Cs = np.logspace(-5, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "19eecc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 59s, sys: 25min 32s, total: 41min 32s\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_cls  = LogisticRegressionCV(Cs=Cs, max_iter=1_000, n_jobs=1, verbose=0).fit(X_cls_train, y_train)\n",
    "clf_mean = LogisticRegressionCV(Cs=Cs, max_iter=1_000, n_jobs=1, verbose=0).fit(X_mean_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "65ca7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import fbeta_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def get_metrics(y, preds, beta = 5):\n",
    "    round3 = lambda x: round(x*1000)/1000\n",
    "    pre = precision_score(y, preds, zero_division=0)\n",
    "    rec = recall_score(y, preds, zero_division=0)\n",
    "    pro = (1-min(pre,0.9999999999999))/(1-min(rec,0.9999999999999))\n",
    "    pro_loss = math.log(abs(beta - pro)+1)\n",
    "    return {'fbeta':round3(fbeta_score(y, preds, beta=beta, zero_division=0)), \n",
    "            'f1':round3(fbeta_score(y, preds, beta=1, zero_division=0)), \n",
    "            'roc_auc':round3(roc_auc_score(y, preds)), \n",
    "            'precision':round3(pre),\n",
    "            'recall':round3(rec),\n",
    "            'pro': round3(pro),\n",
    "            'pro_loss':pro_loss, \n",
    "            'TP': ((y == 1) & (preds == 1)).sum(),\n",
    "            'TN': ((y == 0) & (preds == 0)).sum(),\n",
    "            'FP': ((y == 0) & (preds == 1)).sum(),\n",
    "            'FN': ((y == 1) & (preds == 0)).sum(),\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f507188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6298003072196622"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, clf_cls.predict_proba(X_cls_test)[:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2ad9593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fbeta': 0.636,\n",
       " 'f1': 0.636,\n",
       " 'roc_auc': 0.717,\n",
       " 'precision': 0.658,\n",
       " 'recall': 0.616,\n",
       " 'pro': 0.892,\n",
       " 'pro_loss': 0.10263123063578138,\n",
       " 'TP': 225,\n",
       " 'TN': 525,\n",
       " 'FP': 117,\n",
       " 'FN': 140}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test, clf_cls.predict_proba(X_cls_test)[:,1] > 0.44, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f606a0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fbeta': 0.639,\n",
       " 'f1': 0.639,\n",
       " 'roc_auc': 0.718,\n",
       " 'precision': 0.651,\n",
       " 'recall': 0.627,\n",
       " 'pro': 0.938,\n",
       " 'pro_loss': 0.06032967426580218,\n",
       " 'TP': 229,\n",
       " 'TN': 519,\n",
       " 'FP': 123,\n",
       " 'FN': 136}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test, clf_mean.predict_proba(X_mean_test)[:,1] > 0.434, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0422f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å, –≥–¥–µ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>—á–µ—Ç –∫–∞–∫-—Ç–æ –Ω–µ—Ä–∞–¥–æ—Å—Ç–Ω–æ –≤—Å–µ —ç—Ç–æ...–æ—Å–æ–±–æ –Ω–∞ —Ñ–æ–Ω–µ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Repost with . „Éª„Éª„Éª –∂–∞–ª—å —á—Ç–æ –±—ã—Å—Ç—Ä–æ —É–±–µ–∂–∞–ª–∞!!!#...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#hellomyearth #–¥–æ—Ä–æ–≥–∞–∂–∏–∑–Ω–∏ #—Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω–æ–µ–∫–æ–ª—å—Ü–æ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#–í—Ç–∞–Ω–¥–µ–º–µ–°–ú–∞–º–æ–π#–∫–∞–∫—Ç–∞–º–ø—Ä–æ–±–∫–∞#üòÅ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_test\n",
       "0   - –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å, –≥–¥–µ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å...           1\n",
       "1   —á–µ—Ç –∫–∞–∫-—Ç–æ –Ω–µ—Ä–∞–¥–æ—Å—Ç–Ω–æ –≤—Å–µ —ç—Ç–æ...–æ—Å–æ–±–æ –Ω–∞ —Ñ–æ–Ω–µ...           0\n",
       "2  #Repost with . „Éª„Éª„Éª –∂–∞–ª—å —á—Ç–æ –±—ã—Å—Ç—Ä–æ —É–±–µ–∂–∞–ª–∞!!!#...           0\n",
       "3      #hellomyearth #–¥–æ—Ä–æ–≥–∞–∂–∏–∑–Ω–∏ #—Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω–æ–µ–∫–æ–ª—å—Ü–æ           0\n",
       "4                     #–í—Ç–∞–Ω–¥–µ–º–µ–°–ú–∞–º–æ–π#–∫–∞–∫—Ç–∞–º–ø—Ä–æ–±–∫–∞#üòÅ           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trial dataset\n",
    "file_test='all_merged_temp0_instr0_withEx_test_final_label.csv'\n",
    "\n",
    "test_data=pd.read_csv(fold+file_test, sep=\"|\", encoding ='utf-8')[['text', 'final_label']]\n",
    "test_data=test_data.rename(columns={'final_label':'label_test'})\n",
    "print (test_data.shape[0])\n",
    "test_data.label_test=test_data.label_test.astype(int)\n",
    "test_data.label_test=test_data.label_test.replace(3, 0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff51e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    532\n",
       "1    272\n",
       "Name: label_test, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.label_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9b1f9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e473e8e6bc004ca09c379c8b1c9cb841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36min 6s, sys: 11 s, total: 36min 17s\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emb_test = get_emb(lambda x: embed_bert_pytorch(x, model, tokenizer), test_data.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e988476c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00929506, -0.01398701,  0.00787013, ..., -0.00742487,\n",
       "         0.02980503,  0.00831383],\n",
       "       [-0.04644227, -0.02437294,  0.02493586, ...,  0.04479778,\n",
       "        -0.02900108, -0.00685201],\n",
       "       [-0.05861808, -0.00421491, -0.05079638, ...,  0.00123103,\n",
       "        -0.02409819,  0.03700725],\n",
       "       ...,\n",
       "       [-0.03123325,  0.01808644, -0.02161152, ..., -0.00243144,\n",
       "        -0.00893479, -0.00128236],\n",
       "       [ 0.02588368,  0.0146559 , -0.03030781, ...,  0.00612109,\n",
       "        -0.04469183,  0.02309735],\n",
       "       [-0.00969478, -0.01412101, -0.01880374, ...,  0.01690224,\n",
       "        -0.01349046,  0.00146537]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs['cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6e056f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7574276 , 1.47114682])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75461be",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "941daf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=SVC(class_weight={0: 0.7574276043625423,\n",
       "                                         1: 1.4711468224981739},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [1], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=SVC(class_weight={0: 0.7574276043625423,\n",
       "                                         1: 1.4711468224981739},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [1], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7574276043625423, 1: 1.4711468224981739},\n",
       "    probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7574276043625423, 1: 1.4711468224981739},\n",
       "    probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=SVC(class_weight={0: 0.7574276043625423,\n",
       "                                         1: 1.4711468224981739},\n",
       "                           probability=True),\n",
       "             param_grid={'C': [1], 'gamma': [1], 'kernel': ['poly']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameteres = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "parameteres = {'C': [1], 'gamma': [1],'kernel': ['poly']}\n",
    "clf = GridSearchCV(SVC(class_weight={0:class_weight[0], 1:class_weight[1]}, probability=True), param_grid=parameteres , cv=10, scoring='f1_macro')\n",
    "clf.fit(embs['cls'], df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f0b65b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=clf.predict_proba(emb_test['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9965c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def TestCutoff(df):\n",
    "\n",
    "    cut_off_list_=np.arange(0.005, 0.901, 0.005)\n",
    "#     cut_off_list = itertools.chain([0.01], cut_off_list_)\n",
    "    \n",
    "    f1score_macro_list=[]\n",
    "    f1score_list=[]\n",
    "    recall_list=[]\n",
    "    \n",
    "    predict_list_list=[[]]\n",
    "    for i, cut_off in enumerate(cut_off_list_):\n",
    "        predict_list=np.where(df['predict_1']>cut_off, 1, 0)\n",
    "        predict_list_list.append(predict_list)\n",
    "        print (cut_off)\n",
    "        precision, recall, f1score = precision_recall_fscore_support(df['label_test'], predict_list)[:3]\n",
    "        print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')\n",
    "        f1score_list.append(f1score[1])\n",
    "        recall_list.append(recall[1])\n",
    "        print (\"macro:\")\n",
    "        precision, recall, f1score_macro = precision_recall_fscore_support(df['label_test'], predict_list, average='macro')[:3]\n",
    "        print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score_macro}')\n",
    "        f1score_macro_list.append(f1score_macro)\n",
    "        print (\" \")\n",
    "    \n",
    "    max_ind=f1score_macro_list.index(max(f1score_macro_list))   \n",
    "    print (\"macro\", f1score_macro_list[max_ind])\n",
    "    print (\"F1-valued:\", f1score_list[max_ind])\n",
    "    print (\"recall-valued:\", recall_list[max_ind])\n",
    "    print (cut_off_list_[max_ind])\n",
    "    \n",
    "    df['predict']=predict_list_list[max_ind+1]\n",
    "        \n",
    "    return (df)\n",
    "#         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d161b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "precision: [0.         0.33830846], recall: [0. 1.], f1score: [0.         0.50557621]\n",
      "macro:\n",
      "precision: 0.1691542288557214, recall: 0.5, f1score_macro: 0.2527881040892193\n",
      " \n",
      "0.01\n",
      "precision: [0.         0.33830846], recall: [0. 1.], f1score: [0.         0.50557621]\n",
      "macro:\n",
      "precision: 0.1691542288557214, recall: 0.5, f1score_macro: 0.2527881040892193\n",
      " \n",
      "0.015\n",
      "precision: [0.         0.33830846], recall: [0. 1.], f1score: [0.         0.50557621]\n",
      "macro:\n",
      "precision: 0.1691542288557214, recall: 0.5, f1score_macro: 0.2527881040892193\n",
      " \n",
      "0.02\n",
      "precision: [0.         0.33830846], recall: [0. 1.], f1score: [0.         0.50557621]\n",
      "macro:\n",
      "precision: 0.1691542288557214, recall: 0.5, f1score_macro: 0.2527881040892193\n",
      " \n",
      "0.025\n",
      "precision: [1.         0.33872976], recall: [0.0018797 1.       ], f1score: [0.00375235 0.50604651]\n",
      "macro:\n",
      "precision: 0.6693648816936488, recall: 0.5009398496240601, f1score_macro: 0.25489942842183344\n",
      " \n",
      "0.030000000000000002\n",
      "precision: [1.         0.34042553], recall: [0.0093985 1.       ], f1score: [0.01862197 0.50793651]\n",
      "macro:\n",
      "precision: 0.6702127659574468, recall: 0.5046992481203008, f1score_macro: 0.2632792409328722\n",
      " \n",
      "0.034999999999999996\n",
      "precision: [1.        0.3412798], recall: [0.01315789 1.        ], f1score: [0.02597403 0.50888681]\n",
      "macro:\n",
      "precision: 0.6706398996235885, recall: 0.506578947368421, f1score_macro: 0.26743041803846296\n",
      " \n",
      "0.04\n",
      "precision: [1.         0.34213836], recall: [0.01691729 1.        ], f1score: [0.03327172 0.50984067]\n",
      "macro:\n",
      "precision: 0.6710691823899371, recall: 0.5084586466165414, f1score_macro: 0.2715561969139727\n",
      " \n",
      "0.045\n",
      "precision: [1.        0.3443038], recall: [0.02631579 1.        ], f1score: [0.05128205 0.51224105]\n",
      "macro:\n",
      "precision: 0.6721518987341772, recall: 0.5131578947368421, f1score_macro: 0.28176155294799365\n",
      " \n",
      "0.049999999999999996\n",
      "precision: [1.         0.34827145], recall: [0.04323308 1.        ], f1score: [0.08288288 0.51661918]\n",
      "macro:\n",
      "precision: 0.6741357234314981, recall: 0.5216165413533834, f1score_macro: 0.29975103308436646\n",
      " \n",
      "0.055\n",
      "precision: [1.         0.35142119], recall: [0.05639098 1.        ], f1score: [0.10676157 0.52007648]\n",
      "macro:\n",
      "precision: 0.6757105943152455, recall: 0.5281954887218046, f1score_macro: 0.31341902383593145\n",
      " \n",
      "0.06\n",
      "precision: [1.         0.35695538], recall: [0.07894737 1.        ], f1score: [0.14634146 0.52611219]\n",
      "macro:\n",
      "precision: 0.678477690288714, recall: 0.5394736842105263, f1score_macro: 0.33622682455064395\n",
      " \n",
      "0.065\n",
      "precision: [0.96296296 0.36      ], recall: [0.09774436 0.99264706], f1score: [0.1774744  0.52837573]\n",
      "macro:\n",
      "precision: 0.6614814814814814, recall: 0.5451957098628926, f1score_macro: 0.3529250682927807\n",
      " \n",
      "0.07\n",
      "precision: [0.95454545 0.36449864], recall: [0.11842105 0.98897059], f1score: [0.21070234 0.53267327]\n",
      "macro:\n",
      "precision: 0.6595220497659522, recall: 0.5536958204334366, f1score_macro: 0.3716878042319282\n",
      " \n",
      "0.07500000000000001\n",
      "precision: [0.95945946 0.36849315], recall: [0.13345865 0.98897059], f1score: [0.23432343 0.53692615]\n",
      "macro:\n",
      "precision: 0.6639763050721954, recall: 0.5612146174259177, f1score_macro: 0.3856247900239126\n",
      " \n",
      "0.08\n",
      "precision: [0.96385542 0.37309293], recall: [0.15037594 0.98897059], f1score: [0.2601626  0.54179255]\n",
      "macro:\n",
      "precision: 0.6684741740888659, recall: 0.5696732640424591, f1score_macro: 0.40097757473043005\n",
      " \n",
      "0.085\n",
      "precision: [0.96039604 0.38122333], recall: [0.18233083 0.98529412], f1score: [0.30647709 0.54974359]\n",
      "macro:\n",
      "precision: 0.670809684097855, recall: 0.583812472357364, f1score_macro: 0.4281103414752704\n",
      " \n",
      "0.09000000000000001\n",
      "precision: [0.94594595 0.38383838], recall: [0.19736842 0.97794118], f1score: [0.32659409 0.55129534]\n",
      "macro:\n",
      "precision: 0.6648921648921648, recall: 0.5876547987616099, f1score_macro: 0.438944713494871\n",
      " \n",
      "0.095\n",
      "precision: [0.95275591 0.3929099 ], recall: [0.22744361 0.97794118], f1score: [0.36722307 0.56059009]\n",
      "macro:\n",
      "precision: 0.6728329010572349, recall: 0.6026923927465723, f1score_macro: 0.4639065800435247\n",
      " \n",
      "0.1\n",
      "precision: [0.95035461 0.39969834], recall: [0.2518797  0.97426471], f1score: [0.39821694 0.56684492]\n",
      "macro:\n",
      "precision: 0.6750264754019448, recall: 0.6130722025652366, f1score_macro: 0.4825309294324241\n",
      " \n",
      "0.10500000000000001\n",
      "precision: [0.94904459 0.40803709], recall: [0.28007519 0.97058824], f1score: [0.43251089 0.57453754]\n",
      "macro:\n",
      "precision: 0.6785408401342797, recall: 0.6253317116320212, f1score_macro: 0.5035242130731485\n",
      " \n",
      "0.11\n",
      "precision: [0.93641618 0.41362916], recall: [0.30451128 0.95955882], f1score: [0.45957447 0.57807309]\n",
      "macro:\n",
      "precision: 0.6750226725172448, recall: 0.6320350508624503, f1score_macro: 0.5188237788930515\n",
      " \n",
      "0.115\n",
      "precision: [0.93846154 0.42692939], recall: [0.34398496 0.95588235], f1score: [0.50343879 0.59023837]\n",
      "macro:\n",
      "precision: 0.6826954654540861, recall: 0.6499336576735958, f1score_macro: 0.5468385775199185\n",
      " \n",
      "0.12000000000000001\n",
      "precision: [0.94059406 0.43189369], recall: [0.35714286 0.95588235], f1score: [0.51771117 0.59496568]\n",
      "macro:\n",
      "precision: 0.6862438735567908, recall: 0.6565126050420168, f1score_macro: 0.5563384233596668\n",
      " \n",
      "0.125\n",
      "precision: [0.94392523 0.44067797], recall: [0.37969925 0.95588235], f1score: [0.54155496 0.60324826]\n",
      "macro:\n",
      "precision: 0.6923015998732773, recall: 0.6677908005307387, f1score_macro: 0.5724016098231558\n",
      " \n",
      "0.13\n",
      "precision: [0.94222222 0.44732297], recall: [0.39849624 0.95220588], f1score: [0.56010568 0.60869565]\n",
      "macro:\n",
      "precision: 0.6947725964306275, recall: 0.6753510614772225, f1score_macro: 0.584400666245477\n",
      " \n",
      "0.135\n",
      "precision: [0.93670886 0.45326279], recall: [0.41729323 0.94485294], f1score: [0.57737321 0.61263409]\n",
      "macro:\n",
      "precision: 0.6949858236778068, recall: 0.6810730871295887, f1score_macro: 0.5950036500819138\n",
      " \n",
      "0.14\n",
      "precision: [0.93650794 0.46376812], recall: [0.44360902 0.94117647], f1score: [0.60204082 0.62135922]\n",
      "macro:\n",
      "precision: 0.7001380262249828, recall: 0.6923927465723131, f1score_macro: 0.6117000198137508\n",
      " \n",
      "0.14500000000000002\n",
      "precision: [0.93609023 0.4739777 ], recall: [0.46804511 0.9375    ], f1score: [0.62406015 0.62962963]\n",
      "macro:\n",
      "precision: 0.705033960365598, recall: 0.7027725563909775, f1score_macro: 0.6268448900027848\n",
      " \n",
      "0.15\n",
      "precision: [0.93680297 0.47663551], recall: [0.47368421 0.9375    ], f1score: [0.62921348 0.63197026]\n",
      "macro:\n",
      "precision: 0.7067192439981934, recall: 0.7055921052631579, f1score_macro: 0.6305918716845579\n",
      " \n",
      "0.155\n",
      "precision: [0.93548387 0.48380952], recall: [0.4906015  0.93382353], f1score: [0.64364982 0.63739021]\n",
      "macro:\n",
      "precision: 0.7096466973886328, recall: 0.7122125165855816, f1score_macro: 0.6405200141715155\n",
      " \n",
      "0.16\n",
      "precision: [0.93402778 0.49031008], recall: [0.5056391  0.93014706], f1score: [0.65609756 0.64213198]\n",
      "macro:\n",
      "precision: 0.7121689276485788, recall: 0.7178930782839452, f1score_macro: 0.6491147703355206\n",
      " \n",
      "0.165\n",
      "precision: [0.92666667 0.49603175], recall: [0.52255639 0.91911765], f1score: [0.66826923 0.6443299 ]\n",
      "macro:\n",
      "precision: 0.7113492063492064, recall: 0.7208370190181336, f1score_macro: 0.6562995638382236\n",
      " \n",
      "0.17\n",
      "precision: [0.92880259 0.50505051], recall: [0.53947368 0.91911765], f1score: [0.68252081 0.65189048]\n",
      "macro:\n",
      "precision: 0.7169265470236343, recall: 0.729295665634675, f1score_macro: 0.6672056454800968\n",
      " \n",
      "0.17500000000000002\n",
      "precision: [0.92767296 0.51234568], recall: [0.55451128 0.91544118], f1score: [0.69411765 0.65699208]\n",
      "macro:\n",
      "precision: 0.7200093174935942, recall: 0.7349762273330385, f1score_macro: 0.6755548657457706\n",
      " \n",
      "0.18000000000000002\n",
      "precision: [0.92638037 0.51882845], recall: [0.56766917 0.91176471], f1score: [0.7039627  0.66133333]\n",
      "macro:\n",
      "precision: 0.7226044099905023, recall: 0.739716939407342, f1score_macro: 0.6826480186480186\n",
      " \n",
      "0.185\n",
      "precision: [0.92492492 0.52441614], recall: [0.57894737 0.90808824], f1score: [0.71213873 0.66487214]\n",
      "macro:\n",
      "precision: 0.7246705304030145, recall: 0.7435178018575852, f1score_macro: 0.6885054341483907\n",
      " \n",
      "0.19\n",
      "precision: [0.92082111 0.52915767], recall: [0.59022556 0.90073529], f1score: [0.71935853 0.66666667]\n",
      "macro:\n",
      "precision: 0.7249893908780553, recall: 0.7454804290137107, f1score_macro: 0.693012600229095\n",
      " \n",
      "0.195\n",
      "precision: [0.91690544 0.53406593], recall: [0.60150376 0.89338235], f1score: [0.72644722 0.66850069]\n",
      "macro:\n",
      "precision: 0.7254856890960043, recall: 0.7474430561698364, f1score_macro: 0.6974739534135743\n",
      " \n",
      "0.2\n",
      "precision: [0.91460055 0.54648526], recall: [0.62406015 0.88602941], f1score: [0.74189944 0.67601683]\n",
      "macro:\n",
      "precision: 0.7305429058675812, recall: 0.7550447810703229, f1score_macro: 0.7089581358176562\n",
      " \n",
      "0.20500000000000002\n",
      "precision: [0.91644205 0.55658199], recall: [0.63909774 0.88602941], f1score: [0.7530454  0.68368794]\n",
      "macro:\n",
      "precision: 0.7365120173303537, recall: 0.7625635780628041, f1score_macro: 0.7183666737353032\n",
      " \n",
      "0.21000000000000002\n",
      "precision: [0.91777188 0.56440281], recall: [0.65037594 0.88602941], f1score: [0.76127613 0.68955651]\n",
      "macro:\n",
      "precision: 0.7410873467967871, recall: 0.768202675807165, f1score_macro: 0.72541631845588\n",
      " \n",
      "0.215\n",
      "precision: [0.91361257 0.56635071], recall: [0.65601504 0.87867647], f1score: [0.76367615 0.68876081]\n",
      "macro:\n",
      "precision: 0.7399816381727501, recall: 0.7673457540911102, f1score_macro: 0.7262184778564627\n",
      " \n",
      "0.22\n",
      "precision: [0.9119171  0.56937799], recall: [0.66165414 0.875     ], f1score: [0.76688453 0.68985507]\n",
      "macro:\n",
      "precision: 0.7406475444381089, recall: 0.7683270676691729, f1score_macro: 0.728369802027091\n",
      " \n",
      "0.225\n",
      "precision: [0.91348601 0.57907543], recall: [0.67481203 0.875     ], f1score: [0.77621622 0.69692533]\n",
      "macro:\n",
      "precision: 0.7462807154399064, recall: 0.7749060150375939, f1score_macro: 0.736570772822603\n",
      " \n",
      "0.23\n",
      "precision: [0.91044776 0.58706468], recall: [0.68796992 0.86764706], f1score: [0.78372591 0.70029674]\n",
      "macro:\n",
      "precision: 0.7487562189054726, recall: 0.7778084918177798, f1score_macro: 0.7420113229846421\n",
      " \n",
      "0.23500000000000001\n",
      "precision: [0.91133005 0.59296482], recall: [0.69548872 0.86764706], f1score: [0.78891258 0.70447761]\n",
      "macro:\n",
      "precision: 0.7521474366908434, recall: 0.7815678903140204, f1score_macro: 0.7466950959488272\n",
      " \n",
      "0.24000000000000002\n",
      "precision: [0.9097561 0.5964467], recall: [0.70112782 0.86397059], f1score: [0.79193206 0.70570571]\n",
      "macro:\n",
      "precision: 0.753101399034295, recall: 0.7825492038920832, f1score_macro: 0.7488188825768443\n",
      " \n",
      "0.245\n",
      "precision: [0.91105769 0.6056701 ], recall: [0.71240602 0.86397059], f1score: [0.79957806 0.71212121]\n",
      "macro:\n",
      "precision: 0.7583638977002378, recall: 0.788188301636444, f1score_macro: 0.755849635596471\n",
      " \n",
      "0.25\n",
      "precision: [0.90543735 0.60892388], recall: [0.71992481 0.85294118], f1score: [0.80209424 0.71056662]\n",
      "macro:\n",
      "precision: 0.7571806183801493, recall: 0.7864329942503316, f1score_macro: 0.7563304282289552\n",
      " \n",
      "0.255\n",
      "precision: [0.90186916 0.61170213], recall: [0.72556391 0.84558824], f1score: [0.80416667 0.70987654]\n",
      "macro:\n",
      "precision: 0.7567856432690396, recall: 0.7855760725342769, f1score_macro: 0.7570216049382716\n",
      " \n",
      "0.26\n",
      "precision: [0.90023202 0.61394102], recall: [0.72932331 0.84191176], f1score: [0.80581516 0.71007752]\n",
      "macro:\n",
      "precision: 0.7570865186641205, recall: 0.7856175364882796, f1score_macro: 0.7579463401675964\n",
      " \n",
      "0.265\n",
      "precision: [0.8993135  0.62125341], recall: [0.7387218  0.83823529], f1score: [0.81114551 0.71361502]\n",
      "macro:\n",
      "precision: 0.7602834535693576, recall: 0.7884785493144626, f1score_macro: 0.7623802671550457\n",
      " \n",
      "0.27\n",
      "precision: [0.89819005 0.62707182], recall: [0.7462406  0.83455882], f1score: [0.81519507 0.71608833]\n",
      "macro:\n",
      "precision: 0.7626309342266444, recall: 0.7903997125165856, f1score_macro: 0.7656416999721465\n",
      " \n",
      "0.275\n",
      "precision: [0.89955357 0.63764045], recall: [0.7575188  0.83455882], f1score: [0.82244898 0.72292994]\n",
      "macro:\n",
      "precision: 0.7685970104333868, recall: 0.7960388102609466, f1score_macro: 0.7726894579487846\n",
      " \n",
      "0.28\n",
      "precision: [0.9010989 0.6504298], recall: [0.77067669 0.83455882], f1score: [0.83080041 0.7310789 ]\n",
      "macro:\n",
      "precision: 0.7757643502629177, recall: 0.8026177576293676, f1score_macro: 0.7809396551302193\n",
      " \n",
      "0.28500000000000003\n",
      "precision: [0.89934354 0.65129683], recall: [0.77255639 0.83088235], f1score: [0.83114257 0.73021002]\n",
      "macro:\n",
      "precision: 0.7753201874144748, recall: 0.8017193719593101, f1score_macro: 0.7806762922029236\n",
      " \n",
      "0.29000000000000004\n",
      "precision: [0.89416847 0.65395894], recall: [0.77819549 0.81985294], f1score: [0.8321608  0.72756933]\n",
      "macro:\n",
      "precision: 0.7740637054021016, recall: 0.7990242149491376, f1score_macro: 0.7798650675891693\n",
      " \n",
      "0.295\n",
      "precision: [0.8869936  0.65373134], recall: [0.78195489 0.80514706], f1score: [0.83116883 0.72158155]\n",
      "macro:\n",
      "precision: 0.770362473347548, recall: 0.7935509730207873, f1score_macro: 0.7763751898842508\n",
      " \n",
      "0.3\n",
      "precision: [0.88396624 0.65757576], recall: [0.78759398 0.79779412], f1score: [0.83300199 0.72093023]\n",
      "macro:\n",
      "precision: 0.770771001150748, recall: 0.7926940513047325, f1score_macro: 0.7769661103148551\n",
      " \n",
      "0.305\n",
      "precision: [0.88235294 0.65853659], recall: [0.78947368 0.79411765], f1score: [0.83333333 0.72      ]\n",
      "macro:\n",
      "precision: 0.7704447632711622, recall: 0.791795665634675, f1score_macro: 0.7766666666666666\n",
      " \n",
      "0.31\n",
      "precision: [0.88125    0.66358025], recall: [0.79511278 0.79044118], f1score: [0.83596838 0.72147651]\n",
      "macro:\n",
      "precision: 0.7724151234567901, recall: 0.7927769792127377, f1score_macro: 0.7787224447568772\n",
      " \n",
      "0.315\n",
      "precision: [0.87991718 0.66666667], recall: [0.79887218 0.78676471], f1score: [0.83743842 0.72175379]\n",
      "macro:\n",
      "precision: 0.7732919254658385, recall: 0.7928184431667404, f1score_macro: 0.7795961089558809\n",
      " \n",
      "0.32\n",
      "precision: [0.8788501  0.67192429], recall: [0.80451128 0.78308824], f1score: [0.84003925 0.72325976]\n",
      "macro:\n",
      "precision: 0.7753871964451124, recall: 0.7937997567448032, f1score_macro: 0.781649508239877\n",
      " \n",
      "0.325\n",
      "precision: [0.8755102  0.67197452], recall: [0.80639098 0.77573529], f1score: [0.83953033 0.72013652]\n",
      "macro:\n",
      "precision: 0.773742363187313, recall: 0.791063135780628, f1score_macro: 0.7798334257261743\n",
      " \n",
      "0.33\n",
      "precision: [0.87449393 0.67741935], recall: [0.81203008 0.77205882], f1score: [0.84210526 0.72164948]\n",
      "macro:\n",
      "precision: 0.7759566409821079, recall: 0.7920444493586909, f1score_macro: 0.7818773738469885\n",
      " \n",
      "0.335\n",
      "precision: [0.87374749 0.6852459 ], recall: [0.81954887 0.76838235], f1score: [0.8457808  0.72443674]\n",
      "macro:\n",
      "precision: 0.7794966983146621, recall: 0.7939656125608139, f1score_macro: 0.7851087685560452\n",
      " \n",
      "0.34\n",
      "precision: [0.87128713 0.69230769], recall: [0.82706767 0.76102941], f1score: [0.84860174 0.72504378]\n",
      "macro:\n",
      "precision: 0.7817974105102818, recall: 0.7940485404688191, f1score_macro: 0.7868227593067028\n",
      " \n",
      "0.34500000000000003\n",
      "precision: [0.87007874 0.69594595], recall: [0.83082707 0.75735294], f1score: [0.85       0.72535211]\n",
      "macro:\n",
      "precision: 0.7830123430517131, recall: 0.7940900044228217, f1score_macro: 0.7876760563380282\n",
      " \n",
      "0.35000000000000003\n",
      "precision: [0.87084149 0.70307167], recall: [0.83646617 0.75735294], f1score: [0.85330777 0.72920354]\n",
      "macro:\n",
      "precision: 0.7869565798173961, recall: 0.7969095532950021, f1score_macro: 0.7912556529412264\n",
      " \n",
      "0.35500000000000004\n",
      "precision: [0.86964981 0.70689655], recall: [0.84022556 0.75367647], f1score: [0.85468451 0.72953737]\n",
      "macro:\n",
      "precision: 0.7882731785858044, recall: 0.7969510172490049, f1score_macro: 0.7921109394881705\n",
      " \n",
      "0.36\n",
      "precision: [0.8623327  0.71174377], recall: [0.84774436 0.73529412], f1score: [0.8549763  0.72332731]\n",
      "macro:\n",
      "precision: 0.7870382341133483, recall: 0.7915192392746573, f1score_macro: 0.7891518044616612\n",
      " \n",
      "0.365\n",
      "precision: [0.86068702 0.71071429], recall: [0.84774436 0.73161765], f1score: [0.85416667 0.72101449]\n",
      "macro:\n",
      "precision: 0.7857006543075246, recall: 0.7896810039805395, f1score_macro: 0.7875905797101449\n",
      " \n",
      "0.37\n",
      "precision: [0.85875706 0.72161172], recall: [0.85714286 0.72426471], f1score: [0.8579492  0.72293578]\n",
      "macro:\n",
      "precision: 0.7901843918793071, recall: 0.790703781512605, f1score_macro: 0.7904424900964035\n",
      " \n",
      "0.375\n",
      "precision: [0.85553471 0.7195572 ], recall: [0.85714286 0.71691176], f1score: [0.85633803 0.71823204]\n",
      "macro:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7875459523826007, recall: 0.7870273109243697, f1score_macro: 0.7872850361839545\n",
      " \n",
      "0.38\n",
      "precision: [0.85580524 0.72222222], recall: [0.85902256 0.71691176], f1score: [0.85741088 0.7195572 ]\n",
      "macro:\n",
      "precision: 0.7890137328339575, recall: 0.78796716054843, f1score_macro: 0.7884840386865407\n",
      " \n",
      "0.385\n",
      "precision: [0.85447761 0.7238806 ], recall: [0.86090226 0.71323529], f1score: [0.8576779  0.71851852]\n",
      "macro:\n",
      "precision: 0.789179104477612, recall: 0.7870687748783725, f1score_macro: 0.7880982105701206\n",
      " \n",
      "0.39\n",
      "precision: [0.85212569 0.73003802], recall: [0.86654135 0.70588235], f1score: [0.85927307 0.71775701]\n",
      "macro:\n",
      "precision: 0.7910818579872507, recall: 0.7862118531623176, f1score_macro: 0.7885150377577061\n",
      " \n",
      "0.395\n",
      "precision: [0.84898711 0.72796935], recall: [0.86654135 0.69852941], f1score: [0.85767442 0.71294559]\n",
      "macro:\n",
      "precision: 0.7884782286573104, recall: 0.7825353825740822, f1score_macro: 0.7853100047995114\n",
      " \n",
      "0.4\n",
      "precision: [0.84981685 0.73643411], recall: [0.87218045 0.69852941], f1score: [0.86085343 0.71698113]\n",
      "macro:\n",
      "precision: 0.7931254791719908, recall: 0.7853549314462627, f1score_macro: 0.7889172821787377\n",
      " \n",
      "0.405\n",
      "precision: [0.84909091 0.74409449], recall: [0.87781955 0.69485294], f1score: [0.86321627 0.71863118]\n",
      "macro:\n",
      "precision: 0.7965926986399428, recall: 0.7863362450243255, f1score_macro: 0.7909237224404884\n",
      " \n",
      "0.41000000000000003\n",
      "precision: [0.8471223  0.75403226], recall: [0.88533835 0.6875    ], f1score: [0.86580882 0.71923077]\n",
      "macro:\n",
      "precision: 0.8005772801113947, recall: 0.7864191729323309, f1score_macro: 0.7925197963800905\n",
      " \n",
      "0.41500000000000004\n",
      "precision: [0.84397163 0.76666667], recall: [0.89473684 0.67647059], f1score: [0.86861314 0.71875   ]\n",
      "macro:\n",
      "precision: 0.8053191489361702, recall: 0.7856037151702786, f1score_macro: 0.7936815693430657\n",
      " \n",
      "0.42000000000000004\n",
      "precision: [0.84424779 0.76987448], recall: [0.89661654 0.67647059], f1score: [0.86964448 0.72015656]\n",
      "macro:\n",
      "precision: 0.8070611322990335, recall: 0.7865435647943388, f1score_macro: 0.7949005203659865\n",
      " \n",
      "0.425\n",
      "precision: [0.84303351 0.7721519 ], recall: [0.89849624 0.67279412], f1score: [0.86988171 0.71905697]\n",
      "macro:\n",
      "precision: 0.8075927042171768, recall: 0.7856451791242813, f1score_macro: 0.7944693425528833\n",
      " \n",
      "0.43\n",
      "precision: [0.84182777 0.77446809], recall: [0.90037594 0.66911765], f1score: [0.87011807 0.71794872]\n",
      "macro:\n",
      "precision: 0.8081479265602214, recall: 0.7847467934542238, f1score_macro: 0.7940333962132328\n",
      " \n",
      "0.435\n",
      "precision: [0.83916084 0.77586207], recall: [0.90225564 0.66176471], f1score: [0.86956522 0.71428571]\n",
      "macro:\n",
      "precision: 0.8075114540631783, recall: 0.7820101724900486, f1score_macro: 0.7919254658385093\n",
      " \n",
      "0.44\n",
      "precision: [0.83916084 0.77586207], recall: [0.90225564 0.66176471], f1score: [0.86956522 0.71428571]\n",
      "macro:\n",
      "precision: 0.8075114540631783, recall: 0.7820101724900486, f1score_macro: 0.7919254658385093\n",
      " \n",
      "0.445\n",
      "precision: [0.83680556 0.78070175], recall: [0.90601504 0.65441176], f1score: [0.8700361 0.712    ]\n",
      "macro:\n",
      "precision: 0.8087536549707602, recall: 0.7802134011499336, f1score_macro: 0.7910180505415163\n",
      " \n",
      "0.45\n",
      "precision: [0.8362069  0.79017857], recall: [0.91165414 0.65073529], f1score: [0.87230216 0.71370968]\n",
      "macro:\n",
      "precision: 0.8131927339901477, recall: 0.7811947147279965, f1score_macro: 0.793005917846368\n",
      " \n",
      "0.455\n",
      "precision: [0.83505155 0.79279279], recall: [0.91353383 0.64705882], f1score: [0.87253142 0.71255061]\n",
      "macro:\n",
      "precision: 0.8139221695922727, recall: 0.780296329057939, f1score_macro: 0.7925410127999186\n",
      " \n",
      "0.46\n",
      "precision: [0.82993197 0.7962963 ], recall: [0.91729323 0.63235294], f1score: [0.87142857 0.70491803]\n",
      "macro:\n",
      "precision: 0.813114134542706, recall: 0.7748230871295887, f1score_macro: 0.7881733021077283\n",
      " \n",
      "0.465\n",
      "precision: [0.82993197 0.7962963 ], recall: [0.91729323 0.63235294], f1score: [0.87142857 0.70491803]\n",
      "macro:\n",
      "precision: 0.813114134542706, recall: 0.7748230871295887, f1score_macro: 0.7881733021077283\n",
      " \n",
      "0.47000000000000003\n",
      "precision: [0.8277027  0.80188679], recall: [0.92105263 0.625     ], f1score: [0.87188612 0.70247934]\n",
      "macro:\n",
      "precision: 0.8147947475777665, recall: 0.7730263157894737, f1score_macro: 0.7871827299197083\n",
      " \n",
      "0.47500000000000003\n",
      "precision: [0.82659933 0.8047619 ], recall: [0.92293233 0.62132353], f1score: [0.87211368 0.70124481]\n",
      "macro:\n",
      "precision: 0.8156806156806157, recall: 0.7721279301194162, f1score_macro: 0.7866792450049012\n",
      " \n",
      "0.48000000000000004\n",
      "precision: [0.82136895 0.80487805], recall: [0.92481203 0.60661765], f1score: [0.87002653 0.6918239 ]\n",
      "macro:\n",
      "precision: 0.8131234985137832, recall: 0.7657148385670057, f1score_macro: 0.780925212285004\n",
      " \n",
      "0.485\n",
      "precision: [0.81863561 0.80295567], recall: [0.92481203 0.59926471], f1score: [0.86849073 0.68631579]\n",
      "macro:\n",
      "precision: 0.810795636172881, recall: 0.7620383679787704, f1score_macro: 0.7774032610210433\n",
      " \n",
      "0.49\n",
      "precision: [0.81757877 0.80597015], recall: [0.92669173 0.59558824], f1score: [0.86872247 0.68498943]\n",
      "macro:\n",
      "precision: 0.8117744610281924, recall: 0.7611399823087129, f1score_macro: 0.776855948067914\n",
      " \n",
      "0.495\n",
      "precision: [0.81788079 0.81      ], recall: [0.92857143 0.59558824], f1score: [0.86971831 0.68644068]\n",
      "macro:\n",
      "precision: 0.8139403973509933, recall: 0.7620798319327731, f1score_macro: 0.7780794939126283\n",
      " \n",
      "0.5\n",
      "precision: [0.81609195 0.82051282], recall: [0.93421053 0.58823529], f1score: [0.87116564 0.68522484]\n",
      "macro:\n",
      "precision: 0.8183023872679045, recall: 0.7612229102167183, f1score_macro: 0.7781952417861038\n",
      " \n",
      "0.505\n",
      "precision: [0.81609195 0.82051282], recall: [0.93421053 0.58823529], f1score: [0.87116564 0.68522484]\n",
      "macro:\n",
      "precision: 0.8183023872679045, recall: 0.7612229102167183, f1score_macro: 0.7781952417861038\n",
      " \n",
      "0.51\n",
      "precision: [0.81239804 0.82198953], recall: [0.93609023 0.57720588], f1score: [0.869869   0.67818575]\n",
      "macro:\n",
      "precision: 0.8171937856050836, recall: 0.7566480539584255, f1score_macro: 0.7740273703867883\n",
      " \n",
      "0.515\n",
      "precision: [0.81168831 0.82978723], recall: [0.93984962 0.57352941], f1score: [0.87108014 0.67826087]\n",
      "macro:\n",
      "precision: 0.8207377728654324, recall: 0.7566895179124281, f1score_macro: 0.7746705044690199\n",
      " \n",
      "0.52\n",
      "precision: [0.80906149 0.82795699], recall: [0.93984962 0.56617647], f1score: [0.86956522 0.67248908]\n",
      "macro:\n",
      "precision: 0.8185092389602255, recall: 0.7530130473241928, f1score_macro: 0.7710271501803685\n",
      " \n",
      "0.525\n",
      "precision: [0.80775444 0.82702703], recall: [0.93984962 0.5625    ], f1score: [0.86880973 0.66958425]\n",
      "macro:\n",
      "precision: 0.8173907348382308, recall: 0.7511748120300752, f1score_macro: 0.7691969878727849\n",
      " \n",
      "0.53\n",
      "precision: [0.80546624 0.82967033], recall: [0.94172932 0.55514706], f1score: [0.86828423 0.66519824]\n",
      "macro:\n",
      "precision: 0.8175682838062259, recall: 0.7484381910659, f1score_macro: 0.7667412333274799\n",
      " \n",
      "0.535\n",
      "precision: [0.8048     0.83798883], recall: [0.94548872 0.55147059], f1score: [0.86949006 0.66518847]\n",
      "macro:\n",
      "precision: 0.8213944134078213, recall: 0.7484796550199027, f1score_macro: 0.7673392652839077\n",
      " \n",
      "0.54\n",
      "precision: [0.80351438 0.83707865], recall: [0.94548872 0.54779412], f1score: [0.86873921 0.66222222]\n",
      "macro:\n",
      "precision: 0.8202965143410992, recall: 0.7466414197257851, f1score_macro: 0.7654807138744963\n",
      " \n",
      "0.545\n",
      "precision: [0.80351438 0.83707865], recall: [0.94548872 0.54779412], f1score: [0.86873921 0.66222222]\n",
      "macro:\n",
      "precision: 0.8202965143410992, recall: 0.7466414197257851, f1score_macro: 0.7654807138744963\n",
      " \n",
      "0.55\n",
      "precision: [0.80223285 0.83615819], recall: [0.94548872 0.54411765], f1score: [0.86798965 0.65924276]\n",
      "macro:\n",
      "precision: 0.8191955234774146, recall: 0.7448031844316674, f1score_macro: 0.7636162039697074\n",
      " \n",
      "0.555\n",
      "precision: [0.79968203 0.83428571], recall: [0.94548872 0.53676471], f1score: [0.8664944  0.65324385]\n",
      "macro:\n",
      "precision: 0.8169838746309335, recall: 0.7411267138434321, f1score_macro: 0.7598691246264213\n",
      " \n",
      "0.56\n",
      "precision: [0.79685039 0.84615385], recall: [0.95112782 0.52573529], f1score: [0.86718081 0.64852608]\n",
      "macro:\n",
      "precision: 0.8215021199273167, recall: 0.7384315568332596, f1score_macro: 0.7578534412908265\n",
      " \n",
      "0.5650000000000001\n",
      "precision: [0.79559748 0.8452381 ], recall: [0.95112782 0.52205882], f1score: [0.86643836 0.64545455]\n",
      "macro:\n",
      "precision: 0.8204177897574124, recall: 0.736593321539142, f1score_macro: 0.7559464508094647\n",
      " \n",
      "0.5700000000000001\n",
      "precision: [0.7921875  0.84756098], recall: [0.95300752 0.51102941], f1score: [0.86518771 0.63761468]\n",
      "macro:\n",
      "precision: 0.819874237804878, recall: 0.7320184652808492, f1score_macro: 0.7514011961048315\n",
      " \n",
      "0.5750000000000001\n",
      "precision: [0.79160187 0.85714286], recall: [0.95676692 0.50735294], f1score: [0.86638298 0.63741339]\n",
      "macro:\n",
      "precision: 0.8243723616974006, recall: 0.7320599292348517, f1score_macro: 0.7518981868212864\n",
      " \n",
      "0.5800000000000001\n",
      "precision: [0.79037267 0.85625   ], recall: [0.95676692 0.50367647], f1score: [0.86564626 0.63425926]\n",
      "macro:\n",
      "precision: 0.8233113354037267, recall: 0.7302216939407342, f1score_macro: 0.7499527588813303\n",
      " \n",
      "0.585\n",
      "precision: [0.79069767 0.86163522], recall: [0.95864662 0.50367647], f1score: [0.86661003 0.63573086]\n",
      "macro:\n",
      "precision: 0.8261664472721955, recall: 0.7311615435647943, f1score_macro: 0.7511704419786038\n",
      " \n",
      "0.59\n",
      "precision: [0.78947368 0.86075949], recall: [0.95864662 0.5       ], f1score: [0.86587436 0.63255814]\n",
      "macro:\n",
      "precision: 0.8251165889407062, recall: 0.7293233082706767, f1score_macro: 0.7492162514312788\n",
      " \n",
      "0.595\n",
      "precision: [0.78461538 0.85714286], recall: [0.95864662 0.48529412], f1score: [0.86294416 0.61971831]\n",
      "macro:\n",
      "precision: 0.8208791208791208, recall: 0.7219703670942061, f1score_macro: 0.7413312361478516\n",
      " \n",
      "0.6\n",
      "precision: [0.78341014 0.85620915], recall: [0.95864662 0.48161765], f1score: [0.86221471 0.61647059]\n",
      "macro:\n",
      "precision: 0.8198096442878227, recall: 0.7201321318000885, f1score_macro: 0.7393426483019243\n",
      " \n",
      "0.605\n",
      "precision: [0.78254211 0.86092715], recall: [0.96052632 0.47794118], f1score: [0.86244726 0.61465721]\n",
      "macro:\n",
      "precision: 0.8217346328205024, recall: 0.719233746130031, f1score_macro: 0.7385522338929288\n",
      " \n",
      "0.61\n",
      "precision: [0.77896341 0.85810811], recall: [0.96052632 0.46691176], f1score: [0.86026936 0.6047619 ]\n",
      "macro:\n",
      "precision: 0.8185357613711273, recall: 0.7137190402476781, f1score_macro: 0.7325156325156325\n",
      " \n",
      "0.615\n",
      "precision: [0.77896341 0.85810811], recall: [0.96052632 0.46691176], f1score: [0.86026936 0.6047619 ]\n",
      "macro:\n",
      "precision: 0.8185357613711273, recall: 0.7137190402476781, f1score_macro: 0.7325156325156325\n",
      " \n",
      "0.62\n",
      "precision: [0.77929985 0.86394558], recall: [0.96240602 0.46691176], f1score: [0.86122792 0.60620525]\n",
      "macro:\n",
      "precision: 0.8216227130121454, recall: 0.7146588898717381, f1score_macro: 0.7337165866103562\n",
      " \n",
      "0.625\n",
      "precision: [0.77929985 0.86394558], recall: [0.96240602 0.46691176], f1score: [0.86122792 0.60620525]\n",
      "macro:\n",
      "precision: 0.8216227130121454, recall: 0.7146588898717381, f1score_macro: 0.7337165866103562\n",
      " \n",
      "0.63\n",
      "precision: [0.77929985 0.86394558], recall: [0.96240602 0.46691176], f1score: [0.86122792 0.60620525]\n",
      "macro:\n",
      "precision: 0.8216227130121454, recall: 0.7146588898717381, f1score_macro: 0.7337165866103562\n",
      " \n",
      "0.635\n",
      "precision: [0.77693475 0.86206897], recall: [0.96240602 0.45955882], f1score: [0.8597817  0.59952038]\n",
      "macro:\n",
      "precision: 0.8195018575689393, recall: 0.7109824192835028, f1score_macro: 0.729651039873391\n",
      " \n",
      "0.64\n",
      "precision: [0.77458396 0.86013986], recall: [0.96240602 0.45220588], f1score: [0.85834032 0.59277108]\n",
      "macro:\n",
      "precision: 0.8173619119156184, recall: 0.7073059486952675, f1score_macro: 0.7255557014310385\n",
      " \n",
      "0.645\n",
      "precision: [0.77458396 0.86013986], recall: [0.96240602 0.45220588], f1score: [0.85834032 0.59277108]\n",
      "macro:\n",
      "precision: 0.8173619119156184, recall: 0.7073059486952675, f1score_macro: 0.7255557014310385\n",
      " \n",
      "0.65\n",
      "precision: [0.76992481 0.85611511], recall: [0.96240602 0.4375    ], f1score: [0.85547201 0.57907543]\n",
      "macro:\n",
      "precision: 0.8130199599718722, recall: 0.699953007518797, f1score_macro: 0.7172737195787522\n",
      " \n",
      "0.655\n",
      "precision: [0.77061469 0.86861314], recall: [0.96616541 0.4375    ], f1score: [0.85738115 0.58190709]\n",
      "macro:\n",
      "precision: 0.8196139156699023, recall: 0.7018327067669172, f1score_macro: 0.7196441207118403\n",
      " \n",
      "0.66\n",
      "precision: [0.77061469 0.86861314], recall: [0.96616541 0.4375    ], f1score: [0.85738115 0.58190709]\n",
      "macro:\n",
      "precision: 0.8196139156699023, recall: 0.7018327067669172, f1score_macro: 0.7196441207118403\n",
      " \n",
      "0.665\n",
      "precision: [0.76831091 0.86666667], recall: [0.96616541 0.43014706], f1score: [0.85595337 0.57493857]\n",
      "macro:\n",
      "precision: 0.8174887892376681, recall: 0.6981562361786819, f1score_macro: 0.7154459735642082\n",
      " \n",
      "0.67\n",
      "precision: [0.76602086 0.86466165], recall: [0.96616541 0.42279412], f1score: [0.85453034 0.56790123]\n",
      "macro:\n",
      "precision: 0.8153412592584293, recall: 0.6944797655904467, f1score_macro: 0.7112157876912657\n",
      " \n",
      "0.675\n",
      "precision: [0.76374443 0.86259542], recall: [0.96616541 0.41544118], f1score: [0.85311203 0.56079404]\n",
      "macro:\n",
      "precision: 0.8131699238909746, recall: 0.6908032950022114, f1score_macro: 0.7069530389300167\n",
      " \n",
      "0.68\n",
      "precision: [0.76261128 0.86153846], recall: [0.96616541 0.41176471], f1score: [0.85240464 0.55721393]\n",
      "macro:\n",
      "precision: 0.8120748687514266, recall: 0.6889650597080937, f1score_macro: 0.7048092868988391\n",
      " \n",
      "0.685\n",
      "precision: [0.76148148 0.86046512], recall: [0.96616541 0.40808824], f1score: [0.85169843 0.55361596]\n",
      "macro:\n",
      "precision: 0.8109732988802756, recall: 0.6871268244139761, f1score_macro: 0.7026571929744818\n",
      " \n",
      "0.6900000000000001\n",
      "precision: [0.76218612 0.87401575], recall: [0.96992481 0.40808824], f1score: [0.85359801 0.55639098]\n",
      "macro:\n",
      "precision: 0.8181009316228381, recall: 0.6890065236620964, f1score_macro: 0.7049944961659732\n",
      " \n",
      "0.6950000000000001\n",
      "precision: [0.76029412 0.87903226], recall: [0.97180451 0.40073529], f1score: [0.85313531 0.55050505]\n",
      "macro:\n",
      "precision: 0.8196631878557874, recall: 0.6862699026979213, f1score_macro: 0.7018201820182017\n",
      " \n",
      "0.7000000000000001\n",
      "precision: [0.75620438 0.88235294], recall: [0.97368421 0.38602941], f1score: [0.85127362 0.5370844 ]\n",
      "macro:\n",
      "precision: 0.8192786603692572, recall: 0.6798568111455109, f1score_macro: 0.6941790113208657\n",
      " \n",
      "0.7050000000000001\n",
      "precision: [0.75436047 0.88793103], recall: [0.97556391 0.37867647], f1score: [0.85081967 0.53092784]\n",
      "macro:\n",
      "precision: 0.8211457497995189, recall: 0.6771201901813357, f1score_macro: 0.690873753591347\n",
      " \n",
      "0.71\n",
      "precision: [0.7532656  0.88695652], recall: [0.97556391 0.375     ], f1score: [0.85012285 0.52713178]\n",
      "macro:\n",
      "precision: 0.8201110620306682, recall: 0.675281954887218, f1score_macro: 0.6886273165342933\n",
      " \n",
      "0.715\n",
      "precision: [0.75217391 0.88596491], recall: [0.97556391 0.37132353], f1score: [0.84942717 0.52331606]\n",
      "macro:\n",
      "precision: 0.81906941266209, recall: 0.6734437195931005, f1score_macro: 0.6863716153761352\n",
      " \n",
      "0.72\n",
      "precision: [0.75108538 0.88495575], recall: [0.97556391 0.36764706], f1score: [0.84873262 0.51948052]\n",
      "macro:\n",
      "precision: 0.8180205678572801, recall: 0.6716054842989827, f1score_macro: 0.6841065720869483\n",
      " \n",
      "0.725\n",
      "precision: [0.74891775 0.88288288], recall: [0.97556391 0.36029412], f1score: [0.84734694 0.51174935]\n",
      "macro:\n",
      "precision: 0.8159003159003159, recall: 0.6679290137107474, f1score_macro: 0.6795481430169978\n",
      " \n",
      "0.73\n",
      "precision: [0.74712644 0.88888889], recall: [0.97744361 0.35294118], f1score: [0.84690554 0.50526316]\n",
      "macro:\n",
      "precision: 0.8180076628352491, recall: 0.6651923927465723, f1score_macro: 0.6760843476770102\n",
      " \n",
      "0.735\n",
      "precision: [0.7453505 0.8952381], recall: [0.97932331 0.34558824], f1score: [0.84646629 0.49867374]\n",
      "macro:\n",
      "precision: 0.8202942979767014, recall: 0.6624557717823971, f1score_macro: 0.6725700138120654\n",
      " \n",
      "0.74\n",
      "precision: [0.74253201 0.9009901 ], recall: [0.98120301 0.33455882], f1score: [0.84534413 0.48793566]\n",
      "macro:\n",
      "precision: 0.8217610523499007, recall: 0.6578809155241043, f1score_macro: 0.6666398931955585\n",
      " \n",
      "0.745\n",
      "precision: [0.73937677 0.89795918], recall: [0.98120301 0.32352941], f1score: [0.84329564 0.47567568]\n",
      "macro:\n",
      "precision: 0.8186679771058565, recall: 0.6523662096417514, f1score_macro: 0.6594856569008427\n",
      " \n",
      "0.75\n",
      "precision: [0.73521127 0.89361702], recall: [0.98120301 0.30882353], f1score: [0.84057971 0.45901639]\n",
      "macro:\n",
      "precision: 0.8144141444411148, recall: 0.6450132684652808, f1score_macro: 0.6497980517937753\n",
      " \n",
      "0.755\n",
      "precision: [0.73314607 0.89130435], recall: [0.98120301 0.30147059], f1score: [0.8392283  0.45054945]\n",
      "macro:\n",
      "precision: 0.8122252076209087, recall: 0.6413367978770456, f1score_macro: 0.6448888731846931\n",
      " \n",
      "0.76\n",
      "precision: [0.72299169 0.87804878], recall: [0.98120301 0.26470588], f1score: [0.83253589 0.40677966]\n",
      "macro:\n",
      "precision: 0.8005202351192486, recall: 0.622954444935869, f1score_macro: 0.6196577730922066\n",
      " \n",
      "0.765\n",
      "precision: [0.72237569 0.8875    ], recall: [0.98308271 0.26102941], f1score: [0.83280255 0.40340909]\n",
      "macro:\n",
      "precision: 0.8049378453038674, recall: 0.6220560592658116, f1score_macro: 0.6181058193398958\n",
      " \n",
      "0.77\n",
      "precision: [0.72137931 0.88607595], recall: [0.98308271 0.25735294], f1score: [0.83214002 0.3988604 ]\n",
      "macro:\n",
      "precision: 0.8037276298559581, recall: 0.620217823971694, f1score_macro: 0.615500207385649\n",
      " \n",
      "0.775\n",
      "precision: [0.71840659 0.88157895], recall: [0.98308271 0.24632353], f1score: [0.83015873 0.38505747]\n",
      "macro:\n",
      "precision: 0.7999927703875072, recall: 0.614703118089341, f1score_macro: 0.607608100711549\n",
      " \n",
      "0.78\n",
      "precision: [0.71545828 0.87671233], recall: [0.98308271 0.23529412], f1score: [0.82818686 0.37101449]\n",
      "macro:\n",
      "precision: 0.7960853025504563, recall: 0.609188412206988, f1score_macro: 0.5996006747220215\n",
      " \n",
      "0.785\n",
      "precision: [0.71350614 0.87323944], recall: [0.98308271 0.22794118], f1score: [0.82687747 0.36151603]\n",
      "macro:\n",
      "precision: 0.7933727878869397, recall: 0.6055119416187528, f1score_macro: 0.5941967526705769\n",
      " \n",
      "0.79\n",
      "precision: [0.71156463 0.86956522], recall: [0.98308271 0.22058824], f1score: [0.82557222 0.35190616]\n",
      "macro:\n",
      "precision: 0.7905649216208221, recall: 0.6018354710305175, f1score_macro: 0.5887391880975912\n",
      " \n",
      "0.795\n",
      "precision: [0.71059783 0.86764706], recall: [0.98308271 0.21691176], f1score: [0.82492114 0.34705882]\n",
      "macro:\n",
      "precision: 0.789122442455243, recall: 0.5999972357363998, f1score_macro: 0.5859899795880498\n",
      " \n",
      "0.8\n",
      "precision: [0.70963365 0.86567164], recall: [0.98308271 0.21323529], f1score: [0.82427108 0.34218289]\n",
      "macro:\n",
      "precision: 0.7876526458616011, recall: 0.5981590004422822, f1score_macro: 0.5832269852228429\n",
      " \n",
      "0.805\n",
      "precision: [0.70906631 0.87692308], recall: [0.98496241 0.20955882], f1score: [0.8245476  0.33827893]\n",
      "macro:\n",
      "precision: 0.7929946913708754, recall: 0.5972606147722247, f1score_macro: 0.5814132660327274\n",
      " \n",
      "0.81\n",
      "precision: [0.70564516 0.88333333], recall: [0.98684211 0.19485294], f1score: [0.82288401 0.31927711]\n",
      "macro:\n",
      "precision: 0.7944892473118279, recall: 0.5908475232198143, f1score_macro: 0.5710805604864599\n",
      " \n",
      "0.8150000000000001\n",
      "precision: [0.70375335 0.87931034], recall: [0.98684211 0.1875    ], f1score: [0.82159624 0.30909091]\n",
      "macro:\n",
      "precision: 0.7915318480170103, recall: 0.587171052631579, f1score_macro: 0.5653435766111822\n",
      " \n",
      "0.8200000000000001\n",
      "precision: [0.70320856 0.89285714], recall: [0.9887218  0.18382353], f1score: [0.821875   0.30487805]\n",
      "macro:\n",
      "precision: 0.7980328495034378, recall: 0.5862726669615215, f1score_macro: 0.5633765243902439\n",
      " \n",
      "0.8250000000000001\n",
      "precision: [0.70320856 0.89285714], recall: [0.9887218  0.18382353], f1score: [0.821875   0.30487805]\n",
      "macro:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7980328495034378, recall: 0.5862726669615215, f1score_macro: 0.5633765243902439\n",
      " \n",
      "0.8300000000000001\n",
      "precision: [0.70133333 0.88888889], recall: [0.9887218  0.17647059], f1score: [0.82059282 0.29447853]\n",
      "macro:\n",
      "precision: 0.7951111111111111, recall: 0.5825961963732862, f1score_macro: 0.5575356756601553\n",
      " \n",
      "0.8350000000000001\n",
      "precision: [0.69853918 0.88235294], recall: [0.9887218  0.16544118], f1score: [0.81867704 0.27863777]\n",
      "macro:\n",
      "precision: 0.7904460589016483, recall: 0.5770814904909333, f1score_macro: 0.5486574068496947\n",
      " \n",
      "0.84\n",
      "precision: [0.6957672 0.875    ], recall: [0.9887218  0.15441176], f1score: [0.81677019 0.2625    ]\n",
      "macro:\n",
      "precision: 0.7853835978835979, recall: 0.5715667846085803, f1score_macro: 0.5396350931677019\n",
      " \n",
      "0.845\n",
      "precision: [0.69342105 0.88636364], recall: [0.9906015  0.14338235], f1score: [0.81578947 0.24683544]\n",
      "macro:\n",
      "precision: 0.7898923444976076, recall: 0.5669919283502874, f1score_macro: 0.5313124583610925\n",
      " \n",
      "0.85\n",
      "precision: [0.69342105 0.88636364], recall: [0.9906015  0.14338235], f1score: [0.81578947 0.24683544]\n",
      "macro:\n",
      "precision: 0.7898923444976076, recall: 0.5669919283502874, f1score_macro: 0.5313124583610925\n",
      " \n",
      "0.855\n",
      "precision: [0.68709257 0.86486486], recall: [0.9906015  0.11764706], f1score: [0.81139338 0.20711974]\n",
      "macro:\n",
      "precision: 0.7759787166566827, recall: 0.554124281291464, f1score_macro: 0.5092565603115168\n",
      " \n",
      "0.86\n",
      "precision: [0.68441558 0.85294118], recall: [0.9906015  0.10661765], f1score: [0.80952381 0.18954248]\n",
      "macro:\n",
      "precision: 0.7686783804430863, recall: 0.548609575409111, f1score_macro: 0.4995331465919701\n",
      " \n",
      "0.865\n",
      "precision: [0.68258065 0.89655172], recall: [0.9943609  0.09558824], f1score: [0.80948738 0.17275748]\n",
      "macro:\n",
      "precision: 0.7895661846496107, recall: 0.5449745687748784, f1score_macro: 0.4911224253762643\n",
      " \n",
      "0.87\n",
      "precision: [0.67948718 0.91666667], recall: [0.9962406  0.08088235], f1score: [0.80792683 0.14864865]\n",
      "macro:\n",
      "precision: 0.7980769230769231, recall: 0.5385614772224679, f1score_macro: 0.4782877389584707\n",
      " \n",
      "0.875\n",
      "precision: [0.67602041 0.9       ], recall: [0.9962406  0.06617647], f1score: [0.80547112 0.12328767]\n",
      "macro:\n",
      "precision: 0.7880102040816326, recall: 0.5312085360459974, f1score_macro: 0.46437939792646876\n",
      " \n",
      "0.88\n",
      "precision: [0.67385787 0.9375    ], recall: [0.9981203  0.05514706], f1score: [0.80454545 0.10416667]\n",
      "macro:\n",
      "precision: 0.8056789340101522, recall: 0.5266336797877046, f1score_macro: 0.4543560606060606\n",
      " \n",
      "0.885\n",
      "precision: [0.67130215 0.92307692], recall: [0.9981203  0.04411765], f1score: [0.80272109 0.08421053]\n",
      "macro:\n",
      "precision: 0.7971895361275892, recall: 0.5211189739053517, f1score_macro: 0.44346580737558183\n",
      " \n",
      "0.89\n",
      "precision: [0.67045455 0.91666667], recall: [0.9981203  0.04044118], f1score: [0.8021148  0.07746479]\n",
      "macro:\n",
      "precision: 0.793560606060606, recall: 0.519280738611234, f1score_macro: 0.43978979617888597\n",
      " \n",
      "0.895\n",
      "precision: [0.67045455 0.91666667], recall: [0.9981203  0.04044118], f1score: [0.8021148  0.07746479]\n",
      "macro:\n",
      "precision: 0.793560606060606, recall: 0.519280738611234, f1score_macro: 0.43978979617888597\n",
      " \n",
      "0.9\n",
      "precision: [0.67045455 0.91666667], recall: [0.9981203  0.04044118], f1score: [0.8021148  0.07746479]\n",
      "macro:\n",
      "precision: 0.793560606060606, recall: 0.519280738611234, f1score_macro: 0.43978979617888597\n",
      " \n",
      "macro 0.7949005203659865\n",
      "F1-valued: 0.7201565557729941\n",
      "recall-valued: 0.6764705882352942\n",
      "0.42000000000000004\n"
     ]
    }
   ],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_predict:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "df433a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.84424779 0.76987448], recall: [0.89661654 0.67647059], f1score: [0.86964448 0.72015656]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4c96e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8070611322990335, recall: 0.7865435647943388, f1score_macro: 0.7949005203659865\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b595e",
   "metadata": {},
   "source": [
    "# LogitBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "891d536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c7c8b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('LogitBoost', LogitBoost())]\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps) # define the pipeline object.\n",
    "\n",
    "parameteres = {'LogitBoost__n_estimators':range(10,100,10)}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "78169602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(804, 1024)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_test['cls'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "83fc3255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogitBoost</label><div class=\"sk-toggleable__content\"><pre>LogitBoost()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('LogitBoost', LogitBoost())]),\n",
       "             param_grid={'LogitBoost__n_estimators': range(10, 100, 10)})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(embs['cls'], df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7dde61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from gridsearch: {'LogitBoost__n_estimators': 50}\n",
      "CV score=0.714\n",
      "{'mean_fit_time': array([ 3.73461342,  7.4055469 , 10.97259603, 14.7951643 , 19.09631443,\n",
      "       22.78958521, 25.92236528, 30.04713492, 32.93792868]), 'std_fit_time': array([0.06701074, 0.16823047, 0.20264273, 0.35731802, 0.60867683,\n",
      "       0.5151093 , 0.40347909, 0.57965765, 0.52679355]), 'mean_score_time': array([0.00888124, 0.0151794 , 0.02140398, 0.02689648, 0.03915634,\n",
      "       0.04470406, 0.05560169, 0.06649499, 0.06598163]), 'std_score_time': array([0.00147477, 0.00141773, 0.00223581, 0.00042711, 0.00533535,\n",
      "       0.0096013 , 0.00942776, 0.01159643, 0.0103816 ]), 'param_LogitBoost__n_estimators': masked_array(data=[10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'LogitBoost__n_estimators': 10}, {'LogitBoost__n_estimators': 20}, {'LogitBoost__n_estimators': 30}, {'LogitBoost__n_estimators': 40}, {'LogitBoost__n_estimators': 50}, {'LogitBoost__n_estimators': 60}, {'LogitBoost__n_estimators': 70}, {'LogitBoost__n_estimators': 80}, {'LogitBoost__n_estimators': 90}], 'split0_test_score': array([0.76464747, 0.76564052, 0.76067527, 0.75471698, 0.76464747,\n",
      "       0.75670308, 0.75868918, 0.75372393, 0.75372393]), 'split1_test_score': array([0.60575968, 0.60476663, 0.61271102, 0.61171797, 0.61370407,\n",
      "       0.60973188, 0.61072493, 0.61072493, 0.61370407]), 'split2_test_score': array([0.71996028, 0.72393247, 0.72492552, 0.72691162, 0.72691162,\n",
      "       0.73485601, 0.73088381, 0.72889772, 0.72989076]), 'split3_test_score': array([0.75868918, 0.76365442, 0.77656405, 0.77159881, 0.77259186,\n",
      "       0.77457795, 0.76564052, 0.77656405, 0.76961271]), 'split4_test_score': array([0.68619662, 0.68718967, 0.68321748, 0.67428004, 0.69116187,\n",
      "       0.6673287 , 0.67626614, 0.67924528, 0.68123138]), 'mean_test_score': array([0.70705065, 0.70903674, 0.71161867, 0.70784508, 0.71380338,\n",
      "       0.70863952, 0.70844091, 0.70983118, 0.70963257]), 'std_test_score': array([0.05804367, 0.05959616, 0.05897606, 0.05829593, 0.05787148,\n",
      "       0.06137523, 0.05811023, 0.05916237, 0.05649949]), 'rank_test_score': array([9, 5, 2, 8, 1, 6, 7, 3, 4], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(grid.best_params_))\n",
    "print(\"CV score=%0.3f\" % grid.best_score_)\n",
    "cv_results = grid.cv_results_\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d4a87253",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict_proba(emb_test['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "31b5dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "precision: [0.94736842 0.34522293], recall: [0.03383459 0.99632353], f1score: [0.06533575 0.512772  ]\n",
      "macro:\n",
      "precision: 0.6462956754944686, recall: 0.515079057938965, f1score_macro: 0.28905387469587424\n",
      " \n",
      "0.01\n",
      "precision: [0.95833333 0.35714286], recall: [0.08646617 0.99264706], f1score: [0.15862069 0.52529183]\n",
      "macro:\n",
      "precision: 0.6577380952380952, recall: 0.5395566121185317, f1score_macro: 0.34195625922447337\n",
      " \n",
      "0.015\n",
      "precision: [0.93055556 0.3647541 ], recall: [0.12593985 0.98161765], f1score: [0.2218543  0.53187251]\n",
      "macro:\n",
      "precision: 0.6476548269581057, recall: 0.5537787483414418, f1score_macro: 0.3768634072979605\n",
      " \n",
      "0.02\n",
      "precision: [0.94845361 0.37765205], recall: [0.17293233 0.98161765], f1score: [0.29252782 0.54545455]\n",
      "macro:\n",
      "precision: 0.6630528295834002, recall: 0.5772749889429456, f1score_macro: 0.4189911836970661\n",
      " \n",
      "0.025\n",
      "precision: [0.94214876 0.38799414], recall: [0.21428571 0.97426471], f1score: [0.34915773 0.55497382]\n",
      "macro:\n",
      "precision: 0.6650714519076025, recall: 0.5942752100840336, f1score_macro: 0.4520657777635239\n",
      " \n",
      "0.030000000000000002\n",
      "precision: [0.93939394 0.39285714], recall: [0.23308271 0.97058824], f1score: [0.37349398 0.55932203]\n",
      "macro:\n",
      "precision: 0.6661255411255411, recall: 0.6018354710305175, f1score_macro: 0.46640800490095974\n",
      " \n",
      "0.034999999999999996\n",
      "precision: [0.94871795 0.40740741], recall: [0.27819549 0.97058824], f1score: [0.43023256 0.57391304]\n",
      "macro:\n",
      "precision: 0.6780626780626781, recall: 0.624391862007961, f1score_macro: 0.5020728008088979\n",
      " \n",
      "0.04\n",
      "precision: [0.94117647 0.41324921], recall: [0.30075188 0.96323529], f1score: [0.45584046 0.57836645]\n",
      "macro:\n",
      "precision: 0.677212840972351, recall: 0.6319935869084476, f1score_macro: 0.5171034508782852\n",
      " \n",
      "0.045\n",
      "precision: [0.94240838 0.42577488], recall: [0.33834586 0.95955882], f1score: [0.49792531 0.58983051]\n",
      "macro:\n",
      "precision: 0.684091627307124, recall: 0.6489523440955329, f1score_macro: 0.5438779098389479\n",
      " \n",
      "0.049999999999999996\n",
      "precision: [0.93719807 0.43383585], recall: [0.36466165 0.95220588], f1score: [0.52503383 0.59608746]\n",
      "macro:\n",
      "precision: 0.6855169567644989, recall: 0.6584337682441397, f1score_macro: 0.5605606431731369\n",
      " \n",
      "0.055\n",
      "precision: [0.92342342 0.43814433], recall: [0.38533835 0.9375    ], f1score: [0.54376658 0.5971897 ]\n",
      "macro:\n",
      "precision: 0.6807838766601653, recall: 0.6614191729323309, f1score_macro: 0.5704781368998442\n",
      " \n",
      "0.06\n",
      "precision: [0.92703863 0.44658494], recall: [0.40601504 0.9375    ], f1score: [0.56470588 0.60498221]\n",
      "macro:\n",
      "precision: 0.686811782656735, recall: 0.6717575187969924, f1score_macro: 0.5848440443793176\n",
      " \n",
      "0.065\n",
      "precision: [0.92561983 0.4519573 ], recall: [0.42105263 0.93382353], f1score: [0.57881137 0.60911271]\n",
      "macro:\n",
      "precision: 0.6887885650422046, recall: 0.677438080495356, f1score_macro: 0.5939620396705891\n",
      " \n",
      "0.07\n",
      "precision: [0.92682927 0.45519713], recall: [0.42857143 0.93382353], f1score: [0.58611825 0.61204819]\n",
      "macro:\n",
      "precision: 0.6910132004545853, recall: 0.6811974789915967, f1score_macro: 0.5990832223495526\n",
      " \n",
      "0.07500000000000001\n",
      "precision: [0.92635659 0.46336996], recall: [0.44924812 0.93014706], f1score: [0.60506329 0.61858191]\n",
      "macro:\n",
      "precision: 0.6948632762586251, recall: 0.6896975895621407, f1score_macro: 0.6118225991148525\n",
      " \n",
      "0.08\n",
      "precision: [0.91851852 0.46816479], recall: [0.46616541 0.91911765], f1score: [0.61845387 0.62034739]\n",
      "macro:\n",
      "precision: 0.6933416562630046, recall: 0.692641530296329, f1score_macro: 0.6194006299388006\n",
      " \n",
      "0.085\n",
      "precision: [0.91166078 0.47408829], recall: [0.48496241 0.90808824], f1score: [0.63312883 0.62295082]\n",
      "macro:\n",
      "precision: 0.6928745345659001, recall: 0.6965253206545776, f1score_macro: 0.6280398270139796\n",
      " \n",
      "0.09000000000000001\n",
      "precision: [0.91245791 0.4852071 ], recall: [0.5093985  0.90441176], f1score: [0.65379976 0.63157895]\n",
      "macro:\n",
      "precision: 0.6988325065248142, recall: 0.7069051304732419, f1score_macro: 0.6426893530569487\n",
      " \n",
      "0.095\n",
      "precision: [0.91205212 0.49295775], recall: [0.52631579 0.90073529], f1score: [0.66746126 0.63719116]\n",
      "macro:\n",
      "precision: 0.7025049318713584, recall: 0.7135255417956656, f1score_macro: 0.6523262103780121\n",
      " \n",
      "0.1\n",
      "precision: [0.91401274 0.5       ], recall: [0.53947368 0.90073529], f1score: [0.678487   0.64304462]\n",
      "macro:\n",
      "precision: 0.7070063694267517, recall: 0.7201044891640866, f1score_macro: 0.660765808529253\n",
      " \n",
      "0.10500000000000001\n",
      "precision: [0.915625   0.50619835], recall: [0.55075188 0.90073529], f1score: [0.68779343 0.64814815]\n",
      "macro:\n",
      "precision: 0.7109116735537191, recall: 0.7257435869084476, f1score_macro: 0.6679707876890977\n",
      " \n",
      "0.11\n",
      "precision: [0.91743119 0.51362683], recall: [0.56390977 0.90073529], f1score: [0.69848661 0.65420561]\n",
      "macro:\n",
      "precision: 0.7155290135210509, recall: 0.7323225342768687, f1score_macro: 0.6763461099082828\n",
      " \n",
      "0.115\n",
      "precision: [0.91616766 0.51914894], recall: [0.57518797 0.89705882], f1score: [0.70669746 0.65768194]\n",
      "macro:\n",
      "precision: 0.7176583004204358, recall: 0.7361233967271119, f1score_macro: 0.6821897001425521\n",
      " \n",
      "0.12000000000000001\n",
      "precision: [0.91520468 0.52597403], recall: [0.58834586 0.89338235], f1score: [0.71624714 0.66212534]\n",
      "macro:\n",
      "precision: 0.7205893521682996, recall: 0.7408641088014154, f1score_macro: 0.689186240093778\n",
      " \n",
      "0.125\n",
      "precision: [0.91354467 0.52954048], recall: [0.59586466 0.88970588], f1score: [0.72127418 0.66392318]\n",
      "macro:\n",
      "precision: 0.721542574994167, recall: 0.7427852720035382, f1score_macro: 0.6925986788203955\n",
      " \n",
      "0.13\n",
      "precision: [0.91428571 0.53303965], recall: [0.60150376 0.88970588], f1score: [0.72562358 0.66666667]\n",
      "macro:\n",
      "precision: 0.7236626809314034, recall: 0.7456048208757187, f1score_macro: 0.6961451247165533\n",
      " \n",
      "0.135\n",
      "precision: [0.91242938 0.53555556], recall: [0.60714286 0.88602941], f1score: [0.72911964 0.66759003]\n",
      "macro:\n",
      "precision: 0.7239924670433144, recall: 0.7465861344537814, f1score_macro: 0.698354833263508\n",
      " \n",
      "0.14\n",
      "precision: [0.91160221 0.54298643], recall: [0.62030075 0.88235294], f1score: [0.73825503 0.67226891]\n",
      "macro:\n",
      "precision: 0.727294317642059, recall: 0.7513268465280849, f1score_macro: 0.7052619705600361\n",
      " \n",
      "0.14500000000000002\n",
      "precision: [0.9076087  0.54587156], recall: [0.62781955 0.875     ], f1score: [0.74222222 0.67231638]\n",
      "macro:\n",
      "precision: 0.7267401276426007, recall: 0.7514097744360902, f1score_macro: 0.7072693032015065\n",
      " \n",
      "0.15\n",
      "precision: [0.90691489 0.55373832], recall: [0.64097744 0.87132353], f1score: [0.75110132 0.67714286]\n",
      "macro:\n",
      "precision: 0.7303266056870152, recall: 0.7561504865103936, f1score_macro: 0.71412208936438\n",
      " \n",
      "0.155\n",
      "precision: [0.90314136 0.55687204], recall: [0.64849624 0.86397059], f1score: [0.75492341 0.67723343]\n",
      "macro:\n",
      "precision: 0.7300066995856183, recall: 0.756233414418399, f1score_macro: 0.7160784214807763\n",
      " \n",
      "0.16\n",
      "precision: [0.90180879 0.56115108], recall: [0.65601504 0.86029412], f1score: [0.75952122 0.67924528]\n",
      "macro:\n",
      "precision: 0.7314799323332032, recall: 0.7581545776205219, f1score_macro: 0.7193832508674318\n",
      " \n",
      "0.165\n",
      "precision: [0.9025641  0.56521739], recall: [0.66165414 0.86029412], f1score: [0.76355748 0.68221574]\n",
      "macro:\n",
      "precision: 0.7338907469342252, recall: 0.7609741264927024, f1score_macro: 0.7228866135856264\n",
      " \n",
      "0.17\n",
      "precision: [0.89974937 0.57283951], recall: [0.67481203 0.85294118], f1score: [0.77121375 0.68537666]\n",
      "macro:\n",
      "precision: 0.7362944398032117, recall: 0.7638766032728881, f1score_macro: 0.7282952052001708\n",
      " \n",
      "0.17500000000000002\n",
      "precision: [0.9009901 0.58     ], recall: [0.68421053 0.85294118], f1score: [0.77777778 0.69047619]\n",
      "macro:\n",
      "precision: 0.7404950495049505, recall: 0.7685758513931888, f1score_macro: 0.7341269841269842\n",
      " \n",
      "0.18000000000000002\n",
      "precision: [0.89705882 0.58080808], recall: [0.68796992 0.84558824], f1score: [0.7787234  0.68862275]\n",
      "macro:\n",
      "precision: 0.7389334521687463, recall: 0.7667790800530738, f1score_macro: 0.7336730793731685\n",
      " \n",
      "0.185\n",
      "precision: [0.89805825 0.58673469], recall: [0.69548872 0.84558824], f1score: [0.78389831 0.69277108]\n",
      "macro:\n",
      "precision: 0.7423964731523678, recall: 0.7705384785493145, f1score_macro: 0.7383346947110476\n",
      " \n",
      "0.19\n",
      "precision: [0.8939759  0.58611825], recall: [0.69736842 0.83823529], f1score: [0.78352693 0.68986384]\n",
      "macro:\n",
      "precision: 0.7400470777712391, recall: 0.7678018575851393, f1score_macro: 0.7366953849004819\n",
      " \n",
      "0.195\n",
      "precision: [0.89311164 0.5926893 ], recall: [0.70676692 0.83455882], f1score: [0.78908709 0.69312977]\n",
      "macro:\n",
      "precision: 0.742900466997017, recall: 0.7706628704113224, f1score_macro: 0.7411084321908316\n",
      " \n",
      "0.2\n",
      "precision: [0.89227166 0.5994695 ], recall: [0.71616541 0.83088235], f1score: [0.79457769 0.69645609]\n",
      "macro:\n",
      "precision: 0.745870579392343, recall: 0.7735238832375055, f1score_macro: 0.7455168856876143\n",
      " \n",
      "0.20500000000000002\n",
      "precision: [0.89170507 0.60810811], recall: [0.72744361 0.82720588], f1score: [0.80124224 0.70093458]\n",
      "macro:\n",
      "precision: 0.749906588616266, recall: 0.7773247456877488, f1score_macro: 0.7510884077320485\n",
      " \n",
      "0.21000000000000002\n",
      "precision: [0.89066059 0.61369863], recall: [0.73496241 0.82352941], f1score: [0.8053553 0.7032967]\n",
      "macro:\n",
      "precision: 0.7521796111960558, recall: 0.7792459088898718, f1score_macro: 0.7543260035536039\n",
      " \n",
      "0.215\n",
      "precision: [0.88914027 0.6160221 ], recall: [0.7387218  0.81985294], f1score: [0.80698152 0.70347003]\n",
      "macro:\n",
      "precision: 0.7525811854703632, recall: 0.7792873728438744, f1score_macro: 0.7552257755264641\n",
      " \n",
      "0.22\n",
      "precision: [0.8836689 0.6162465], recall: [0.7424812  0.80882353], f1score: [0.80694586 0.69952305]\n",
      "macro:\n",
      "precision: 0.7499577012012859, recall: 0.7756523662096417, f1score_macro: 0.7532344577949337\n",
      " \n",
      "0.225\n",
      "precision: [0.88053097 0.61931818], recall: [0.7481203  0.80147059], f1score: [0.80894309 0.69871795]\n",
      "macro:\n",
      "precision: 0.7499245776347546, recall: 0.774795444493587, f1score_macro: 0.7538305190744214\n",
      " \n",
      "0.23\n",
      "precision: [0.87772926 0.62427746], recall: [0.7556391  0.79411765], f1score: [0.81212121 0.69902913]\n",
      "macro:\n",
      "precision: 0.7510033571446602, recall: 0.7748783724015922, f1score_macro: 0.7555751691674022\n",
      " \n",
      "0.23500000000000001\n",
      "precision: [0.87068966 0.62352941], recall: [0.7593985  0.77941176], f1score: [0.81124498 0.69281046]\n",
      "macro:\n",
      "precision: 0.7471095334685598, recall: 0.7694051304732419, f1score_macro: 0.7520277187180093\n",
      " \n",
      "0.24000000000000002\n",
      "precision: [0.86993603 0.62985075], recall: [0.76691729 0.77573529], f1score: [0.81518482 0.69522241]\n",
      "macro:\n",
      "precision: 0.7498933901918976, recall: 0.7713262936753649, f1score_macro: 0.7552036102283219\n",
      " \n",
      "0.245\n",
      "precision: [0.86680761 0.63141994], recall: [0.77067669 0.76838235], f1score: [0.8159204  0.69320066]\n",
      "macro:\n",
      "precision: 0.7491137752853484, recall: 0.7695295223352498, f1score_macro: 0.7545605306799337\n",
      " \n",
      "0.25\n",
      "precision: [0.86680761 0.63141994], recall: [0.77067669 0.76838235], f1score: [0.8159204  0.69320066]\n",
      "macro:\n",
      "precision: 0.7491137752853484, recall: 0.7695295223352498, f1score_macro: 0.7545605306799337\n",
      " \n",
      "0.255\n",
      "precision: [0.86610879 0.63803681], recall: [0.77819549 0.76470588], f1score: [0.81980198 0.69565217]\n",
      "macro:\n",
      "precision: 0.7520727982134148, recall: 0.7714506855373728, f1score_macro: 0.7577270770555317\n",
      " \n",
      "0.26\n",
      "precision: [0.86458333 0.63888889], recall: [0.78007519 0.76102941], f1score: [0.8201581  0.69463087]\n",
      "macro:\n",
      "precision: 0.7517361111111112, recall: 0.7705522998673153, f1score_macro: 0.7573944876250099\n",
      " \n",
      "0.265\n",
      "precision: [0.86128364 0.63862928], recall: [0.78195489 0.75367647], f1score: [0.81970443 0.69139966]\n",
      "macro:\n",
      "precision: 0.7499564636907181, recall: 0.7678156789031402, f1score_macro: 0.7555520481147043\n",
      " \n",
      "0.27\n",
      "precision: [0.862423  0.6466877], recall: [0.78947368 0.75367647], f1score: [0.82433759 0.69609508]\n",
      "macro:\n",
      "precision: 0.7545553475537476, recall: 0.7715750773993808, f1score_macro: 0.7602163311345889\n",
      " \n",
      "0.275\n",
      "precision: [0.86122449 0.64968153], recall: [0.79323308 0.75      ], f1score: [0.8258317  0.69624573]\n",
      "macro:\n",
      "precision: 0.7554530092291694, recall: 0.7716165413533835, f1score_macro: 0.7610387181662137\n",
      " \n",
      "0.28\n",
      "precision: [0.86178862 0.65384615], recall: [0.79699248 0.75      ], f1score: [0.828125   0.69863014]\n",
      "macro:\n",
      "precision: 0.7578173858661663, recall: 0.7734962406015038, f1score_macro: 0.7633775684931507\n",
      " \n",
      "0.28500000000000003\n",
      "precision: [0.86262626 0.66019417], recall: [0.80263158 0.75      ], f1score: [0.8315482  0.70223752]\n",
      "macro:\n",
      "precision: 0.7614102186917722, recall: 0.7763157894736843, f1score_macro: 0.7668928600757181\n",
      " \n",
      "0.29000000000000004\n",
      "precision: [0.85971944 0.66229508], recall: [0.80639098 0.74264706], f1score: [0.83220175 0.70017331]\n",
      "macro:\n",
      "precision: 0.7610072604224842, recall: 0.7745190181335693, f1score_macro: 0.766187528051546\n",
      " \n",
      "0.295\n",
      "precision: [0.85798817 0.67340067], recall: [0.81766917 0.73529412], f1score: [0.8373436 0.7029877]\n",
      "macro:\n",
      "precision: 0.7656944195405735, recall: 0.7764816452896949, f1score_macro: 0.7701656486651522\n",
      " \n",
      "0.3\n",
      "precision: [0.85490196 0.67346939], recall: [0.81954887 0.72794118], f1score: [0.83685221 0.69964664]\n",
      "macro:\n",
      "precision: 0.7641856742697078, recall: 0.7737450243255197, f1score_macro: 0.7682494252016032\n",
      " \n",
      "0.305\n",
      "precision: [0.85380117 0.67697595], recall: [0.82330827 0.72426471], f1score: [0.83827751 0.69982238]\n",
      "macro:\n",
      "precision: 0.7653885573039128, recall: 0.7737864882795223, f1score_macro: 0.7690499460341472\n",
      " \n",
      "0.31\n",
      "precision: [0.8540856  0.67931034], recall: [0.82518797 0.72426471], f1score: [0.83938815 0.70106762]\n",
      "macro:\n",
      "precision: 0.7666979739702133, recall: 0.7747263379035825, f1score_macro: 0.7702278804869254\n",
      " \n",
      "0.315\n",
      "precision: [0.85242718 0.67820069], recall: [0.82518797 0.72058824], f1score: [0.83858644 0.69875223]\n",
      "macro:\n",
      "precision: 0.7653139382537709, recall: 0.7728881026094648, f1score_macro: 0.7686693328021492\n",
      " \n",
      "0.32\n",
      "precision: [0.85135135 0.68181818], recall: [0.82894737 0.71691176], f1score: [0.84       0.69892473]\n",
      "macro:\n",
      "precision: 0.7665847665847665, recall: 0.7729295665634675, f1score_macro: 0.7694623655913979\n",
      " \n",
      "0.325\n",
      "precision: [0.85057471 0.68794326], recall: [0.83458647 0.71323529], f1score: [0.84250474 0.70036101]\n",
      "macro:\n",
      "precision: 0.7692589875275129, recall: 0.7739108801415303, f1score_macro: 0.771432877331671\n",
      " \n",
      "0.33\n",
      "precision: [0.84952381 0.69175627], recall: [0.83834586 0.70955882], f1score: [0.84389782 0.70054446]\n",
      "macro:\n",
      "precision: 0.7706400409626216, recall: 0.7739523440955329, f1score_macro: 0.7722211443200374\n",
      " \n",
      "0.335\n",
      "precision: [0.84848485 0.69565217], recall: [0.84210526 0.70588235], f1score: [0.84528302 0.70072993]\n",
      "macro:\n",
      "precision: 0.772068511198946, recall: 0.7739938080495357, f1score_macro: 0.7730064729376118\n",
      " \n",
      "0.34\n",
      "precision: [0.84774436 0.70220588], recall: [0.84774436 0.70220588], f1score: [0.84774436 0.70220588]\n",
      "macro:\n",
      "precision: 0.7749751216275984, recall: 0.7749751216275984, f1score_macro: 0.7749751216275984\n",
      " \n",
      "0.34500000000000003\n",
      "precision: [0.84831461 0.70740741], recall: [0.85150376 0.70220588], f1score: [0.84990619 0.70479705]\n",
      "macro:\n",
      "precision: 0.7778610070744902, recall: 0.7768548208757187, f1score_macro: 0.7773516196700428\n",
      " \n",
      "0.35000000000000003\n",
      "precision: [0.84916201 0.71535581], recall: [0.85714286 0.70220588], f1score: [0.85313377 0.70871985]\n",
      "macro:\n",
      "precision: 0.782258908208315, recall: 0.7796743697478992, f1score_macro: 0.7809268107276925\n",
      " \n",
      "0.35500000000000004\n",
      "precision: [0.84786642 0.71698113], recall: [0.85902256 0.69852941], f1score: [0.85340803 0.70763501]\n",
      "macro:\n",
      "precision: 0.7824237756852312, recall: 0.7787759840778417, f1score_macro: 0.7805215195948025\n",
      " \n",
      "0.36\n",
      "precision: [0.84686347 0.72137405], recall: [0.86278195 0.69485294], f1score: [0.8547486  0.70786517]\n",
      "macro:\n",
      "precision: 0.7841187572181065, recall: 0.7788174480318444, f1score_macro: 0.7813068859456406\n",
      " \n",
      "0.365\n",
      "precision: [0.84220183 0.71814672], recall: [0.86278195 0.68382353], f1score: [0.85236769 0.70056497]\n",
      "macro:\n",
      "precision: 0.7801742765045517, recall: 0.7733027421494914, f1score_macro: 0.7764663298868483\n",
      " \n",
      "0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.83941606 0.71875   ], recall: [0.86466165 0.67647059], f1score: [0.85185185 0.6969697 ]\n",
      "macro:\n",
      "precision: 0.7790830291970803, recall: 0.7705661211853163, f1score_macro: 0.7744107744107744\n",
      " \n",
      "0.375\n",
      "precision: [0.84       0.72440945], recall: [0.86842105 0.67647059], f1score: [0.85397412 0.69961977]\n",
      "macro:\n",
      "precision: 0.7822047244094488, recall: 0.7724458204334366, f1score_macro: 0.7767969469297105\n",
      " \n",
      "0.38\n",
      "precision: [0.84       0.72440945], recall: [0.86842105 0.67647059], f1score: [0.85397412 0.69961977]\n",
      "macro:\n",
      "precision: 0.7822047244094488, recall: 0.7724458204334366, f1score_macro: 0.7767969469297105\n",
      " \n",
      "0.385\n",
      "precision: [0.84115523 0.736     ], recall: [0.87593985 0.67647059], f1score: [0.85819521 0.70498084]\n",
      "macro:\n",
      "precision: 0.7885776173285198, recall: 0.7762052189296771, f1score_macro: 0.7815880273491247\n",
      " \n",
      "0.39\n",
      "precision: [0.83662478 0.73279352], recall: [0.87593985 0.66544118], f1score: [0.85583104 0.69749518]\n",
      "macro:\n",
      "precision: 0.7847091489253447, recall: 0.7706905130473242, f1score_macro: 0.7766631103467678\n",
      " \n",
      "0.395\n",
      "precision: [0.83363148 0.73061224], recall: [0.87593985 0.65808824], f1score: [0.85426214 0.69245648]\n",
      "macro:\n",
      "precision: 0.7821218648461173, recall: 0.7670140424590889, f1score_macro: 0.7733593122558935\n",
      " \n",
      "0.4\n",
      "precision: [0.83244207 0.73251029], recall: [0.87781955 0.65441176], f1score: [0.85452882 0.69126214]\n",
      "macro:\n",
      "precision: 0.7824761779010145, recall: 0.7661156567890315, f1score_macro: 0.7728954778422263\n",
      " \n",
      "0.405\n",
      "precision: [0.83274021 0.73553719], recall: [0.87969925 0.65441176], f1score: [0.85557587 0.692607  ]\n",
      "macro:\n",
      "precision: 0.7841387018028881, recall: 0.7670555064130915, f1score_macro: 0.774091436131997\n",
      " \n",
      "0.41000000000000003\n",
      "precision: [0.83333333 0.74166667], recall: [0.88345865 0.65441176], f1score: [0.85766423 0.6953125 ]\n",
      "macro:\n",
      "precision: 0.7875000000000001, recall: 0.7689352056612119, f1score_macro: 0.7764883667883211\n",
      " \n",
      "0.41500000000000004\n",
      "precision: [0.83215548 0.74369748], recall: [0.88533835 0.65073529], f1score: [0.8579235  0.69411765]\n",
      "macro:\n",
      "precision: 0.7879264780116995, recall: 0.7680368199911544, f1score_macro: 0.7760205721632916\n",
      " \n",
      "0.42000000000000004\n",
      "precision: [0.83215548 0.74369748], recall: [0.88533835 0.65073529], f1score: [0.8579235  0.69411765]\n",
      "macro:\n",
      "precision: 0.7879264780116995, recall: 0.7680368199911544, f1score_macro: 0.7760205721632916\n",
      " \n",
      "0.425\n",
      "precision: [0.83068783 0.74261603], recall: [0.88533835 0.64705882], f1score: [0.85714286 0.69155206]\n",
      "macro:\n",
      "precision: 0.7866519322215525, recall: 0.7661985846970367, f1score_macro: 0.7743474600056133\n",
      " \n",
      "0.43\n",
      "precision: [0.82807018 0.74358974], recall: [0.88721805 0.63970588], f1score: [0.85662432 0.68774704]\n",
      "macro:\n",
      "precision: 0.78582995951417, recall: 0.7634619637328615, f1score_macro: 0.7721856774961802\n",
      " \n",
      "0.435\n",
      "precision: [0.82837128 0.74678112], recall: [0.88909774 0.63970588], f1score: [0.85766092 0.68910891]\n",
      "macro:\n",
      "precision: 0.7875761971693362, recall: 0.7644018133569217, f1score_macro: 0.7733849178208845\n",
      " \n",
      "0.44\n",
      "precision: [0.82722513 0.74891775], recall: [0.89097744 0.63602941], f1score: [0.85791855 0.68787276]\n",
      "macro:\n",
      "precision: 0.7880714399039006, recall: 0.7635034276868642, f1score_macro: 0.7728956577278411\n",
      " \n",
      "0.445\n",
      "precision: [0.82495667 0.75330396], recall: [0.89473684 0.62867647], f1score: [0.85843102 0.68537074]\n",
      "macro:\n",
      "precision: 0.7891303186006917, recall: 0.7617066563467492, f1score_macro: 0.7719008802094721\n",
      " \n",
      "0.45\n",
      "precision: [0.82525952 0.75663717], recall: [0.89661654 0.62867647], f1score: [0.85945946 0.68674699]\n",
      "macro:\n",
      "precision: 0.7909483418562635, recall: 0.7626465059708094, f1score_macro: 0.7731032237056332\n",
      " \n",
      "0.455\n",
      "precision: [0.82444062 0.76233184], recall: [0.90037594 0.625     ], f1score: [0.86073675 0.68686869]\n",
      "macro:\n",
      "precision: 0.7933862290931825, recall: 0.762687969924812, f1score_macro: 0.7738027171989437\n",
      " \n",
      "0.46\n",
      "precision: [0.82363014 0.76818182], recall: [0.90413534 0.62132353], f1score: [0.86200717 0.68699187]\n",
      "macro:\n",
      "precision: 0.7959059775840598, recall: 0.7627294338788146, f1score_macro: 0.7744995191887403\n",
      " \n",
      "0.465\n",
      "precision: [0.8225256 0.7706422], recall: [0.90601504 0.61764706], f1score: [0.86225403 0.68571429]\n",
      "macro:\n",
      "precision: 0.7965838995522435, recall: 0.7618310482087571, f1score_macro: 0.7739841553795043\n",
      " \n",
      "0.47000000000000003\n",
      "precision: [0.82003396 0.77209302], recall: [0.90789474 0.61029412], f1score: [0.8617306  0.68172485]\n",
      "macro:\n",
      "precision: 0.7960634895565997, recall: 0.7590944272445821, f1score_macro: 0.7717277218382678\n",
      " \n",
      "0.47500000000000003\n",
      "precision: [0.81864407 0.77102804], recall: [0.90789474 0.60661765], f1score: [0.86096257 0.67901235]\n",
      "macro:\n",
      "precision: 0.7948360525898939, recall: 0.7572561919504643, f1score_macro: 0.7699874562619662\n",
      " \n",
      "0.48000000000000004\n",
      "precision: [0.81649832 0.77619048], recall: [0.91165414 0.59926471], f1score: [0.86145648 0.67634855]\n",
      "macro:\n",
      "precision: 0.7963443963443964, recall: 0.7554594206103493, f1score_macro: 0.7689025154219762\n",
      " \n",
      "0.485\n",
      "precision: [0.81543624 0.77884615], recall: [0.91353383 0.59558824], f1score: [0.86170213 0.675     ]\n",
      "macro:\n",
      "precision: 0.797141197728446, recall: 0.7545610349402919, f1score_macro: 0.7683510638297872\n",
      " \n",
      "0.49\n",
      "precision: [0.81543624 0.77884615], recall: [0.91353383 0.59558824], f1score: [0.86170213 0.675     ]\n",
      "macro:\n",
      "precision: 0.797141197728446, recall: 0.7545610349402919, f1score_macro: 0.7683510638297872\n",
      " \n",
      "0.495\n",
      "precision: [0.8130217 0.7804878], recall: [0.91541353 0.58823529], f1score: [0.86118479 0.67085954]\n",
      "macro:\n",
      "precision: 0.7967547538580562, recall: 0.7518244139761168, f1score_macro: 0.766022165501671\n",
      " \n",
      "0.5\n",
      "precision: [0.81198003 0.78325123], recall: [0.91729323 0.58455882], f1score: [0.86142983 0.66947368]\n",
      "macro:\n",
      "precision: 0.7976156324024819, recall: 0.7509260283060593, f1score_macro: 0.7654517582570726\n",
      " \n",
      "0.505\n",
      "precision: [0.80826446 0.7839196 ], recall: [0.91917293 0.57352941], f1score: [0.86015831 0.66242038]\n",
      "macro:\n",
      "precision: 0.7960920303999335, recall: 0.7463511720477665, f1score_macro: 0.7612893467556257\n",
      " \n",
      "0.51\n",
      "precision: [0.80858086 0.78787879], recall: [0.92105263 0.57352941], f1score: [0.86115993 0.66382979]\n",
      "macro:\n",
      "precision: 0.7982298229822982, recall: 0.7472910216718266, f1score_macro: 0.7624948584676363\n",
      " \n",
      "0.515\n",
      "precision: [0.80756579 0.79081633], recall: [0.92293233 0.56985294], f1score: [0.86140351 0.66239316]\n",
      "macro:\n",
      "precision: 0.7991910580021482, recall: 0.7463926360017692, f1score_macro: 0.7618983355825462\n",
      " \n",
      "0.52\n",
      "precision: [0.80655738 0.79381443], recall: [0.92481203 0.56617647], f1score: [0.86164623 0.66094421]\n",
      "macro:\n",
      "precision: 0.8001859050194355, recall: 0.7454942503317117, f1score_macro: 0.7612952203422952\n",
      " \n",
      "0.525\n",
      "precision: [0.80424144 0.79581152], recall: [0.92669173 0.55882353], f1score: [0.86113537 0.65658747]\n",
      "macro:\n",
      "precision: 0.8000264769437067, recall: 0.7427576293675364, f1score_macro: 0.7588614220905996\n",
      " \n",
      "0.53\n",
      "precision: [0.80325203 0.7989418 ], recall: [0.92857143 0.55514706], f1score: [0.86137751 0.65509761]\n",
      "macro:\n",
      "precision: 0.8010969157310621, recall: 0.741859243697479, f1score_macro: 0.75823756021083\n",
      " \n",
      "0.535\n",
      "precision: [0.80357143 0.80319149], recall: [0.93045113 0.55514706], f1score: [0.86236934 0.65652174]\n",
      "macro:\n",
      "precision: 0.8033814589665653, recall: 0.7427990933215392, f1score_macro: 0.7594455385547645\n",
      " \n",
      "0.54\n",
      "precision: [0.80388979 0.80748663], recall: [0.93233083 0.55514706], f1score: [0.86335944 0.65795207]\n",
      "macro:\n",
      "precision: 0.805688210159561, recall: 0.7437389429455993, f1score_macro: 0.7606557563553416\n",
      " \n",
      "0.545\n",
      "precision: [0.80129241 0.80540541], recall: [0.93233083 0.54779412], f1score: [0.86185925 0.65207877]\n",
      "macro:\n",
      "precision: 0.8033489062568222, recall: 0.740062472357364, f1score_macro: 0.7569690137203497\n",
      " \n",
      "0.55\n",
      "precision: [0.79775281 0.80662983], recall: [0.93421053 0.53676471], f1score: [0.86060606 0.64459161]\n",
      "macro:\n",
      "precision: 0.8021913216214538, recall: 0.7354876160990712, f1score_macro: 0.7525988360425446\n",
      " \n",
      "0.555\n",
      "precision: [0.79807692 0.81111111], recall: [0.93609023 0.53676471], f1score: [0.8615917 0.6460177]\n",
      "macro:\n",
      "precision: 0.8045940170940171, recall: 0.7364274657231313, f1score_macro: 0.7538046973083872\n",
      " \n",
      "0.56\n",
      "precision: [0.7971246  0.81460674], recall: [0.93796992 0.53308824], f1score: [0.86183074 0.64444444]\n",
      "macro:\n",
      "precision: 0.8058656711060057, recall: 0.7355290800530738, f1score_macro: 0.7531375935521013\n",
      " \n",
      "0.5650000000000001\n",
      "precision: [0.79585327 0.81355932], recall: [0.93796992 0.52941176], f1score: [0.86108714 0.64142539]\n",
      "macro:\n",
      "precision: 0.8047062957856892, recall: 0.7336908447589563, f1score_macro: 0.7512562669223719\n",
      " \n",
      "0.5700000000000001\n",
      "precision: [0.7968254  0.82758621], recall: [0.94360902 0.52941176], f1score: [0.86402754 0.64573991]\n",
      "macro:\n",
      "precision: 0.8122058018609742, recall: 0.7365103936311367, f1score_macro: 0.7548837245201176\n",
      " \n",
      "0.5750000000000001\n",
      "precision: [0.7968254  0.82758621], recall: [0.94360902 0.52941176], f1score: [0.86402754 0.64573991]\n",
      "macro:\n",
      "precision: 0.8122058018609742, recall: 0.7365103936311367, f1score_macro: 0.7548837245201176\n",
      " \n",
      "0.5800000000000001\n",
      "precision: [0.7955626 0.8265896], recall: [0.94360902 0.52573529], f1score: [0.86328461 0.64269663]\n",
      "macro:\n",
      "precision: 0.8110760972124255, recall: 0.734672158337019, f1score_macro: 0.7529906189919524\n",
      " \n",
      "0.585\n",
      "precision: [0.79588608 0.83139535], recall: [0.94548872 0.52573529], f1score: [0.86426117 0.64414414]\n",
      "macro:\n",
      "precision: 0.8136407123932883, recall: 0.7356120079610792, f1score_macro: 0.754202656264512\n",
      " \n",
      "0.59\n",
      "precision: [0.79588608 0.83139535], recall: [0.94548872 0.52573529], f1score: [0.86426117 0.64414414]\n",
      "macro:\n",
      "precision: 0.8136407123932883, recall: 0.7356120079610792, f1score_macro: 0.754202656264512\n",
      " \n",
      "0.595\n",
      "precision: [0.79462875 0.83040936], recall: [0.94548872 0.52205882], f1score: [0.86351931 0.64108352]\n",
      "macro:\n",
      "precision: 0.8125190543499348, recall: 0.7337737726669615, f1score_macro: 0.7523014173747082\n",
      " \n",
      "0.6\n",
      "precision: [0.79337539 0.82941176], recall: [0.94548872 0.51838235], f1score: [0.86277873 0.63800905]\n",
      "macro:\n",
      "precision: 0.8113935795138245, recall: 0.7319355373728439, f1score_macro: 0.7503938902385073\n",
      " \n",
      "0.605\n",
      "precision: [0.79337539 0.82941176], recall: [0.94548872 0.51838235], f1score: [0.86277873 0.63800905]\n",
      "macro:\n",
      "precision: 0.8113935795138245, recall: 0.7319355373728439, f1score_macro: 0.7503938902385073\n",
      " \n",
      "0.61\n",
      "precision: [0.79186228 0.84242424], recall: [0.95112782 0.51102941], f1score: [0.86421862 0.63615561]\n",
      "macro:\n",
      "precision: 0.8171432636221369, recall: 0.731078615656789, f1score_macro: 0.7501871114871796\n",
      " \n",
      "0.615\n",
      "precision: [0.790625   0.84146341], recall: [0.95112782 0.50735294], f1score: [0.86348123 0.63302752]\n",
      "macro:\n",
      "precision: 0.8160442073170732, recall: 0.7292403803626714, f1score_macro: 0.7482543758023609\n",
      " \n",
      "0.62\n",
      "precision: [0.79095164 0.84662577], recall: [0.95300752 0.50735294], f1score: [0.86445013 0.63448276]\n",
      "macro:\n",
      "precision: 0.8187887024683441, recall: 0.7301802299867315, f1score_macro: 0.7494664432489637\n",
      " \n",
      "0.625\n",
      "precision: [0.79037267 0.85625   ], recall: [0.95676692 0.50367647], f1score: [0.86564626 0.63425926]\n",
      "macro:\n",
      "precision: 0.8233113354037267, recall: 0.7302216939407342, f1score_macro: 0.7499527588813303\n",
      " \n",
      "0.63\n",
      "precision: [0.78914729 0.85534591], recall: [0.95676692 0.5       ], f1score: [0.86491079 0.63109049]\n",
      "macro:\n",
      "precision: 0.8222465993856956, recall: 0.7283834586466165, f1score_macro: 0.7480006386917071\n",
      " \n",
      "0.635\n",
      "precision: [0.7879257  0.85443038], recall: [0.95676692 0.49632353], f1score: [0.86417657 0.62790698]\n",
      "macro:\n",
      "precision: 0.8211780381706313, recall: 0.7265452233524989, f1score_macro: 0.7460417736012951\n",
      " \n",
      "0.64\n",
      "precision: [0.78703704 0.85897436], recall: [0.95864662 0.49264706], f1score: [0.86440678 0.62616822]\n",
      "macro:\n",
      "precision: 0.823005698005698, recall: 0.7256468376824414, f1score_macro: 0.7452875019800411\n",
      " \n",
      "0.645\n",
      "precision: [0.78736518 0.86451613], recall: [0.96052632 0.49264706], f1score: [0.86536833 0.62763466]\n",
      "macro:\n",
      "precision: 0.8259406531139719, recall: 0.7265866873065016, f1score_macro: 0.7465014961718228\n",
      " \n",
      "0.65\n",
      "precision: [0.78494624 0.8627451 ], recall: [0.96052632 0.48529412], f1score: [0.86390533 0.62117647]\n",
      "macro:\n",
      "precision: 0.8238456672991777, recall: 0.7229102167182663, f1score_macro: 0.7425408980160111\n",
      " \n",
      "0.655\n",
      "precision: [0.78134557 0.86      ], recall: [0.96052632 0.47426471], f1score: [0.86172007 0.61137441]\n",
      "macro:\n",
      "precision: 0.8206727828746178, recall: 0.7173955108359134, f1score_macro: 0.736547237518282\n",
      " \n",
      "0.66\n",
      "precision: [0.78134557 0.86      ], recall: [0.96052632 0.47426471], f1score: [0.86172007 0.61137441]\n",
      "macro:\n",
      "precision: 0.8206727828746178, recall: 0.7173955108359134, f1score_macro: 0.736547237518282\n",
      " \n",
      "0.665\n",
      "precision: [0.7784522  0.86896552], recall: [0.96428571 0.46323529], f1score: [0.86146096 0.60431655]\n",
      "macro:\n",
      "precision: 0.8237088587724347, recall: 0.7137605042016807, f1score_macro: 0.7328887519707157\n",
      " \n",
      "0.67\n",
      "precision: [0.7784522  0.86896552], recall: [0.96428571 0.46323529], f1score: [0.86146096 0.60431655]\n",
      "macro:\n",
      "precision: 0.8237088587724347, recall: 0.7137605042016807, f1score_macro: 0.7328887519707157\n",
      " \n",
      "0.675\n",
      "precision: [0.77609682 0.86713287], recall: [0.96428571 0.45588235], f1score: [0.86001676 0.59759036]\n",
      "macro:\n",
      "precision: 0.8216148450641643, recall: 0.7100840336134454, f1score_macro: 0.7288035629525647\n",
      " \n",
      "0.68\n",
      "precision: [0.77609682 0.86713287], recall: [0.96428571 0.45588235], f1score: [0.86001676 0.59759036]\n",
      "macro:\n",
      "precision: 0.8216148450641643, recall: 0.7100840336134454, f1score_macro: 0.7288035629525647\n",
      " \n",
      "0.685\n",
      "precision: [0.77526395 0.87234043], recall: [0.96616541 0.45220588], f1score: [0.86025105 0.59564165]\n",
      "macro:\n",
      "precision: 0.8238021886332274, recall: 0.7091856479433879, f1score_macro: 0.7279463462571043\n",
      " \n",
      "0.6900000000000001\n",
      "precision: [0.77061469 0.86861314], recall: [0.96616541 0.4375    ], f1score: [0.85738115 0.58190709]\n",
      "macro:\n",
      "precision: 0.8196139156699023, recall: 0.7018327067669172, f1score_macro: 0.7196441207118403\n",
      " \n",
      "0.6950000000000001\n",
      "precision: [0.76716418 0.86567164], recall: [0.96616541 0.42647059], f1score: [0.85524126 0.57142857]\n",
      "macro:\n",
      "precision: 0.8164179104477611, recall: 0.6963180008845643, f1score_macro: 0.7133349179938198\n",
      " \n",
      "0.7000000000000001\n",
      "precision: [0.76602086 0.86466165], recall: [0.96616541 0.42279412], f1score: [0.85453034 0.56790123]\n",
      "macro:\n",
      "precision: 0.8153412592584293, recall: 0.6944797655904467, f1score_macro: 0.7112157876912657\n",
      " \n",
      "0.7050000000000001\n",
      "precision: [0.76374443 0.86259542], recall: [0.96616541 0.41544118], f1score: [0.85311203 0.56079404]\n",
      "macro:\n",
      "precision: 0.8131699238909746, recall: 0.6908032950022114, f1score_macro: 0.7069530389300167\n",
      " \n",
      "0.71\n",
      "precision: [0.75811209 0.85714286], recall: [0.96616541 0.39705882], f1score: [0.84958678 0.54271357]\n",
      "macro:\n",
      "precision: 0.8076274757690687, recall: 0.6816121185316232, f1score_macro: 0.69615017234935\n",
      " \n",
      "0.715\n",
      "precision: [0.75624082 0.86178862], recall: [0.96804511 0.38970588], f1score: [0.84913438 0.53670886]\n",
      "macro:\n",
      "precision: 0.8090147201031481, recall: 0.678875497567448, f1score_macro: 0.6929216191678755\n",
      " \n",
      "0.72\n",
      "precision: [0.75624082 0.86178862], recall: [0.96804511 0.38970588], f1score: [0.84913438 0.53670886]\n",
      "macro:\n",
      "precision: 0.8090147201031481, recall: 0.678875497567448, f1score_macro: 0.6929216191678755\n",
      " \n",
      "0.725\n",
      "precision: [0.75624082 0.86178862], recall: [0.96804511 0.38970588], f1score: [0.84913438 0.53670886]\n",
      "macro:\n",
      "precision: 0.8090147201031481, recall: 0.678875497567448, f1score_macro: 0.6929216191678755\n",
      " \n",
      "0.73\n",
      "precision: [0.75513196 0.86065574], recall: [0.96804511 0.38602941], f1score: [0.84843493 0.53299492]\n",
      "macro:\n",
      "precision: 0.8078938512571511, recall: 0.6770372622733304, f1score_macro: 0.6907149248613887\n",
      " \n",
      "0.735\n",
      "precision: [0.75292398 0.85833333], recall: [0.96804511 0.37867647], f1score: [0.84703947 0.5255102 ]\n",
      "macro:\n",
      "precision: 0.8056286549707602, recall: 0.6733607916850951, f1score_macro: 0.6862748388829216\n",
      " \n",
      "0.74\n",
      "precision: [0.75364431 0.87288136], recall: [0.97180451 0.37867647], f1score: [0.84893268 0.52820513]\n",
      "macro:\n",
      "precision: 0.813262835400504, recall: 0.6752404909332154, f1score_macro: 0.6885689023620057\n",
      " \n",
      "0.745\n",
      "precision: [0.75145349 0.87068966], recall: [0.97180451 0.37132353], f1score: [0.84754098 0.52061856]\n",
      "macro:\n",
      "precision: 0.8110715717722534, recall: 0.6715640203449801, f1score_macro: 0.6840797701537941\n",
      " \n",
      "0.75\n",
      "precision: [0.74927536 0.86842105], recall: [0.97180451 0.36397059], f1score: [0.84615385 0.51295337]\n",
      "macro:\n",
      "precision: 0.8088482074752098, recall: 0.6678875497567448, f1score_macro: 0.679553607014747\n",
      " \n",
      "0.755\n",
      "precision: [0.74927536 0.86842105], recall: [0.97180451 0.36397059], f1score: [0.84615385 0.51295337]\n",
      "macro:\n",
      "precision: 0.8088482074752098, recall: 0.6678875497567448, f1score_macro: 0.679553607014747\n",
      " \n",
      "0.76\n",
      "precision: [0.74927536 0.86842105], recall: [0.97180451 0.36397059], f1score: [0.84615385 0.51295337]\n",
      "macro:\n",
      "precision: 0.8088482074752098, recall: 0.6678875497567448, f1score_macro: 0.679553607014747\n",
      " \n",
      "0.765\n",
      "precision: [0.74927536 0.86842105], recall: [0.97180451 0.36397059], f1score: [0.84615385 0.51295337]\n",
      "macro:\n",
      "precision: 0.8088482074752098, recall: 0.6678875497567448, f1score_macro: 0.679553607014747\n",
      " \n",
      "0.77\n",
      "precision: [0.74710983 0.86607143], recall: [0.97180451 0.35661765], f1score: [0.84477124 0.50520833]\n",
      "macro:\n",
      "precision: 0.8065906275805119, recall: 0.6642110791685095, f1score_macro: 0.6749897875816993\n",
      " \n",
      "0.775\n",
      "precision: [0.74532374 0.87155963], recall: [0.97368421 0.34926471], f1score: [0.84433578 0.49868766]\n",
      "macro:\n",
      "precision: 0.8084416870173585, recall: 0.6614744582043344, f1score_macro: 0.6715117211815516\n",
      " \n",
      "0.78\n",
      "precision: [0.74318508 0.86915888], recall: [0.97368421 0.34191176], f1score: [0.84296176 0.49076517]\n",
      "macro:\n",
      "precision: 0.8061719787071427, recall: 0.6577979876160991, f1score_macro: 0.666863464515201\n",
      " \n",
      "0.785\n",
      "precision: [0.74212034 0.86792453], recall: [0.97368421 0.33823529], f1score: [0.84227642 0.48677249]\n",
      "macro:\n",
      "precision: 0.8050224360707141, recall: 0.6559597523219814, f1score_macro: 0.6645244547683572\n",
      " \n",
      "0.79\n",
      "precision: [0.7403709  0.87378641], recall: [0.97556391 0.33088235], f1score: [0.84184915 0.48      ]\n",
      "macro:\n",
      "precision: 0.807078653241555, recall: 0.6532231313578063, f1score_macro: 0.6609245742092457\n",
      " \n",
      "0.795\n",
      "precision: [0.73931624 0.87254902], recall: [0.97556391 0.32720588], f1score: [0.84116694 0.47593583]\n",
      "macro:\n",
      "precision: 0.8059326294620413, recall: 0.6513848960636887, f1score_macro: 0.6585513828339646\n",
      " \n",
      "0.8\n",
      "precision: [0.73617021 0.86868687], recall: [0.97556391 0.31617647], f1score: [0.83912692 0.46361186]\n",
      "macro:\n",
      "precision: 0.8024285407264131, recall: 0.6458701901813357, f1score_macro: 0.6513693899029693\n",
      " \n",
      "0.805\n",
      "precision: [0.73512748 0.86734694], recall: [0.97556391 0.3125    ], f1score: [0.83844911 0.45945946]\n",
      "macro:\n",
      "precision: 0.8012372087645256, recall: 0.644031954887218, f1score_macro: 0.6489542854647863\n",
      " \n",
      "0.81\n",
      "precision: [0.73512748 0.86734694], recall: [0.97556391 0.3125    ], f1score: [0.83844911 0.45945946]\n",
      "macro:\n",
      "precision: 0.8012372087645256, recall: 0.644031954887218, f1score_macro: 0.6489542854647863\n",
      " \n",
      "0.8150000000000001\n",
      "precision: [0.73550212 0.87628866], recall: [0.97744361 0.3125    ], f1score: [0.8393866  0.46070461]\n",
      "macro:\n",
      "precision: 0.805895390717275, recall: 0.6449718045112782, f1score_macro: 0.6500456045722685\n",
      " \n",
      "0.8200000000000001\n",
      "precision: [0.73587571 0.88541667], recall: [0.97932331 0.3125    ], f1score: [0.84032258 0.46195652]\n",
      "macro:\n",
      "precision: 0.810646186440678, recall: 0.6459116541353384, f1score_macro: 0.6511395511921458\n",
      " \n",
      "0.8250000000000001\n",
      "precision: [0.732493 0.9     ], recall: [0.98308271 0.29779412], f1score: [0.83948636 0.44751381]\n",
      "macro:\n",
      "precision: 0.8162464985994398, recall: 0.640438412206988, f1score_macro: 0.6435000842474925\n",
      " \n",
      "0.8300000000000001\n",
      "precision: [0.732493 0.9     ], recall: [0.98308271 0.29779412], f1score: [0.83948636 0.44751381]\n",
      "macro:\n",
      "precision: 0.8162464985994398, recall: 0.640438412206988, f1score_macro: 0.6435000842474925\n",
      " \n",
      "0.8350000000000001\n",
      "precision: [0.73221757 0.91954023], recall: [0.98684211 0.29411765], f1score: [0.84067254 0.44568245]\n",
      "macro:\n",
      "precision: 0.8258789015534074, recall: 0.6404798761609907, f1score_macro: 0.6431774946419531\n",
      " \n",
      "0.84\n",
      "precision: [0.73221757 0.91954023], recall: [0.98684211 0.29411765], f1score: [0.84067254 0.44568245]\n",
      "macro:\n",
      "precision: 0.8258789015534074, recall: 0.6404798761609907, f1score_macro: 0.6431774946419531\n",
      " \n",
      "0.845\n",
      "precision: [0.73055556 0.92857143], recall: [0.9887218  0.28676471], f1score: [0.84025559 0.43820225]\n",
      "macro:\n",
      "precision: 0.829563492063492, recall: 0.6377432551968156, f1score_macro: 0.6392289191226621\n",
      " \n",
      "0.85\n",
      "precision: [0.7299169  0.93902439], recall: [0.9906015  0.28308824], f1score: [0.84051037 0.43502825]\n",
      "macro:\n",
      "precision: 0.8344706438754138, recall: 0.6368448695267581, f1score_macro: 0.6377693077068635\n",
      " \n",
      "0.855\n",
      "precision: [0.72890733 0.9382716 ], recall: [0.9906015  0.27941176], f1score: [0.83984064 0.4305949 ]\n",
      "macro:\n",
      "precision: 0.8335894677526765, recall: 0.6350066342326404, f1score_macro: 0.6352177691500287\n",
      " \n",
      "0.86\n",
      "precision: [0.72689655 0.93670886], recall: [0.9906015  0.27205882], f1score: [0.83850438 0.42165242]\n",
      "macro:\n",
      "precision: 0.8318027062418158, recall: 0.6313301636444051, f1score_macro: 0.6300783985748185\n",
      " \n",
      "0.865\n",
      "precision: [0.72689655 0.93670886], recall: [0.9906015  0.27205882], f1score: [0.83850438 0.42165242]\n",
      "macro:\n",
      "precision: 0.8318027062418158, recall: 0.6313301636444051, f1score_macro: 0.6300783985748185\n",
      " \n",
      "0.87\n",
      "precision: [0.72489684 0.93506494], recall: [0.9906015  0.26470588], f1score: [0.83717236 0.41260745]\n",
      "macro:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8299808856892763, recall: 0.6276536930561698, f1score_macro: 0.6248899044359124\n",
      " \n",
      "0.875\n",
      "precision: [0.72290809 0.93333333], recall: [0.9906015  0.25735294], f1score: [0.83584457 0.40345821]\n",
      "macro:\n",
      "precision: 0.8281207133058985, recall: 0.6239772224679345, f1score_macro: 0.6196513905299075\n",
      " \n",
      "0.88\n",
      "precision: [0.71994536 0.93055556], recall: [0.9906015  0.24632353], f1score: [0.83386076 0.38953488]\n",
      "macro:\n",
      "precision: 0.8252504553734061, recall: 0.6184625165855816, f1score_macro: 0.6116978216073006\n",
      " \n",
      "0.885\n",
      "precision: [0.7170068  0.92753623], recall: [0.9906015  0.23529412], f1score: [0.83188635 0.37536657]\n",
      "macro:\n",
      "precision: 0.8222715173025732, recall: 0.6129478107032287, f1score_macro: 0.6036264573067283\n",
      " \n",
      "0.89\n",
      "precision: [0.71603261 0.92647059], recall: [0.9906015  0.23161765], f1score: [0.83123028 0.37058824]\n",
      "macro:\n",
      "precision: 0.8212515984654731, recall: 0.611109575409111, f1score_macro: 0.6009092596028949\n",
      " \n",
      "0.895\n",
      "precision: [0.71409214 0.92424242], recall: [0.9906015  0.22426471], f1score: [0.82992126 0.36094675]\n",
      "macro:\n",
      "precision: 0.8191672825819167, recall: 0.6074331048208758, f1score_macro: 0.5954340027023249\n",
      " \n",
      "0.9\n",
      "precision: [0.71351351 0.9375    ], recall: [0.9924812  0.22058824], f1score: [0.83018868 0.35714286]\n",
      "macro:\n",
      "precision: 0.8255067567567568, recall: 0.6065347191508181, f1score_macro: 0.59366576819407\n",
      " \n",
      "macro 0.7815880273491247\n",
      "F1-valued: 0.7049808429118775\n",
      "recall-valued: 0.6764705882352942\n",
      "0.385\n"
     ]
    }
   ],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce8abc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.84115523 0.736     ], recall: [0.87593985 0.67647059], f1score: [0.85819521 0.70498084]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "38b97191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7885776173285198, recall: 0.7762052189296771, f1score_macro: 0.7815880273491247\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bf0b9",
   "metadata": {},
   "source": [
    "# Logit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d22f6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7a7d525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76264768, 1.45184544])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(df.label), y=df.label)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b8a0d44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "250 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.6648099         nan 0.69625263        nan 0.6957246\n",
      "        nan 0.69385737        nan 0.69450634        nan 0.6942156\n",
      "        nan 0.69527193        nan 0.69336733        nan 0.69308049\n",
      "        nan 0.69266584        nan 0.6942928         nan 0.69362664\n",
      "        nan 0.69414142        nan 0.69360254        nan 0.69507204\n",
      "        nan 0.69555482        nan 0.69492041        nan 0.69537607\n",
      "        nan 0.69574645        nan 0.69593207        nan 0.69529943\n",
      "        nan 0.69594598        nan 0.69660234        nan 0.69578804\n",
      "        nan 0.69502149        nan 0.69459366        nan 0.6946387\n",
      "        nan 0.69531294        nan 0.69415255        nan 0.69479495\n",
      "        nan 0.69507186        nan 0.69580215        nan 0.69580973\n",
      "        nan 0.69521393        nan 0.69414923        nan 0.69404047\n",
      "        nan 0.69268641        nan 0.69281511        nan 0.69247619\n",
      "        nan 0.69294984        nan 0.69253267        nan 0.69209994\n",
      "        nan 0.69227727        nan 0.69262887        nan 0.69197545\n",
      "        nan 0.69220549        nan 0.69157654        nan 0.69253168\n",
      "        nan 0.69153067        nan 0.69193289]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight={0: 0.7626476825204483,\n",
       "                                                        1: 1.4518454440599768}),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 2.04179592e-01, 4.08259184e-01, 6.12338776e-01,\n",
       "       8.16418367e-01, 1.02049796e+00, 1.22457755e+00, 1.42865714e+00,\n",
       "       1.63273673e+00, 1.83681633e+00, 2.04089592e+00, 2.24497551e+00,\n",
       "       2.44905510e+00, 2.65313469e+00, 2.85721429e+...\n",
       "       5.71432857e+00, 5.91840816e+00, 6.12248776e+00, 6.32656735e+00,\n",
       "       6.53064694e+00, 6.73472653e+00, 6.93880612e+00, 7.14288571e+00,\n",
       "       7.34696531e+00, 7.55104490e+00, 7.75512449e+00, 7.95920408e+00,\n",
       "       8.16328367e+00, 8.36736327e+00, 8.57144286e+00, 8.77552245e+00,\n",
       "       8.97960204e+00, 9.18368163e+00, 9.38776122e+00, 9.59184082e+00,\n",
       "       9.79592041e+00, 1.00000000e+01]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight={0: 0.7626476825204483,\n",
       "                                                        1: 1.4518454440599768}),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 2.04179592e-01, 4.08259184e-01, 6.12338776e-01,\n",
       "       8.16418367e-01, 1.02049796e+00, 1.22457755e+00, 1.42865714e+00,\n",
       "       1.63273673e+00, 1.83681633e+00, 2.04089592e+00, 2.24497551e+00,\n",
       "       2.44905510e+00, 2.65313469e+00, 2.85721429e+...\n",
       "       5.71432857e+00, 5.91840816e+00, 6.12248776e+00, 6.32656735e+00,\n",
       "       6.53064694e+00, 6.73472653e+00, 6.93880612e+00, 7.14288571e+00,\n",
       "       7.34696531e+00, 7.55104490e+00, 7.75512449e+00, 7.95920408e+00,\n",
       "       8.16328367e+00, 8.36736327e+00, 8.57144286e+00, 8.77552245e+00,\n",
       "       8.97960204e+00, 9.18368163e+00, 9.38776122e+00, 9.59184082e+00,\n",
       "       9.79592041e+00, 1.00000000e+01]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 0.7626476825204483, 1: 1.4518454440599768})</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 0.7626476825204483, 1: 1.4518454440599768})</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight={0: 0.7626476825204483,\n",
       "                                                        1: 1.4518454440599768}),\n",
       "             param_grid={'C': array([1.00000000e-04, 2.04179592e-01, 4.08259184e-01, 6.12338776e-01,\n",
       "       8.16418367e-01, 1.02049796e+00, 1.22457755e+00, 1.42865714e+00,\n",
       "       1.63273673e+00, 1.83681633e+00, 2.04089592e+00, 2.24497551e+00,\n",
       "       2.44905510e+00, 2.65313469e+00, 2.85721429e+...\n",
       "       5.71432857e+00, 5.91840816e+00, 6.12248776e+00, 6.32656735e+00,\n",
       "       6.53064694e+00, 6.73472653e+00, 6.93880612e+00, 7.14288571e+00,\n",
       "       7.34696531e+00, 7.55104490e+00, 7.75512449e+00, 7.95920408e+00,\n",
       "       8.16328367e+00, 8.36736327e+00, 8.57144286e+00, 8.77552245e+00,\n",
       "       8.97960204e+00, 9.18368163e+00, 9.38776122e+00, 9.59184082e+00,\n",
       "       9.79592041e+00, 1.00000000e+01]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 10, 50), \"penalty\":[\"l1\",\"l2\"]}  #high C means \"Trust this training data a lot\", while a low value says \"This data may not be fully representative of the real world data, so if it's telling you to make a parameter really large, don't listen to it\"\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight={0:class_weight[0], 1:class_weight[1]}), parameters, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(embs['cls'], df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "df418568",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict_proba(emb_test['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "de479596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "precision: [0.         0.33830846], recall: [0. 1.], f1score: [0.         0.50557621]\n",
      "macro:\n",
      "precision: 0.1691542288557214, recall: 0.5, f1score_macro: 0.2527881040892193\n",
      " \n",
      "0.01\n",
      "precision: [0.         0.33830846], recall: [0. 1.], f1score: [0.         0.50557621]\n",
      "macro:\n",
      "precision: 0.1691542288557214, recall: 0.5, f1score_macro: 0.2527881040892193\n",
      " \n",
      "0.015\n",
      "precision: [1.         0.33957553], recall: [0.0056391 1.       ], f1score: [0.01121495 0.50698975]\n",
      "macro:\n",
      "precision: 0.6697877652933832, recall: 0.5028195488721805, f1score_macro: 0.2591023508200434\n",
      " \n",
      "0.02\n",
      "precision: [1.         0.34300126], recall: [0.02067669 1.        ], f1score: [0.04051565 0.51079812]\n",
      "macro:\n",
      "precision: 0.6715006305170239, recall: 0.5103383458646616, f1score_macro: 0.275656887920525\n",
      " \n",
      "0.025\n",
      "precision: [1.         0.34386852], recall: [0.02443609 1.        ], f1score: [0.04770642 0.51175917]\n",
      "macro:\n",
      "precision: 0.6719342604298356, recall: 0.5122180451127819, f1score_macro: 0.2797327970863145\n",
      " \n",
      "0.030000000000000002\n",
      "precision: [1.         0.34517766], recall: [0.03007519 1.        ], f1score: [0.05839416 0.51320755]\n",
      "macro:\n",
      "precision: 0.6725888324873096, recall: 0.5150375939849624, f1score_macro: 0.2858008538768765\n",
      " \n",
      "0.034999999999999996\n",
      "precision: [1.         0.34649682], recall: [0.03571429 1.        ], f1score: [0.06896552 0.51466414]\n",
      "macro:\n",
      "precision: 0.6732484076433121, recall: 0.5178571428571429, f1score_macro: 0.291814830522298\n",
      " \n",
      "0.04\n",
      "precision: [1.         0.35051546], recall: [0.05263158 1.        ], f1score: [0.1        0.51908397]\n",
      "macro:\n",
      "precision: 0.6752577319587629, recall: 0.5263157894736842, f1score_macro: 0.3095419847328244\n",
      " \n",
      "0.045\n",
      "precision: [1.         0.35233161], recall: [0.06015038 1.        ], f1score: [0.11347518 0.5210728 ]\n",
      "macro:\n",
      "precision: 0.6761658031088082, recall: 0.5300751879699248, f1score_macro: 0.31727398711991517\n",
      " \n",
      "0.049999999999999996\n",
      "precision: [1.         0.35462842], recall: [0.06954887 1.        ], f1score: [0.13005272 0.52358037]\n",
      "macro:\n",
      "precision: 0.6773142112125163, recall: 0.5347744360902256, f1score_macro: 0.3268165449068068\n",
      " \n",
      "0.055\n",
      "precision: [1.         0.35602094], recall: [0.07518797 1.        ], f1score: [0.13986014 0.52509653]\n",
      "macro:\n",
      "precision: 0.6780104712041884, recall: 0.5375939849624061, f1score_macro: 0.3324783324783325\n",
      " \n",
      "0.06\n",
      "precision: [1.         0.35978836], recall: [0.09022556 1.        ], f1score: [0.16551724 0.52918288]\n",
      "macro:\n",
      "precision: 0.6798941798941799, recall: 0.5451127819548872, f1score_macro: 0.34735006037837113\n",
      " \n",
      "0.065\n",
      "precision: [1.         0.36218375], recall: [0.09962406 1.        ], f1score: [0.18119658 0.53176931]\n",
      "macro:\n",
      "precision: 0.6810918774966711, recall: 0.549812030075188, f1score_macro: 0.35648294357971777\n",
      " \n",
      "0.07\n",
      "precision: [1.         0.36363636], recall: [0.10526316 1.        ], f1score: [0.19047619 0.53333333]\n",
      "macro:\n",
      "precision: 0.6818181818181819, recall: 0.5526315789473684, f1score_macro: 0.3619047619047619\n",
      " \n",
      "0.07500000000000001\n",
      "precision: [1.         0.36608345], recall: [0.11466165 1.        ], f1score: [0.20573356 0.53596059]\n",
      "macro:\n",
      "precision: 0.6830417227456258, recall: 0.5573308270676691, f1score_macro: 0.3708470746558785\n",
      " \n",
      "0.08\n",
      "precision: [0.98550725 0.36870748], recall: [0.12781955 0.99632353], f1score: [0.22628952 0.53823237]\n",
      "macro:\n",
      "precision: 0.6771073646850044, recall: 0.5620715391419726, f1score_macro: 0.3822609454285889\n",
      " \n",
      "0.085\n",
      "precision: [0.97333333 0.37037037], recall: [0.13721805 0.99264706], f1score: [0.24052718 0.53946054]\n",
      "macro:\n",
      "precision: 0.6718518518518519, recall: 0.5649325519681557, f1score_macro: 0.38999386116354817\n",
      " \n",
      "0.09000000000000001\n",
      "precision: [0.97560976 0.37396122], recall: [0.15037594 0.99264706], f1score: [0.26058632 0.54325956]\n",
      "macro:\n",
      "precision: 0.674785487467063, recall: 0.5715114993365767, f1score_macro: 0.4019229382811527\n",
      " \n",
      "0.095\n",
      "precision: [0.97752809 0.37762238], recall: [0.16353383 0.99264706], f1score: [0.28019324 0.54711246]\n",
      "macro:\n",
      "precision: 0.6775752337550089, recall: 0.5780904467049978, f1score_macro: 0.41365284936052743\n",
      " \n",
      "0.1\n",
      "precision: [0.97979798 0.38297872], recall: [0.18233083 0.99264706], f1score: [0.30744849 0.55271238]\n",
      "macro:\n",
      "precision: 0.6813883516011175, recall: 0.5874889429455993, f1score_macro: 0.4300804396524177\n",
      " \n",
      "0.10500000000000001\n",
      "precision: [0.97247706 0.38705036], recall: [0.19924812 0.98897059], f1score: [0.33073323 0.55635988]\n",
      "macro:\n",
      "precision: 0.6797637119662069, recall: 0.594109354268023, f1score_macro: 0.44354655261701675\n",
      " \n",
      "0.11\n",
      "precision: [0.97435897 0.3915575 ], recall: [0.21428571 0.98897059], f1score: [0.35130971 0.56100104]\n",
      "macro:\n",
      "precision: 0.6829582353599821, recall: 0.6016281512605042, f1score_macro: 0.45615537499738906\n",
      " \n",
      "0.115\n",
      "precision: [0.96850394 0.39586411], recall: [0.23120301 0.98529412], f1score: [0.37329287 0.56480506]\n",
      "macro:\n",
      "precision: 0.6821840216797125, recall: 0.6082485625829279, f1score_macro: 0.46904896296876675\n",
      " \n",
      "0.12000000000000001\n",
      "precision: [0.96183206 0.39673105], recall: [0.23684211 0.98161765], f1score: [0.3800905  0.56507937]\n",
      "macro:\n",
      "precision: 0.679281558023207, recall: 0.6092298761609907, f1score_macro: 0.4725849314084607\n",
      " \n",
      "0.125\n",
      "precision: [0.96428571 0.40210843], recall: [0.2537594  0.98161765], f1score: [0.40178571 0.57051282]\n",
      "macro:\n",
      "precision: 0.683197074010327, recall: 0.6176885227775321, f1score_macro: 0.4861492673992674\n",
      " \n",
      "0.13\n",
      "precision: [0.96621622 0.4070122 ], recall: [0.26879699 0.98161765], f1score: [0.42058824 0.57543103]\n",
      "macro:\n",
      "precision: 0.6866142056690837, recall: 0.6252073197700132, f1score_macro: 0.49800963488843814\n",
      " \n",
      "0.135\n",
      "precision: [0.96753247 0.41076923], recall: [0.28007519 0.98161765], f1score: [0.43440233 0.5791757 ]\n",
      "macro:\n",
      "precision: 0.6891508491508491, recall: 0.6308464175143742, f1score_macro: 0.506789018675335\n",
      " \n",
      "0.14\n",
      "precision: [0.96855346 0.41395349], recall: [0.28947368 0.98161765], f1score: [0.44573082 0.5823337 ]\n",
      "macro:\n",
      "precision: 0.6912534737457949, recall: 0.635545665634675, f1score_macro: 0.5140322608644876\n",
      " \n",
      "0.14500000000000002\n",
      "precision: [0.96428571 0.41823899], recall: [0.30451128 0.97794118], f1score: [0.46285714 0.58590308]\n",
      "macro:\n",
      "precision: 0.691262353998203, recall: 0.6412262273330385, f1score_macro: 0.5243801132787917\n",
      " \n",
      "0.15\n",
      "precision: [0.96590909 0.42356688], recall: [0.31954887 0.97794118], f1score: [0.48022599 0.59111111]\n",
      "macro:\n",
      "precision: 0.6947379849449913, recall: 0.6487450243255197, f1score_macro: 0.535668549905838\n",
      " \n",
      "0.155\n",
      "precision: [0.95652174 0.42580645], recall: [0.33082707 0.97058824], f1score: [0.49162011 0.59192825]\n",
      "macro:\n",
      "precision: 0.691164095371669, recall: 0.6507076514816452, f1score_macro: 0.5417741814264598\n",
      " \n",
      "0.16\n",
      "precision: [0.95833333 0.43137255], recall: [0.34586466 0.97058824], f1score: [0.50828729 0.59728507]\n",
      "macro:\n",
      "precision: 0.6948529411764706, recall: 0.6582264484741265, f1score_macro: 0.5527861803454914\n",
      " \n",
      "0.165\n",
      "precision: [0.95959596 0.43564356], recall: [0.35714286 0.97058824], f1score: [0.52054795 0.60136674]\n",
      "macro:\n",
      "precision: 0.6976197619761976, recall: 0.6638655462184874, f1score_macro: 0.5609573439011452\n",
      " \n",
      "0.17\n",
      "precision: [0.95631068 0.43979933], recall: [0.37030075 0.96691176], f1score: [0.53387534 0.6045977 ]\n",
      "macro:\n",
      "precision: 0.6980550053576647, recall: 0.6686062582927907, f1score_macro: 0.5692365199514063\n",
      " \n",
      "0.17500000000000002\n",
      "precision: [0.95260664 0.44182125], recall: [0.37781955 0.96323529], f1score: [0.5410498  0.60578035]\n",
      "macro:\n",
      "precision: 0.6972139414815821, recall: 0.6705274214949137, f1score_macro: 0.573415072468278\n",
      " \n",
      "0.18000000000000002\n",
      "precision: [0.95348837 0.44482173], recall: [0.38533835 0.96323529], f1score: [0.54886212 0.60859466]\n",
      "macro:\n",
      "precision: 0.6991550519208749, recall: 0.6742868199911544, f1score_macro: 0.5787283862511603\n",
      " \n",
      "0.185\n",
      "precision: [0.94618834 0.4475043 ], recall: [0.39661654 0.95588235], f1score: [0.5589404  0.60961313]\n",
      "macro:\n",
      "precision: 0.6968463218665822, recall: 0.67624944714728, f1score_macro: 0.5842767637399751\n",
      " \n",
      "0.19\n",
      "precision: [0.94736842 0.45138889], recall: [0.40601504 0.95588235], f1score: [0.56842105 0.61320755]\n",
      "macro:\n",
      "precision: 0.6993786549707602, recall: 0.6809486952675807, f1score_macro: 0.5908142999006951\n",
      " \n",
      "0.195\n",
      "precision: [0.94871795 0.45614035], recall: [0.41729323 0.95588235], f1score: [0.57963446 0.6175772 ]\n",
      "macro:\n",
      "precision: 0.7024291497975708, recall: 0.6865877930119416, f1score_macro: 0.598605830950801\n",
      " \n",
      "0.2\n",
      "precision: [0.94650206 0.46167558], recall: [0.43233083 0.95220588], f1score: [0.59354839 0.62184874]\n",
      "macro:\n",
      "precision: 0.7040888184679035, recall: 0.6922683547103051, f1score_macro: 0.6076985632962862\n",
      " \n",
      "0.20500000000000002\n",
      "precision: [0.9437751  0.46486486], recall: [0.44172932 0.94852941], f1score: [0.60179257 0.62394196]\n",
      "macro:\n",
      "precision: 0.7043199826332356, recall: 0.6951293675364882, f1score_macro: 0.6128672662555525\n",
      " \n",
      "0.21000000000000002\n",
      "precision: [0.94466403 0.46823956], recall: [0.44924812 0.94852941], f1score: [0.6089172  0.62697448]\n",
      "macro:\n",
      "precision: 0.7064517980244327, recall: 0.6988887660327289, f1score_macro: 0.6179458405244136\n",
      " \n",
      "0.215\n",
      "precision: [0.94552529 0.47166362], recall: [0.45676692 0.94852941], f1score: [0.61596958 0.63003663]\n",
      "macro:\n",
      "precision: 0.7085944557864261, recall: 0.7026481645289695, f1score_macro: 0.6230031058928398\n",
      " \n",
      "0.22\n",
      "precision: [0.94636015 0.47513812], recall: [0.46428571 0.94852941], f1score: [0.62295082 0.63312883]\n",
      "macro:\n",
      "precision: 0.7107491374018331, recall: 0.70640756302521, f1score_macro: 0.6280398270139798\n",
      " \n",
      "0.225\n",
      "precision: [0.94795539 0.48224299], recall: [0.47932331 0.94852941], f1score: [0.63670412 0.6394052 ]\n",
      "macro:\n",
      "precision: 0.7150991904943891, recall: 0.7139263600176913, f1score_macro: 0.6380546621555769\n",
      " \n",
      "0.23\n",
      "precision: [0.94181818 0.48393195], recall: [0.48684211 0.94117647], f1score: [0.64188352 0.639201  ]\n",
      "macro:\n",
      "precision: 0.7128750644440626, recall: 0.7140092879256966, f1score_macro: 0.64054225897925\n",
      " \n",
      "0.23500000000000001\n",
      "precision: [0.93971631 0.48850575], recall: [0.4981203 0.9375   ], f1score: [0.65110565 0.64231738]\n",
      "macro:\n",
      "precision: 0.7141110295915871, recall: 0.7178101503759399, f1score_macro: 0.646711515729148\n",
      " \n",
      "0.24000000000000002\n",
      "precision: [0.94097222 0.49418605], recall: [0.5093985 0.9375   ], f1score: [0.66097561 0.64720812]\n",
      "macro:\n",
      "precision: 0.7175791343669251, recall: 0.7234492481203008, f1score_macro: 0.6540918657917544\n",
      " \n",
      "0.245\n",
      "precision: [0.94217687 0.5       ], recall: [0.52067669 0.9375    ], f1score: [0.67070218 0.65217391]\n",
      "macro:\n",
      "precision: 0.7210884353741497, recall: 0.7290883458646616, f1score_macro: 0.6614380461101168\n",
      " \n",
      "0.25\n",
      "precision: [0.94276094 0.50295858], recall: [0.52631579 0.9375    ], f1score: [0.67551267 0.65468549]\n",
      "macro:\n",
      "precision: 0.7228597613212998, recall: 0.731907894736842, f1score_macro: 0.6650990800429241\n",
      " \n",
      "0.255\n",
      "precision: [0.93708609 0.50398406], recall: [0.53195489 0.93014706], f1score: [0.67865707 0.65374677]\n",
      "macro:\n",
      "precision: 0.7205350782301259, recall: 0.7310509730207873, f1score_macro: 0.6662019221831836\n",
      " \n",
      "0.26\n",
      "precision: [0.9379085  0.50803213], recall: [0.53947368 0.93014706], f1score: [0.6849642  0.65714286]\n",
      "macro:\n",
      "precision: 0.7229703126230411, recall: 0.7348103715170279, f1score_macro: 0.6710535288100921\n",
      " \n",
      "0.265\n",
      "precision: [0.93548387 0.51012146], recall: [0.54511278 0.92647059], f1score: [0.6888361  0.65796345]\n",
      "macro:\n",
      "precision: 0.7228026642288102, recall: 0.7357916850950907, f1score_macro: 0.67339977549413\n",
      " \n",
      "0.27\n",
      "precision: [0.93650794 0.51533742], recall: [0.55451128 0.92647059], f1score: [0.69657615 0.66228647]\n",
      "macro:\n",
      "precision: 0.7259226799104099, recall: 0.7404909332153915, f1score_macro: 0.6794313081495019\n",
      " \n",
      "0.275\n",
      "precision: [0.93375394 0.51540041], recall: [0.55639098 0.92279412], f1score: [0.69729093 0.66139657]\n",
      "macro:\n",
      "precision: 0.7245771769476419, recall: 0.739592547545334, f1score_macro: 0.6793437524732654\n",
      " \n",
      "0.28\n",
      "precision: [0.93478261 0.52074689], recall: [0.56578947 0.92279412], f1score: [0.70491803 0.66578249]\n",
      "macro:\n",
      "precision: 0.7277647483312286, recall: 0.7442917956656347, f1score_macro: 0.6853502630777928\n",
      " \n",
      "0.28500000000000003\n",
      "precision: [0.93188854 0.51975052], recall: [0.56578947 0.91911765], f1score: [0.70409357 0.66401062]\n",
      "macro:\n",
      "precision: 0.7258195323210803, recall: 0.742453560371517, f1score_macro: 0.6840520957107243\n",
      " \n",
      "0.29000000000000004\n",
      "precision: [0.92705167 0.52210526], recall: [0.57330827 0.91176471], f1score: [0.70847851 0.66398929]\n",
      "macro:\n",
      "precision: 0.7245784674452087, recall: 0.7425364882795223, f1score_macro: 0.6862339019259384\n",
      " \n",
      "0.295\n",
      "precision: [0.92192192 0.52229299], recall: [0.57706767 0.90441176], f1score: [0.70982659 0.66218035]\n",
      "macro:\n",
      "precision: 0.7221074577762476, recall: 0.7407397169394073, f1score_macro: 0.6860034697640405\n",
      " \n",
      "0.3\n",
      "precision: [0.92330383 0.52903226], recall: [0.58834586 0.90441176], f1score: [0.71871412 0.66757123]\n",
      "macro:\n",
      "precision: 0.7261680464363879, recall: 0.7463788146837682, f1score_macro: 0.6931426782173051\n",
      " \n",
      "0.305\n",
      "precision: [0.92196532 0.5349345 ], recall: [0.59962406 0.90073529], f1score: [0.72665148 0.67123288]\n",
      "macro:\n",
      "precision: 0.7284499078678345, recall: 0.7501796771340115, f1score_macro: 0.698942178675071\n",
      " \n",
      "0.31\n",
      "precision: [0.92045455 0.53982301], recall: [0.60902256 0.89705882], f1score: [0.73303167 0.67403315]\n",
      "macro:\n",
      "precision: 0.7301387771520514, recall: 0.7530406899601947, f1score_macro: 0.7035324116897077\n",
      " \n",
      "0.315\n",
      "precision: [0.91876751 0.54362416], recall: [0.61654135 0.89338235], f1score: [0.73790776 0.6759388 ]\n",
      "macro:\n",
      "precision: 0.7311958340383133, recall: 0.7549618531623176, f1score_macro: 0.7069232827120532\n",
      " \n",
      "0.32\n",
      "precision: [0.91530055 0.55022831], recall: [0.62969925 0.88602941], f1score: [0.74610245 0.67887324]\n",
      "macro:\n",
      "precision: 0.7327644284751853, recall: 0.7578643299425033, f1score_macro: 0.7124878446626306\n",
      " \n",
      "0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mmilkov2/miniconda3/envs/TextMining_py3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.91152815 0.55452436], recall: [0.63909774 0.87867647], f1score: [0.75138122 0.6799431 ]\n",
      "macro:\n",
      "precision: 0.7330262560415022, recall: 0.7588871074745688, f1score_macro: 0.715662158232673\n",
      " \n",
      "0.33\n",
      "precision: [0.91176471 0.55581395], recall: [0.64097744 0.87867647], f1score: [0.75275938 0.68091168]\n",
      "macro:\n",
      "precision: 0.7337893296853626, recall: 0.7598269570986289, f1score_macro: 0.7168355314050678\n",
      " \n",
      "0.335\n",
      "precision: [0.90765172 0.55764706], recall: [0.64661654 0.87132353], f1score: [0.75521405 0.68005739]\n",
      "macro:\n",
      "precision: 0.7326493869315536, recall: 0.7589700353825741, f1score_macro: 0.7176357196515724\n",
      " \n",
      "0.34\n",
      "precision: [0.90625    0.56190476], recall: [0.65413534 0.86764706], f1score: [0.75982533 0.68208092]\n",
      "macro:\n",
      "precision: 0.734077380952381, recall: 0.7608911985846971, f1score_macro: 0.7209531261832042\n",
      " \n",
      "0.34500000000000003\n",
      "precision: [0.90180879 0.56115108], recall: [0.65601504 0.86029412], f1score: [0.75952122 0.67924528]\n",
      "macro:\n",
      "precision: 0.7314799323332032, recall: 0.7581545776205219, f1score_macro: 0.7193832508674318\n",
      " \n",
      "0.35000000000000003\n",
      "precision: [0.9005102  0.56553398], recall: [0.66353383 0.85661765], f1score: [0.76406926 0.68128655]\n",
      "macro:\n",
      "precision: 0.7330220923320785, recall: 0.7600757408226448, f1score_macro: 0.7226779068884331\n",
      " \n",
      "0.35500000000000004\n",
      "precision: [0.89924433 0.57002457], recall: [0.67105263 0.85294118], f1score: [0.76856835 0.68335788]\n",
      "macro:\n",
      "precision: 0.7346344512591364, recall: 0.7619969040247678, f1score_macro: 0.7259631161509914\n",
      " \n",
      "0.36\n",
      "precision: [0.89578164 0.57356608], recall: [0.67857143 0.84558824], f1score: [0.77219251 0.68350669]\n",
      "macro:\n",
      "precision: 0.7346738612525758, recall: 0.7620798319327731, f1score_macro: 0.7278495999237193\n",
      " \n",
      "0.365\n",
      "precision: [0.89578164 0.57356608], recall: [0.67857143 0.84558824], f1score: [0.77219251 0.68350669]\n",
      "macro:\n",
      "precision: 0.7346738612525758, recall: 0.7620798319327731, f1score_macro: 0.7278495999237193\n",
      " \n",
      "0.37\n",
      "precision: [0.89382716 0.57393484], recall: [0.68045113 0.84191176], f1score: [0.77267876 0.68256334]\n",
      "macro:\n",
      "precision: 0.7338809987932795, recall: 0.7611814462627156, f1score_macro: 0.7276210501537232\n",
      " \n",
      "0.375\n",
      "precision: [0.89434889 0.5768262 ], recall: [0.68421053 0.84191176], f1score: [0.77529286 0.68460389]\n",
      "macro:\n",
      "precision: 0.735587545411223, recall: 0.7630611455108359, f1score_macro: 0.7299483755736711\n",
      " \n",
      "0.38\n",
      "precision: [0.89294404 0.58015267], recall: [0.68984962 0.83823529], f1score: [0.77836691 0.68571429]\n",
      "macro:\n",
      "precision: 0.7365483553425828, recall: 0.7640424590888988, f1score_macro: 0.7320405999091046\n",
      " \n",
      "0.385\n",
      "precision: [0.89423077 0.58762887], recall: [0.69924812 0.83823529], f1score: [0.78481013 0.69090909]\n",
      "macro:\n",
      "precision: 0.7409298176050754, recall: 0.7687417072091995, f1score_macro: 0.7378596087456848\n",
      " \n",
      "0.39\n",
      "precision: [0.89498807 0.59220779], recall: [0.70488722 0.83823529], f1score: [0.78864353 0.69406393]\n",
      "macro:\n",
      "precision: 0.7435979295167839, recall: 0.7715612560813799, f1score_macro: 0.7413537300318338\n",
      " \n",
      "0.395\n",
      "precision: [0.8952381 0.59375  ], recall: [0.70676692 0.83823529], f1score: [0.78991597 0.69512195]\n",
      "macro:\n",
      "precision: 0.7444940476190476, recall: 0.7725011057054401, f1score_macro: 0.7425189588030334\n",
      " \n",
      "0.4\n",
      "precision: [0.8957346  0.59685864], recall: [0.71052632 0.83823529], f1score: [0.79245283 0.69724771]\n",
      "macro:\n",
      "precision: 0.7462966179499269, recall: 0.7743808049535603, f1score_macro: 0.7448502683053488\n",
      " \n",
      "0.405\n",
      "precision: [0.89647059 0.60158311], recall: [0.71616541 0.83823529], f1score: [0.79623824 0.70046083]\n",
      "macro:\n",
      "precision: 0.7490268508458793, recall: 0.7772003538257408, f1score_macro: 0.7483495370035971\n",
      " \n",
      "0.41000000000000003\n",
      "precision: [0.89719626 0.60638298], recall: [0.72180451 0.83823529], f1score: [0.8       0.7037037]\n",
      "macro:\n",
      "precision: 0.7517896202028236, recall: 0.7800199026979213, f1score_macro: 0.7518518518518519\n",
      " \n",
      "0.41500000000000004\n",
      "precision: [0.89559165 0.60857909], recall: [0.72556391 0.83455882], f1score: [0.80166147 0.70387597]\n",
      "macro:\n",
      "precision: 0.7520853679018182, recall: 0.7800613666519239, f1score_macro: 0.7527687217754593\n",
      " \n",
      "0.42000000000000004\n",
      "precision: [0.89400922 0.61081081], recall: [0.72932331 0.83088235], f1score: [0.80331263 0.70404984]\n",
      "macro:\n",
      "precision: 0.7524100137003362, recall: 0.7801028306059266, f1score_macro: 0.753681236818173\n",
      " \n",
      "0.425\n",
      "precision: [0.89497717 0.61748634], recall: [0.73684211 0.83088235], f1score: [0.80824742 0.70846395]\n",
      "macro:\n",
      "precision: 0.7562317538737929, recall: 0.7838622291021672, f1score_macro: 0.7583556862618362\n",
      " \n",
      "0.43\n",
      "precision: [0.89414414 0.625     ], recall: [0.7462406  0.82720588], f1score: [0.81352459 0.71202532]\n",
      "macro:\n",
      "precision: 0.759572072072072, recall: 0.7867232419283503, f1score_macro: 0.7627749533098154\n",
      " \n",
      "0.435\n",
      "precision: [0.89333333 0.63276836], recall: [0.7556391  0.82352941], f1score: [0.81873727 0.71565495]\n",
      "macro:\n",
      "precision: 0.7630508474576272, recall: 0.7895842547545333, f1score_macro: 0.7671961114762205\n",
      " \n",
      "0.44\n",
      "precision: [0.88986784 0.63428571], recall: [0.7593985  0.81617647], f1score: [0.81947262 0.71382637]\n",
      "macro:\n",
      "precision: 0.7620767778477029, recall: 0.7877874834144184, f1score_macro: 0.7666494915961728\n",
      " \n",
      "0.445\n",
      "precision: [0.89106754 0.64347826], recall: [0.76879699 0.81617647], f1score: [0.82542886 0.71961102]\n",
      "macro:\n",
      "precision: 0.7672728994979634, recall: 0.7924867315347192, f1score_macro: 0.7725199404036653\n",
      " \n",
      "0.45\n",
      "precision: [0.89130435 0.64534884], recall: [0.77067669 0.81617647], f1score: [0.8266129  0.72077922]\n",
      "macro:\n",
      "precision: 0.7683265925176946, recall: 0.7934265811587793, f1score_macro: 0.7736960620025136\n",
      " \n",
      "0.455\n",
      "precision: [0.89247312 0.65486726], recall: [0.78007519 0.81617647], f1score: [0.83249749 0.72667758]\n",
      "macro:\n",
      "precision: 0.773670187458369, recall: 0.79812582927908, f1score_macro: 0.77958753510942\n",
      " \n",
      "0.46\n",
      "precision: [0.88865096 0.65281899], recall: [0.78007519 0.80882353], f1score: [0.83083083 0.72249589]\n",
      "macro:\n",
      "precision: 0.7707349773476766, recall: 0.7944493586908448, f1score_macro: 0.7766633628702594\n",
      " \n",
      "0.465\n",
      "precision: [0.88723404 0.65568862], recall: [0.78383459 0.80514706], f1score: [0.83233533 0.72277228]\n",
      "macro:\n",
      "precision: 0.7714613326538413, recall: 0.7944908226448475, f1score_macro: 0.77755380328452\n",
      " \n",
      "0.47000000000000003\n",
      "precision: [0.88559322 0.65662651], recall: [0.78571429 0.80147059], f1score: [0.83266932 0.7218543 ]\n",
      "macro:\n",
      "precision: 0.7711098631815396, recall: 0.79359243697479, f1score_macro: 0.7772618136724625\n",
      " \n",
      "0.47500000000000003\n",
      "precision: [0.88050314 0.65749235], recall: [0.78947368 0.79044118], f1score: [0.83250743 0.71786311]\n",
      "macro:\n",
      "precision: 0.7689977496970746, recall: 0.7899574303405572, f1score_macro: 0.7751852691386867\n",
      " \n",
      "0.48000000000000004\n",
      "precision: [0.87891441 0.65846154], recall: [0.79135338 0.78676471], f1score: [0.83283877 0.71691792]\n",
      "macro:\n",
      "precision: 0.7686879717359885, recall: 0.7890590446704997, f1score_macro: 0.7748783482198331\n",
      " \n",
      "0.485\n",
      "precision: [0.87784679 0.6635514 ], recall: [0.79699248 0.78308824], f1score: [0.83546798 0.71838111]\n",
      "macro:\n",
      "precision: 0.770699096379714, recall: 0.7900403582485626, f1score_macro: 0.7769245466401946\n",
      " \n",
      "0.49\n",
      "precision: [0.87679671 0.66876972], recall: [0.80263158 0.77941176], f1score: [0.83807655 0.71986418]\n",
      "macro:\n",
      "precision: 0.7727832153336918, recall: 0.7910216718266254, f1score_macro: 0.778970361101716\n",
      " \n",
      "0.495\n",
      "precision: [0.87525562 0.66984127], recall: [0.80451128 0.77573529], f1score: [0.83839373 0.71890971]\n",
      "macro:\n",
      "precision: 0.7725484467815755, recall: 0.7901232861565679, f1score_macro: 0.7786517210137371\n",
      " \n",
      "0.5\n",
      "precision: [0.87246964 0.67419355], recall: [0.81015038 0.76838235], f1score: [0.84015595 0.71821306]\n",
      "macro:\n",
      "precision: 0.7733315920073136, recall: 0.7892663644405131, f1score_macro: 0.7791845019191737\n",
      " \n",
      "0.505\n",
      "precision: [0.87323944 0.68078176], recall: [0.81578947 0.76838235], f1score: [0.84353741 0.72193437]\n",
      "macro:\n",
      "precision: 0.7770105977886865, recall: 0.7920859133126935, f1score_macro: 0.782735892284375\n",
      " \n",
      "0.51\n",
      "precision: [0.87025948 0.68316832], recall: [0.81954887 0.76102941], f1score: [0.84414327 0.72      ]\n",
      "macro:\n",
      "precision: 0.7767138989348037, recall: 0.7902891419725785, f1score_macro: 0.7820716360116168\n",
      " \n",
      "0.515\n",
      "precision: [0.86956522 0.69127517], recall: [0.82706767 0.75735294], f1score: [0.8477842  0.72280702]\n",
      "macro:\n",
      "precision: 0.7804201925882697, recall: 0.7922103051747014, f1score_macro: 0.7852956089646081\n",
      " \n",
      "0.52\n",
      "precision: [0.86862745 0.69727891], recall: [0.83270677 0.75367647], f1score: [0.85028791 0.72438163]\n",
      "macro:\n",
      "precision: 0.782953181272509, recall: 0.7931916187527643, f1score_macro: 0.787334766655589\n",
      " \n",
      "0.525\n",
      "precision: [0.86627907 0.70486111], recall: [0.84022556 0.74632353], f1score: [0.85305344 0.725     ]\n",
      "macro:\n",
      "precision: 0.7855700904392765, recall: 0.7932745466607696, f1score_macro: 0.7890267175572518\n",
      " \n",
      "0.53\n",
      "precision: [0.86512524 0.70877193], recall: [0.84398496 0.74264706], f1score: [0.85442436 0.72531418]\n",
      "macro:\n",
      "precision: 0.7869485853361728, recall: 0.7933160106147723, f1score_macro: 0.7898692704391987\n",
      " \n",
      "0.535\n",
      "precision: [0.86538462 0.71126761], recall: [0.84586466 0.74264706], f1score: [0.85551331 0.72661871]\n",
      "macro:\n",
      "precision: 0.7883261105092092, recall: 0.7942558602388323, f1score_macro: 0.7910660065103812\n",
      " \n",
      "0.54\n",
      "precision: [0.86615679 0.71886121], recall: [0.85150376 0.74264706], f1score: [0.85876777 0.73056058]\n",
      "macro:\n",
      "precision: 0.7925089988636596, recall: 0.7970754091110128, f1score_macro: 0.7946641755868464\n",
      " \n",
      "0.545\n",
      "precision: [0.86641221 0.72142857], recall: [0.85338346 0.74264706], f1score: [0.85984848 0.73188406]\n",
      "macro:\n",
      "precision: 0.7939203925845147, recall: 0.7980152587350731, f1score_macro: 0.7958662714097496\n",
      " \n",
      "0.55\n",
      "precision: [0.86527514 0.72563177], recall: [0.85714286 0.73897059], f1score: [0.8611898  0.73224044]\n",
      "macro:\n",
      "precision: 0.7954534556340296, recall: 0.7980567226890756, f1score_macro: 0.7967151194290933\n",
      " \n",
      "0.555\n",
      "precision: [0.86440678 0.73260073], recall: [0.86278195 0.73529412], f1score: [0.8635936  0.73394495]\n",
      "macro:\n",
      "precision: 0.7985037561308748, recall: 0.7990380362671385, f1score_macro: 0.7987692785693943\n",
      " \n",
      "0.56\n",
      "precision: [0.85981308 0.73234201], recall: [0.86466165 0.72426471], f1score: [0.86223055 0.72828096]\n",
      "macro:\n",
      "precision: 0.796077545773547, recall: 0.7944631800088456, f1score_macro: 0.7952557570675984\n",
      " \n",
      "0.5650000000000001\n",
      "precision: [0.86007463 0.73507463], recall: [0.86654135 0.72426471], f1score: [0.86329588 0.72962963]\n",
      "macro:\n",
      "precision: 0.7975746268656716, recall: 0.7954030296329058, f1score_macro: 0.7964627548897212\n",
      " \n",
      "0.5700000000000001\n",
      "precision: [0.85687732 0.73308271], recall: [0.86654135 0.71691176], f1score: [0.86168224 0.72490706]\n",
      "macro:\n",
      "precision: 0.7949800150934958, recall: 0.7917265590446705, f1score_macro: 0.7932946530938403\n",
      " \n",
      "0.5750000000000001\n",
      "precision: [0.85767098 0.74144487], recall: [0.87218045 0.71691176], f1score: [0.86486486 0.72897196]\n",
      "macro:\n",
      "precision: 0.7995579232937174, recall: 0.794546107916851, f1score_macro: 0.7969184137408436\n",
      " \n",
      "0.5800000000000001\n",
      "precision: [0.85504587 0.74517375], recall: [0.87593985 0.70955882], f1score: [0.86536676 0.72693032]\n",
      "macro:\n",
      "precision: 0.8001098083666891, recall: 0.792749336576736, f1score_macro: 0.7961485398339183\n",
      " \n",
      "0.585\n",
      "precision: [0.85374771 0.74708171], recall: [0.87781955 0.70588235], f1score: [0.86561631 0.72589792]\n",
      "macro:\n",
      "precision: 0.8004147134351504, recall: 0.7918509509066785, f1score_macro: 0.7957571160021795\n",
      " \n",
      "0.59\n",
      "precision: [0.84936479 0.74703557], recall: [0.87969925 0.69485294], f1score: [0.86426593 0.72      ]\n",
      "macro:\n",
      "precision: 0.798200182205548, recall: 0.7872760946483857, f1score_macro: 0.7921329639889196\n",
      " \n",
      "0.595\n",
      "precision: [0.84963768 0.75      ], recall: [0.88157895 0.69485294], f1score: [0.86531365 0.72137405]\n",
      "macro:\n",
      "precision: 0.7998188405797102, recall: 0.7882159442724458, f1score_macro: 0.793343849469029\n",
      " \n",
      "0.6\n",
      "precision: [0.84892086 0.75806452], recall: [0.88721805 0.69117647], f1score: [0.86764706 0.72307692]\n",
      "macro:\n",
      "precision: 0.8034926897191924, recall: 0.7891972578505086, f1score_macro: 0.7953619909502263\n",
      " \n",
      "0.605\n",
      "precision: [0.84892086 0.75806452], recall: [0.88721805 0.69117647], f1score: [0.86764706 0.72307692]\n",
      "macro:\n",
      "precision: 0.8034926897191924, recall: 0.7891972578505086, f1score_macro: 0.7953619909502263\n",
      " \n",
      "0.61\n",
      "precision: [0.84642857 0.76229508], recall: [0.89097744 0.68382353], f1score: [0.86813187 0.72093023]\n",
      "macro:\n",
      "precision: 0.8043618266978922, recall: 0.7874004865103936, f1score_macro: 0.7945310503450038\n",
      " \n",
      "0.615\n",
      "precision: [0.84275618 0.76890756], recall: [0.89661654 0.67279412], f1score: [0.86885246 0.71764706]\n",
      "macro:\n",
      "precision: 0.8058318733853966, recall: 0.7847053295002211, f1score_macro: 0.7932497589199614\n",
      " \n",
      "0.62\n",
      "precision: [0.83859649 0.76923077], recall: [0.89849624 0.66176471], f1score: [0.86751361 0.71146245]\n",
      "macro:\n",
      "precision: 0.8039136302294198, recall: 0.7801304732419283, f1score_macro: 0.7894880311040652\n",
      " \n",
      "0.625\n",
      "precision: [0.83797909 0.77826087], recall: [0.90413534 0.65808824], f1score: [0.86980108 0.71314741]\n",
      "macro:\n",
      "precision: 0.8081199818209361, recall: 0.7811117868199912, f1score_macro: 0.791474247674762\n",
      " \n",
      "0.63\n",
      "precision: [0.83419689 0.78222222], recall: [0.90789474 0.64705882], f1score: [0.86948695 0.7082495 ]\n",
      "macro:\n",
      "precision: 0.808209556706966, recall: 0.7774767801857585, f1score_macro: 0.7888682228383804\n",
      " \n",
      "0.635\n",
      "precision: [0.83190395 0.78733032], recall: [0.91165414 0.63970588], f1score: [0.86995516 0.70588235]\n",
      "macro:\n",
      "precision: 0.8096171309267868, recall: 0.7756800088456435, f1score_macro: 0.7879187549459246\n",
      " \n",
      "0.64\n",
      "precision: [0.82571912 0.79342723], recall: [0.91729323 0.62132353], f1score: [0.86910062 0.69690722]\n",
      "macro:\n",
      "precision: 0.8095731750911561, recall: 0.7693083812472357, f1score_macro: 0.7830039199126052\n",
      " \n",
      "0.645\n",
      "precision: [0.82214765 0.79807692], recall: [0.92105263 0.61029412], f1score: [0.86879433 0.69166667]\n",
      "macro:\n",
      "precision: 0.8101122870418173, recall: 0.7656733746130031, f1score_macro: 0.7802304964539006\n",
      " \n",
      "0.65\n",
      "precision: [0.82107023 0.80097087], recall: [0.92293233 0.60661765], f1score: [0.86902655 0.69037657]\n",
      "macro:\n",
      "precision: 0.8110205539500601, recall: 0.7647749889429456, f1score_macro: 0.7797015588551117\n",
      " \n",
      "0.655\n",
      "precision: [0.81727575 0.8019802 ], recall: [0.92481203 0.59558824], f1score: [0.86772487 0.6835443 ]\n",
      "macro:\n",
      "precision: 0.8096279727640538, recall: 0.7602001326846528, f1score_macro: 0.7756345857611681\n",
      " \n",
      "0.66\n",
      "precision: [0.81622517 0.805     ], recall: [0.92669173 0.59191176], f1score: [0.86795775 0.68220339]\n",
      "macro:\n",
      "precision: 0.810612582781457, recall: 0.7593017470145953, f1score_macro: 0.7750805681546908\n",
      " \n",
      "0.665\n",
      "precision: [0.81045752 0.8125    ], recall: [0.93233083 0.57352941], f1score: [0.86713287 0.67241379]\n",
      "macro:\n",
      "precision: 0.8114787581699346, recall: 0.7529301194161875, f1score_macro: 0.7697733301181576\n",
      " \n",
      "0.67\n",
      "precision: [0.80944625 0.81578947], recall: [0.93421053 0.56985294], f1score: [0.86736475 0.67099567]\n",
      "macro:\n",
      "precision: 0.8126178638779359, recall: 0.75203173374613, f1score_macro: 0.7691802089707849\n",
      " \n",
      "0.675\n",
      "precision: [0.80813008 0.81481481], recall: [0.93421053 0.56617647], f1score: [0.86660854 0.6681128 ]\n",
      "macro:\n",
      "precision: 0.8114724480578139, recall: 0.7501934984520124, f1score_macro: 0.7673606711462706\n",
      " \n",
      "0.68\n",
      "precision: [0.80515298 0.82513661], recall: [0.93984962 0.55514706], f1score: [0.86730269 0.66373626]\n",
      "macro:\n",
      "precision: 0.8151447955439403, recall: 0.7474983414418399, f1score_macro: 0.7655194761872992\n",
      " \n",
      "0.685\n",
      "precision: [0.80515298 0.82513661], recall: [0.93984962 0.55514706], f1score: [0.86730269 0.66373626]\n",
      "macro:\n",
      "precision: 0.8151447955439403, recall: 0.7474983414418399, f1score_macro: 0.7655194761872992\n",
      " \n",
      "0.6900000000000001\n",
      "precision: [0.80546624 0.82967033], recall: [0.94172932 0.55514706], f1score: [0.86828423 0.66519824]\n",
      "macro:\n",
      "precision: 0.8175682838062259, recall: 0.7484381910659, f1score_macro: 0.7667412333274799\n",
      " \n",
      "0.6950000000000001\n",
      "precision: [0.80031949 0.8258427 ], recall: [0.94172932 0.54044118], f1score: [0.86528497 0.65333333]\n",
      "macro:\n",
      "precision: 0.8130810927235524, recall: 0.7410852498894294, f1score_macro: 0.7593091537132988\n",
      " \n",
      "0.7000000000000001\n",
      "precision: [0.7977707  0.82386364], recall: [0.94172932 0.53308824], f1score: [0.8637931  0.64732143]\n",
      "macro:\n",
      "precision: 0.8108171685002895, recall: 0.7374087793011941, f1score_macro: 0.7555572660098522\n",
      " \n",
      "0.7050000000000001\n",
      "precision: [0.79809221 0.82857143], recall: [0.94360902 0.53308824], f1score: [0.86477175 0.64876957]\n",
      "macro:\n",
      "precision: 0.8133318192141722, recall: 0.7383486289252543, f1score_macro: 0.7567706617183751\n",
      " \n",
      "0.71\n",
      "precision: [0.79746835 0.8372093 ], recall: [0.94736842 0.52941176], f1score: [0.86597938 0.64864865]\n",
      "macro:\n",
      "precision: 0.8173388283779806, recall: 0.7383900928792569, f1score_macro: 0.7573140150459738\n",
      " \n",
      "0.715\n",
      "precision: [0.79495268 0.83529412], recall: [0.94736842 0.52205882], f1score: [0.864494   0.64253394]\n",
      "macro:\n",
      "precision: 0.8151233995175358, recall: 0.7347136222910217, f1score_macro: 0.753513966610526\n",
      " \n",
      "0.72\n",
      "precision: [0.79245283 0.83333333], recall: [0.94736842 0.51470588], f1score: [0.8630137  0.63636364]\n",
      "macro:\n",
      "precision: 0.8128930817610063, recall: 0.7310371517027863, f1score_macro: 0.7496886674968866\n",
      " \n",
      "0.725\n",
      "precision: [0.79127726 0.85185185], recall: [0.95488722 0.50735294], f1score: [0.86541738 0.6359447 ]\n",
      "macro:\n",
      "precision: 0.8215645552094151, recall: 0.7311200796107917, f1score_macro: 0.7506810384757299\n",
      " \n",
      "0.73\n",
      "precision: [0.79004666 0.85093168], recall: [0.95488722 0.50367647], f1score: [0.86468085 0.63279446]\n",
      "macro:\n",
      "precision: 0.8204891666586169, recall: 0.729281844316674, f1score_macro: 0.7487376541693282\n",
      " \n",
      "0.735\n",
      "precision: [0.7875969 0.8490566], recall: [0.95488722 0.49632353], f1score: [0.86321155 0.62645012]\n",
      "macro:\n",
      "precision: 0.8183267514991956, recall: 0.7256053737284387, f1score_macro: 0.7448308354048103\n",
      " \n",
      "0.74\n",
      "precision: [0.78516229 0.84713376], recall: [0.95488722 0.48897059], f1score: [0.86174724 0.62004662]\n",
      "macro:\n",
      "precision: 0.8161480227212318, recall: 0.7219289031402034, f1score_macro: 0.7408969317366264\n",
      " \n",
      "0.745\n",
      "precision: [0.78274268 0.84516129], recall: [0.95488722 0.48161765], f1score: [0.86028789 0.61358314]\n",
      "macro:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8139519856851732, recall: 0.7182524325519681, f1score_macro: 0.7369355148952879\n",
      " \n",
      "0.75\n",
      "precision: [0.78220859 0.85526316], recall: [0.95864662 0.47794118], f1score: [0.86148649 0.61320755]\n",
      "macro:\n",
      "precision: 0.818735873425896, recall: 0.7182938965059709, f1score_macro: 0.737347016828149\n",
      " \n",
      "0.755\n",
      "precision: [0.77743902 0.85135135], recall: [0.95864662 0.46323529], f1score: [0.85858586 0.6       ]\n",
      "macro:\n",
      "precision: 0.8143951878707976, recall: 0.7109409553295003, f1score_macro: 0.7292929292929293\n",
      " \n",
      "0.76\n",
      "precision: [0.77743902 0.85135135], recall: [0.95864662 0.46323529], f1score: [0.85858586 0.6       ]\n",
      "macro:\n",
      "precision: 0.8143951878707976, recall: 0.7109409553295003, f1score_macro: 0.7292929292929293\n",
      " \n",
      "0.765\n",
      "precision: [0.77659574 0.85616438], recall: [0.96052632 0.45955882], f1score: [0.85882353 0.59808612]\n",
      "macro:\n",
      "precision: 0.8163800641212474, recall: 0.7100425696594427, f1score_macro: 0.7284548269068392\n",
      " \n",
      "0.77\n",
      "precision: [0.7734139  0.85915493], recall: [0.96240602 0.44852941], f1score: [0.85762144 0.58937198]\n",
      "macro:\n",
      "precision: 0.8162844134292158, recall: 0.7054677134011499, f1score_macro: 0.7234967106061709\n",
      " \n",
      "0.775\n",
      "precision: [0.7734139  0.85915493], recall: [0.96240602 0.44852941], f1score: [0.85762144 0.58937198]\n",
      "macro:\n",
      "precision: 0.8162844134292158, recall: 0.7054677134011499, f1score_macro: 0.7234967106061709\n",
      " \n",
      "0.78\n",
      "precision: [0.76796407 0.86029412], recall: [0.96428571 0.43014706], f1score: [0.855      0.57352941]\n",
      "macro:\n",
      "precision: 0.8141290947516732, recall: 0.6972163865546219, f1score_macro: 0.714264705882353\n",
      " \n",
      "0.785\n",
      "precision: [0.76681614 0.85925926], recall: [0.96428571 0.42647059], f1score: [0.85428809 0.57002457]\n",
      "macro:\n",
      "precision: 0.8130377013785086, recall: 0.6953781512605042, f1score_macro: 0.7121563316400952\n",
      " \n",
      "0.79\n",
      "precision: [0.76148148 0.86046512], recall: [0.96616541 0.40808824], f1score: [0.85169843 0.55361596]\n",
      "macro:\n",
      "precision: 0.8109732988802756, recall: 0.6871268244139761, f1score_macro: 0.7026571929744818\n",
      " \n",
      "0.795\n",
      "precision: [0.76070901 0.86614173], recall: [0.96804511 0.40441176], f1score: [0.85194376 0.55137845]\n",
      "macro:\n",
      "precision: 0.8134253713115993, recall: 0.6862284387439186, f1score_macro: 0.7016611006424249\n",
      " \n",
      "0.8\n",
      "precision: [0.75958702 0.86507937], recall: [0.96804511 0.40073529], f1score: [0.85123967 0.54773869]\n",
      "macro:\n",
      "precision: 0.8123331928641664, recall: 0.6843902034498011, f1score_macro: 0.6994891814444122\n",
      " \n",
      "0.805\n",
      "precision: [0.75958702 0.86507937], recall: [0.96804511 0.40073529], f1score: [0.85123967 0.54773869]\n",
      "macro:\n",
      "precision: 0.8123331928641664, recall: 0.6843902034498011, f1score_macro: 0.6994891814444122\n",
      " \n",
      "0.81\n",
      "precision: [0.75846834 0.864     ], recall: [0.96804511 0.39705882], f1score: [0.85053675 0.5440806 ]\n",
      "macro:\n",
      "precision: 0.8112341678939616, recall: 0.6825519681556833, f1score_macro: 0.6973086755122544\n",
      " \n",
      "0.8150000000000001\n",
      "precision: [0.75624082 0.86178862], recall: [0.96804511 0.38970588], f1score: [0.84913438 0.53670886]\n",
      "macro:\n",
      "precision: 0.8090147201031481, recall: 0.678875497567448, f1score_macro: 0.6929216191678755\n",
      " \n",
      "0.8200000000000001\n",
      "precision: [0.75402635 0.85950413], recall: [0.96804511 0.38235294], f1score: [0.84773663 0.52926209]\n",
      "macro:\n",
      "precision: 0.8067652432752925, recall: 0.6751990269792127, f1score_macro: 0.6884993560141991\n",
      " \n",
      "0.8250000000000001\n",
      "precision: [0.75436047 0.88793103], recall: [0.97556391 0.37867647], f1score: [0.85081967 0.53092784]\n",
      "macro:\n",
      "precision: 0.8211457497995189, recall: 0.6771201901813357, f1score_macro: 0.690873753591347\n",
      " \n",
      "0.8300000000000001\n",
      "precision: [0.75362319 0.89473684], recall: [0.97744361 0.375     ], f1score: [0.85106383 0.52849741]\n",
      "macro:\n",
      "precision: 0.8241800152555301, recall: 0.6762218045112782, f1score_macro: 0.6897806195568295\n",
      " \n",
      "0.8350000000000001\n",
      "precision: [0.75072046 0.9       ], recall: [0.97932331 0.36397059], f1score: [0.84991843 0.51832461]\n",
      "macro:\n",
      "precision: 0.8253602305475505, recall: 0.6716469482529854, f1score_macro: 0.6841215206306637\n",
      " \n",
      "0.84\n",
      "precision: [0.74641834 0.89622642], recall: [0.97932331 0.34926471], f1score: [0.84715447 0.5026455 ]\n",
      "macro:\n",
      "precision: 0.8213223766016111, recall: 0.6642940070765149, f1score_macro: 0.674899987095109\n",
      " \n",
      "0.845\n",
      "precision: [0.74216524 0.89215686], recall: [0.97932331 0.33455882], f1score: [0.84440843 0.48663102]\n",
      "macro:\n",
      "precision: 0.8171610524551701, recall: 0.6569410659000442, f1score_macro: 0.665519721959802\n",
      " \n",
      "0.85\n",
      "precision: [0.74147727 0.9       ], recall: [0.98120301 0.33088235], f1score: [0.84466019 0.48387097]\n",
      "macro:\n",
      "precision: 0.8207386363636364, recall: 0.6560426802299867, f1score_macro: 0.6642655809583463\n",
      " \n",
      "0.855\n",
      "precision: [0.73728814 0.89583333], recall: [0.98120301 0.31617647], f1score: [0.84193548 0.4673913 ]\n",
      "macro:\n",
      "precision: 0.8165607344632768, recall: 0.6486897390535161, f1score_macro: 0.654663394109397\n",
      " \n",
      "0.86\n",
      "precision: [0.73314607 0.89130435], recall: [0.98120301 0.30147059], f1score: [0.8392283  0.45054945]\n",
      "macro:\n",
      "precision: 0.8122252076209087, recall: 0.6413367978770456, f1score_macro: 0.6448888731846931\n",
      " \n",
      "0.865\n",
      "precision: [0.73184358 0.90909091], recall: [0.98496241 0.29411765], f1score: [0.83974359 0.44444444]\n",
      "macro:\n",
      "precision: 0.8204672422549517, recall: 0.6395400265369305, f1score_macro: 0.6420940170940171\n",
      " \n",
      "0.87\n",
      "precision: [0.73119777 0.91860465], recall: [0.98684211 0.29044118], f1score: [0.84       0.44134078]\n",
      "macro:\n",
      "precision: 0.8249012113752672, recall: 0.638641640866873, f1score_macro: 0.6406703910614525\n",
      " \n",
      "0.875\n",
      "precision: [0.72916667 0.91666667], recall: [0.98684211 0.28308824], f1score: [0.83865815 0.43258427]\n",
      "macro:\n",
      "precision: 0.8229166666666666, recall: 0.6349651702786377, f1score_macro: 0.6356212083138888\n",
      " \n",
      "0.88\n",
      "precision: [0.72853186 0.92682927], recall: [0.9887218  0.27941176], f1score: [0.83891547 0.42937853]\n",
      "macro:\n",
      "precision: 0.8276805621241808, recall: 0.6340667846085803, f1score_macro: 0.634147000783932\n",
      " \n",
      "0.885\n",
      "precision: [0.72551724 0.92405063], recall: [0.9887218  0.26838235], f1score: [0.83691329 0.41595442]\n",
      "macro:\n",
      "precision: 0.8247839371453514, recall: 0.6285520787262273, f1score_macro: 0.6264338507775262\n",
      " \n",
      "0.89\n",
      "precision: [0.72451791 0.92307692], recall: [0.9887218  0.26470588], f1score: [0.83624801 0.41142857]\n",
      "macro:\n",
      "precision: 0.8237974147065057, recall: 0.6267138434321097, f1score_macro: 0.6238382920735862\n",
      " \n",
      "0.895\n",
      "precision: [0.72093023 0.93150685], recall: [0.9906015 0.25     ], f1score: [0.83452098 0.3942029 ]\n",
      "macro:\n",
      "precision: 0.826218540936604, recall: 0.6203007518796992, f1score_macro: 0.6143619401700575\n",
      " \n",
      "0.9\n",
      "precision: [0.71603261 0.92647059], recall: [0.9906015  0.23161765], f1score: [0.83123028 0.37058824]\n",
      "macro:\n",
      "precision: 0.8212515984654731, recall: 0.611109575409111, f1score_macro: 0.6009092596028949\n",
      " \n",
      "macro 0.7987692785693943\n",
      "F1-valued: 0.7339449541284403\n",
      "recall-valued: 0.7352941176470589\n",
      "0.555\n"
     ]
    }
   ],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d593cd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.86440678 0.73260073], recall: [0.86278195 0.73529412], f1score: [0.8635936  0.73394495]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "37fa9a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7985037561308748, recall: 0.7990380362671385, f1score_macro: 0.7987692785693943\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
