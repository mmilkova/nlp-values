{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3522406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup # AdamW (deprec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30103e31",
   "metadata": {},
   "source": [
    "# 1. Fine-tune rubert-tiny2, extract embeddings and train SVM, LogitBoost, and LogitRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4b1fb",
   "metadata": {},
   "source": [
    "batch_size = 8, epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf9506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model\n",
    "BASE_BERT = 'cointegrated/rubert-tiny2'\n",
    "\n",
    "# data balance\n",
    "major_class_exrta_w = 1.2\n",
    "\n",
    "# data loading\n",
    "max_length = int(2048*0.75)\n",
    "batch_size = 8\n",
    "\n",
    "# train\n",
    "epochs = 5\n",
    "\n",
    "#not random\n",
    "seed_val = 42\n",
    "\n",
    "#save\n",
    "bert_path = f'./temp/models/v2_{batch_size}_{max_length}_{major_class_exrta_w}/'\n",
    "\n",
    "###################\n",
    "# compute on GPU #0\n",
    "device_id = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c8b8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(bert_path)\n",
    "    os.mkdir(bert_path+'epochs')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(bert_path+'epochs')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dea7e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:{}\".format(str(device_id)) if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa5129",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8497c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Думаете, что умеете пользоваться фотошопом?...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...Самое страшное - это когда ты стоишь под х...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Друзья мои! Поддержим дочку моей подруги! Про...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Мой новый дневник, читаем, коментим :)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>РУССКИЙ  КРЫМ - МИФ для быдла! (о чем молчат ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0     Думаете, что умеете пользоваться фотошопом?...    0.0\n",
       "1   ...Самое страшное - это когда ты стоишь под х...    1.0\n",
       "2   Друзья мои! Поддержим дочку моей подруги! Про...    1.0\n",
       "3             Мой новый дневник, читаем, коментим :)    0.0\n",
       "4   РУССКИЙ  КРЫМ - МИФ для быдла! (о чем молчат ...    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold='../data/data_for_binary_classification/'\n",
    "file_='chatGPT_3_instr0_withEx_temp0_train_all_updated.csv'\n",
    "\n",
    "df=pd.read_csv(fold+file_, sep=\"|\", encoding ='utf-8')[['text', 'final_label']] #'label_crowd', 'gpt_result', \n",
    "df=df.rename(columns={'final_label':'label'})\n",
    "print (df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e4d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label = df.label.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d71fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3301\n",
       "1    1734\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine 'doesn't reflect' and 'spam' classes\n",
    "df.label=df.label.replace(3, 0)\n",
    "df.label.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69c2d9",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5543afb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.label.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "792bd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.label.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4209a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63553974, 1.45184544])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_w = compute_class_weight('balanced', classes=df.label.unique(), y=df.label)\n",
    "\n",
    "# fix disbalance to major class\n",
    "major_class_idx = np.argmin(class_w)\n",
    "class_w[major_class_idx] = class_w[major_class_idx]/major_class_exrta_w\n",
    "class_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dcb2b3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5035,), (5035,))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.text\n",
    "Y = df.label\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c2a05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X.values, Y.values, test_size = .20, stratify = Y.values, random_state = 87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0be8557f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4028,), (1007,), 5035)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_val.shape , X_train.shape[0] + X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9277df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 s, sys: 128 ms, total: 4.87 s\n",
      "Wall time: 5.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BASE_BERT, \n",
    "                                          do_lower_case=False)\n",
    "                                          \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    X_train, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length', # можно поставить True  #'max_length'\n",
    "    truncation=True,\n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    X_val, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=False,\n",
    "    padding='max_length',  #'max_length',\n",
    "    truncation=True,\n",
    "    max_length=max_length, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae5d602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(y_train)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(y_val)\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e44fb8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(BASE_BERT,\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd1198d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), #SequentialSampler\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c29014cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33794116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted'), f1_score(labels_flat, preds_flat, average='macro')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)} = {len(y_preds[y_preds==label])/len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ca838004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d748c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0].to(device),\n",
    "                  'attention_mask': batch[1].to(device),\n",
    "                  'labels':         batch[2].to(device),\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c031e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "def save_checpoint(model, optimizer, output_model):\n",
    "    # save\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()}, output_model)\n",
    "\n",
    "# save(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "67411466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2148685f5c340398970074df279d6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "Training loss: 0.6455677735900122\n",
      "Validation loss: 0.6234295635469376\n",
      "F1 Score (Weighted/Macro): (0.656251957711443, 0.6468783185467086)\n",
      "Class: 0\n",
      "Accuracy: 370/660 = 0.5606060606060606\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 284/347 = 0.8184438040345822\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.5627760663037262\n",
      "Validation loss: 0.5686113704291601\n",
      "F1 Score (Weighted/Macro): (0.7084040459663059, 0.6914517516401745)\n",
      "Class: 0\n",
      "Accuracy: 442/660 = 0.6696969696969697\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 264/347 = 0.760806916426513\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.5233887325794924\n",
      "Validation loss: 0.556405167849291\n",
      "F1 Score (Weighted/Macro): (0.7316920650851454, 0.7120496307531641)\n",
      "Class: 0\n",
      "Accuracy: 476/660 = 0.7212121212121212\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 255/347 = 0.7348703170028819\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.5005263998690579\n",
      "Validation loss: 0.563113215660292\n",
      "F1 Score (Weighted/Macro): (0.7297478046872117, 0.7099630338745637)\n",
      "Class: 0\n",
      "Accuracy: 475/660 = 0.7196969696969697\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 254/347 = 0.7319884726224783\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.4895340929340039\n",
      "Validation loss: 0.5619315552333045\n",
      "F1 Score (Weighted/Macro): (0.7324875421414411, 0.7124270358566647)\n",
      "Class: 0\n",
      "Accuracy: 479/660 = 0.7257575757575757\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 253/347 = 0.729106628242075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_w), reduction = 'mean').to(device)\n",
    "scores = {}\n",
    "\n",
    "for epoch in tqdm(range(0,5)): # 1,epochs+1\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0].to(device),\n",
    "                  'attention_mask': batch[1].to(device),\n",
    "                  'labels':         batch[2].to(device),\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs['logits']\n",
    "        \n",
    "        \n",
    "        loss = criterion(logits, inputs['labels'])\n",
    "        loss_train_total += loss.item()    \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "                 \n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1_w, val_f1_macro  = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted/Macro): {(val_f1_w, val_f1_macro)}')\n",
    "    accuracy_per_class(predictions, true_vals)\n",
    "    \n",
    "    scores[epoch] = {'Training loss':loss_train_avg,\n",
    "                     'Validation loss':val_loss,\n",
    "                     'F1 Score (Weighted/Macro)':(val_f1_w, val_f1_macro) \n",
    "                    }\n",
    "    \n",
    "    # save checkpoint\n",
    "    save_checpoint(model, optimizer, bert_path+f'epochs/{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bert_path+f'epochs/scores.json', 'w') as f:\n",
    "    json.dump(scores, f)\n",
    "\n",
    "# load best\n",
    "\n",
    "best_epoch = np.argmin([scores[e]['Validation loss'] for e in scores]) + 1\n",
    "print(f'best_epoch #{best_epoch}')\n",
    "\n",
    "checkpoint = torch.load(bert_path+f'epochs/{best_epoch}', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.save_pretrained(bert_path)\n",
    "tokenizer.save_pretrained(bert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1828b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./temp/models/v2_8_1536_1.2/'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! SAVE MODEL !\n",
    "model.save_pretrained(bert_path)\n",
    "tokenizer.save_pretrained(bert_path)\n",
    "bert_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c798683",
   "metadata": {},
   "source": [
    "## export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61c7b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_path = './models/v2_8_1536_1.2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b81e8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "748c2d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_model = BertModel.from_pretrained(bert_path)\n",
    "# b_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73ebf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_model.save_pretrained(rc_path)\n",
    "# tokenizer.save_pretrained(rc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34a2bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./models/v2_8_1536_1.2/ were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(rc_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(rc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff48f21",
   "metadata": {},
   "source": [
    "Take embeddings forn fine-tuned rubert-tiny2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6ac69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "36cc8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bae82ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a852316cffa54569bd8422fa138aa5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5035 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 6s, sys: 1min 46s, total: 29min 52s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "emb_list = list()\n",
    "it = 0\n",
    "for s in tqdm(df.text.values):\n",
    "    emb_list.append(embed_bert_cls(s, model_emb, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9ed784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018464</td>\n",
       "      <td>-0.025443</td>\n",
       "      <td>-0.005412</td>\n",
       "      <td>-0.067210</td>\n",
       "      <td>-0.008098</td>\n",
       "      <td>-0.042848</td>\n",
       "      <td>0.048566</td>\n",
       "      <td>0.038053</td>\n",
       "      <td>-0.051750</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>-0.137592</td>\n",
       "      <td>-0.063010</td>\n",
       "      <td>-0.102285</td>\n",
       "      <td>-0.017897</td>\n",
       "      <td>0.058684</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.078772</td>\n",
       "      <td>-0.005704</td>\n",
       "      <td>0.041218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087185</td>\n",
       "      <td>-0.013556</td>\n",
       "      <td>0.034466</td>\n",
       "      <td>-0.041398</td>\n",
       "      <td>-0.009335</td>\n",
       "      <td>0.038518</td>\n",
       "      <td>0.072062</td>\n",
       "      <td>-0.126953</td>\n",
       "      <td>0.072556</td>\n",
       "      <td>-0.010305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>0.031439</td>\n",
       "      <td>0.044652</td>\n",
       "      <td>0.031633</td>\n",
       "      <td>-0.081807</td>\n",
       "      <td>-0.021026</td>\n",
       "      <td>-0.011231</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>-0.057428</td>\n",
       "      <td>0.005134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121493</td>\n",
       "      <td>0.024607</td>\n",
       "      <td>-0.038873</td>\n",
       "      <td>-0.034820</td>\n",
       "      <td>-0.033760</td>\n",
       "      <td>-0.023758</td>\n",
       "      <td>0.055283</td>\n",
       "      <td>-0.082305</td>\n",
       "      <td>-0.030336</td>\n",
       "      <td>-0.063620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074011</td>\n",
       "      <td>0.065398</td>\n",
       "      <td>0.025788</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>-0.076790</td>\n",
       "      <td>0.114930</td>\n",
       "      <td>0.083010</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>-0.053610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.020010</td>\n",
       "      <td>0.041242</td>\n",
       "      <td>-0.016424</td>\n",
       "      <td>-0.036992</td>\n",
       "      <td>-0.039034</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.042822</td>\n",
       "      <td>-0.038598</td>\n",
       "      <td>-0.078856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016536</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>-0.130887</td>\n",
       "      <td>0.024420</td>\n",
       "      <td>0.049948</td>\n",
       "      <td>-0.068521</td>\n",
       "      <td>-0.050156</td>\n",
       "      <td>0.030229</td>\n",
       "      <td>0.039134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026711</td>\n",
       "      <td>-0.061871</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>-0.026486</td>\n",
       "      <td>0.046739</td>\n",
       "      <td>-0.060128</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>-0.053569</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000268</td>\n",
       "      <td>-0.096092</td>\n",
       "      <td>-0.059798</td>\n",
       "      <td>-0.059040</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>0.083468</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.097353</td>\n",
       "      <td>0.100729</td>\n",
       "      <td>-0.048607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>0.090720</td>\n",
       "      <td>0.068379</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.037703</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>-0.022078</td>\n",
       "      <td>0.057416</td>\n",
       "      <td>0.074114</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.036362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039732</td>\n",
       "      <td>-0.056965</td>\n",
       "      <td>-0.118393</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>0.018497</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.101765</td>\n",
       "      <td>0.023785</td>\n",
       "      <td>0.004840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>0.143055</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.107946</td>\n",
       "      <td>-0.004803</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.043309</td>\n",
       "      <td>0.042991</td>\n",
       "      <td>-0.025998</td>\n",
       "      <td>0.029961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>-0.007555</td>\n",
       "      <td>-0.065752</td>\n",
       "      <td>0.068371</td>\n",
       "      <td>-0.064800</td>\n",
       "      <td>0.034165</td>\n",
       "      <td>0.053517</td>\n",
       "      <td>-0.010068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>0.124135</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>-0.001954</td>\n",
       "      <td>-0.043581</td>\n",
       "      <td>-0.027300</td>\n",
       "      <td>-0.040936</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>-0.125258</td>\n",
       "      <td>-0.009013</td>\n",
       "      <td>-0.044418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051877</td>\n",
       "      <td>0.048784</td>\n",
       "      <td>0.106491</td>\n",
       "      <td>0.048471</td>\n",
       "      <td>-0.019057</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.046124</td>\n",
       "      <td>-0.033521</td>\n",
       "      <td>0.045135</td>\n",
       "      <td>-0.047027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>-0.040512</td>\n",
       "      <td>-0.012929</td>\n",
       "      <td>-0.042989</td>\n",
       "      <td>0.068927</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.060874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>-0.044231</td>\n",
       "      <td>0.059576</td>\n",
       "      <td>-0.017738</td>\n",
       "      <td>-0.072191</td>\n",
       "      <td>-0.035146</td>\n",
       "      <td>-0.112178</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>-0.006640</td>\n",
       "      <td>-0.064849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.058433</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>-0.033897</td>\n",
       "      <td>-0.067209</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>-0.102263</td>\n",
       "      <td>0.044758</td>\n",
       "      <td>0.110103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>0.076197</td>\n",
       "      <td>0.102915</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>-0.096565</td>\n",
       "      <td>-0.038375</td>\n",
       "      <td>-0.022783</td>\n",
       "      <td>-0.060977</td>\n",
       "      <td>-0.062677</td>\n",
       "      <td>-0.003916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5035 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.018464 -0.025443 -0.005412 -0.067210 -0.008098 -0.042848  0.048566   \n",
       "1     0.087185 -0.013556  0.034466 -0.041398 -0.009335  0.038518  0.072062   \n",
       "2     0.121493  0.024607 -0.038873 -0.034820 -0.033760 -0.023758  0.055283   \n",
       "3    -0.020010  0.041242 -0.016424 -0.036992 -0.039034  0.003855  0.005490   \n",
       "4     0.026711 -0.061871  0.018863 -0.026486  0.046739 -0.060128  0.027036   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5030  0.090720  0.068379  0.007549 -0.037703  0.008094 -0.022078  0.057416   \n",
       "5031  0.143055  0.031883  0.000566 -0.107946 -0.004803 -0.010487  0.043309   \n",
       "5032  0.124135  0.004982 -0.001954 -0.043581 -0.027300 -0.040936  0.006083   \n",
       "5033  0.050855  0.037297  0.013623 -0.040512 -0.012929 -0.042989  0.068927   \n",
       "5034  0.008289  0.058433  0.002247 -0.033897 -0.067209 -0.010444  0.017773   \n",
       "\n",
       "           7         8         9    ...       302       303       304  \\\n",
       "0     0.038053 -0.051750  0.016248  ...  0.013072 -0.137592 -0.063010   \n",
       "1    -0.126953  0.072556 -0.010305  ... -0.009245  0.031439  0.044652   \n",
       "2    -0.082305 -0.030336 -0.063620  ...  0.074011  0.065398  0.025788   \n",
       "3     0.042822 -0.038598 -0.078856  ... -0.016536 -0.062215 -0.011497   \n",
       "4     0.004546 -0.053569  0.005665  ... -0.000268 -0.096092 -0.059798   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5030  0.074114  0.012745  0.036362  ...  0.039732 -0.056965 -0.118393   \n",
       "5031  0.042991 -0.025998  0.029961  ...  0.030708  0.031169  0.063458   \n",
       "5032 -0.125258 -0.009013 -0.044418  ...  0.051877  0.048784  0.106491   \n",
       "5033  0.009016  0.003902  0.060874  ...  0.009632 -0.044231  0.059576   \n",
       "5034 -0.102263  0.044758  0.110103  ... -0.046597  0.076197  0.102915   \n",
       "\n",
       "           305       306       307       308       309       310       311  \n",
       "0    -0.102285 -0.017897  0.058684 -0.000319  0.078772 -0.005704  0.041218  \n",
       "1     0.031633 -0.081807 -0.021026 -0.011231  0.007678 -0.057428  0.005134  \n",
       "2     0.005126  0.049230 -0.076790  0.114930  0.083010  0.026723 -0.053610  \n",
       "3    -0.130887  0.024420  0.049948 -0.068521 -0.050156  0.030229  0.039134  \n",
       "4    -0.059040  0.025562  0.083468  0.007707  0.097353  0.100729 -0.048607  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5030  0.032156  0.018497  0.021067  0.037554  0.101765  0.023785  0.004840  \n",
       "5031 -0.007555 -0.065752  0.068371 -0.064800  0.034165  0.053517 -0.010068  \n",
       "5032  0.048471 -0.019057 -0.011693  0.046124 -0.033521  0.045135 -0.047027  \n",
       "5033 -0.017738 -0.072191 -0.035146 -0.112178  0.042907 -0.006640 -0.064849  \n",
       "5034  0.000366 -0.096565 -0.038375 -0.022783 -0.060977 -0.062677 -0.003916  \n",
       "\n",
       "[5035 rows x 312 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings for train dataset:\n",
    "labels = df[\"label\"]\n",
    "\n",
    "emb_list_ = [np.asarray(s) for s in emb_list]\n",
    "df_emb_=pd.DataFrame(emb_list_)\n",
    "df_emb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd64815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- интересный новый сервис, где можно оставить...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>чет как-то нерадостно все это...особо на фоне...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Repost with . ・・・ жаль что быстро убежала!!!#...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#hellomyearth #дорогажизни #разорванноекольцо</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ВтандемеСМамой#кактампробка#😁</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_test\n",
       "0   - интересный новый сервис, где можно оставить...           1\n",
       "1   чет как-то нерадостно все это...особо на фоне...           0\n",
       "2  #Repost with . ・・・ жаль что быстро убежала!!!#...           0\n",
       "3      #hellomyearth #дорогажизни #разорванноекольцо           0\n",
       "4                     #ВтандемеСМамой#кактампробка#😁           0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trial dataset\n",
    "\n",
    "file_test='all_merged_temp0_instr0_withEx_test_final_label.csv'\n",
    "\n",
    "test_data=pd.read_csv(fold+file_test, sep=\"|\", encoding ='utf-8')[['text', 'final_label']]\n",
    "test_data=test_data.rename(columns={'final_label':'label_test'})\n",
    "print (test_data.shape[0])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ace1a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    532\n",
       "1    272\n",
       "Name: label_test, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.replace({'label_test': {3: 0}}, inplace=True)\n",
    "test_data.label_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4b75170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b59cbe17d445148153054bed8d0821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 16s, sys: 15.8 s, total: 4min 32s\n",
      "Wall time: 6.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "emb_list_test = list()\n",
    "it = 0\n",
    "for s in tqdm(test_data.text.values):\n",
    "    emb_list_test.append(embed_bert_cls(s, model_emb, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b32b1d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.047982</td>\n",
       "      <td>-0.007989</td>\n",
       "      <td>0.019273</td>\n",
       "      <td>-0.064445</td>\n",
       "      <td>-0.047470</td>\n",
       "      <td>0.079242</td>\n",
       "      <td>-0.094084</td>\n",
       "      <td>0.037180</td>\n",
       "      <td>0.049691</td>\n",
       "      <td>-0.039148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050658</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>-0.030989</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>-0.025440</td>\n",
       "      <td>0.075424</td>\n",
       "      <td>0.062284</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.038568</td>\n",
       "      <td>-0.067602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048708</td>\n",
       "      <td>0.038768</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>-0.043480</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>-0.074801</td>\n",
       "      <td>0.068448</td>\n",
       "      <td>-0.029761</td>\n",
       "      <td>0.038171</td>\n",
       "      <td>-0.086254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>-0.086703</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>-0.156870</td>\n",
       "      <td>0.034332</td>\n",
       "      <td>0.029744</td>\n",
       "      <td>-0.051479</td>\n",
       "      <td>0.020975</td>\n",
       "      <td>-0.005021</td>\n",
       "      <td>-0.045287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046934</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>-0.034438</td>\n",
       "      <td>-0.060966</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.076556</td>\n",
       "      <td>-0.046489</td>\n",
       "      <td>-0.026749</td>\n",
       "      <td>-0.019772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>-0.030804</td>\n",
       "      <td>-0.031761</td>\n",
       "      <td>-0.056468</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.162177</td>\n",
       "      <td>-0.056490</td>\n",
       "      <td>0.092742</td>\n",
       "      <td>0.047726</td>\n",
       "      <td>-0.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044973</td>\n",
       "      <td>-0.031754</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>-0.088200</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>0.086622</td>\n",
       "      <td>0.048924</td>\n",
       "      <td>-0.041500</td>\n",
       "      <td>-0.050908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058033</td>\n",
       "      <td>-0.037874</td>\n",
       "      <td>-0.066198</td>\n",
       "      <td>-0.072266</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>0.040231</td>\n",
       "      <td>-0.079380</td>\n",
       "      <td>0.028450</td>\n",
       "      <td>0.032081</td>\n",
       "      <td>0.027410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019812</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>-0.081504</td>\n",
       "      <td>-0.021689</td>\n",
       "      <td>-0.016962</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>0.072162</td>\n",
       "      <td>-0.058702</td>\n",
       "      <td>-0.041161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032649</td>\n",
       "      <td>-0.088169</td>\n",
       "      <td>-0.050347</td>\n",
       "      <td>-0.059466</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>0.087201</td>\n",
       "      <td>-0.081285</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.088323</td>\n",
       "      <td>-0.029691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.101509</td>\n",
       "      <td>-0.086583</td>\n",
       "      <td>0.037290</td>\n",
       "      <td>-0.097883</td>\n",
       "      <td>-0.067217</td>\n",
       "      <td>-0.012579</td>\n",
       "      <td>0.081658</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>-0.060402</td>\n",
       "      <td>-0.037441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020561</td>\n",
       "      <td>-0.054927</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.079025</td>\n",
       "      <td>0.088163</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.089325</td>\n",
       "      <td>0.038812</td>\n",
       "      <td>0.045627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.015678</td>\n",
       "      <td>-0.010740</td>\n",
       "      <td>-0.001362</td>\n",
       "      <td>-0.025951</td>\n",
       "      <td>-0.016946</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>0.062379</td>\n",
       "      <td>0.035687</td>\n",
       "      <td>-0.057801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027969</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>-0.050198</td>\n",
       "      <td>-0.040739</td>\n",
       "      <td>0.081978</td>\n",
       "      <td>0.084395</td>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>-0.015127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.017429</td>\n",
       "      <td>-0.018824</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>-0.043123</td>\n",
       "      <td>0.043978</td>\n",
       "      <td>-0.012925</td>\n",
       "      <td>-0.038624</td>\n",
       "      <td>0.043852</td>\n",
       "      <td>-0.117673</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-0.078440</td>\n",
       "      <td>-0.072294</td>\n",
       "      <td>-0.057007</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>-0.018018</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.067275</td>\n",
       "      <td>-0.090942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>-0.004265</td>\n",
       "      <td>0.044574</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>-0.093753</td>\n",
       "      <td>-0.026876</td>\n",
       "      <td>0.010413</td>\n",
       "      <td>-0.004832</td>\n",
       "      <td>0.034466</td>\n",
       "      <td>-0.071080</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>-0.076574</td>\n",
       "      <td>0.039202</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.040497</td>\n",
       "      <td>-0.113724</td>\n",
       "      <td>0.067692</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>-0.046457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.163189</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>-0.092622</td>\n",
       "      <td>-0.071083</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>-0.021714</td>\n",
       "      <td>-0.060533</td>\n",
       "      <td>0.053720</td>\n",
       "      <td>0.033975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.032454</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.079011</td>\n",
       "      <td>-0.049759</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>-0.021592</td>\n",
       "      <td>-0.008963</td>\n",
       "      <td>-0.052697</td>\n",
       "      <td>-0.016109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -0.047982 -0.007989  0.019273 -0.064445 -0.047470  0.079242 -0.094084   \n",
       "1    0.048708  0.038768  0.008993 -0.043480 -0.011525 -0.074801  0.068448   \n",
       "2    0.046934 -0.007776 -0.034438 -0.060966  0.001300 -0.036679  0.076556   \n",
       "3   -0.044973 -0.031754  0.013514 -0.088200  0.005767  0.006182  0.086622   \n",
       "4    0.019812  0.003509  0.010675 -0.081504 -0.021689 -0.016962  0.031124   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "799  0.101509 -0.086583  0.037290 -0.097883 -0.067217 -0.012579  0.081658   \n",
       "800  0.015678 -0.010740 -0.001362 -0.025951 -0.016946  0.006844 -0.015210   \n",
       "801  0.017429 -0.018824  0.004258 -0.043123  0.043978 -0.012925 -0.038624   \n",
       "802 -0.004265  0.044574  0.046853 -0.093753 -0.026876  0.010413 -0.004832   \n",
       "803  0.163189  0.033339  0.033599 -0.092622 -0.071083  0.030324 -0.021714   \n",
       "\n",
       "          7         8         9    ...       302       303       304  \\\n",
       "0    0.037180  0.049691 -0.039148  ...  0.050658 -0.002591 -0.030989   \n",
       "1   -0.029761  0.038171 -0.086254  ...  0.015159 -0.086703  0.058923   \n",
       "2   -0.046489 -0.026749 -0.019772  ...  0.004219 -0.030804 -0.031761   \n",
       "3    0.048924 -0.041500 -0.050908  ... -0.058033 -0.037874 -0.066198   \n",
       "4    0.072162 -0.058702 -0.041161  ... -0.032649 -0.088169 -0.050347   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "799  0.014439 -0.060402 -0.037441  ... -0.020561 -0.054927  0.003964   \n",
       "800  0.062379  0.035687 -0.057801  ... -0.027969 -0.004778 -0.050198   \n",
       "801  0.043852 -0.117673  0.061700  ...  0.001252 -0.078440 -0.072294   \n",
       "802  0.034466 -0.071080  0.073750  ...  0.043476 -0.076574  0.039202   \n",
       "803 -0.060533  0.053720  0.033975  ...  0.000949  0.032454 -0.001005   \n",
       "\n",
       "          305       306       307       308       309       310       311  \n",
       "0    0.011156 -0.025440  0.075424  0.062284  0.021909  0.038568 -0.067602  \n",
       "1   -0.156870  0.034332  0.029744 -0.051479  0.020975 -0.005021 -0.045287  \n",
       "2   -0.056468  0.068399  0.162177 -0.056490  0.092742  0.047726 -0.021333  \n",
       "3   -0.072266  0.083422  0.040231 -0.079380  0.028450  0.032081  0.027410  \n",
       "4   -0.059466  0.042321  0.087201 -0.081285  0.027309  0.088323 -0.029691  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "799 -0.058199  0.079025  0.088163  0.000104  0.089325  0.038812  0.045627  \n",
       "800 -0.040739  0.081978  0.084395  0.013094  0.002331  0.059930 -0.015127  \n",
       "801 -0.057007  0.068025  0.063575 -0.018018  0.005897  0.067275 -0.090942  \n",
       "802  0.005576 -0.015504  0.040497 -0.113724  0.067692  0.015220 -0.046457  \n",
       "803  0.079011 -0.049759  0.009575 -0.021592 -0.008963 -0.052697 -0.016109  \n",
       "\n",
       "[804 rows x 312 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings for trial dataset:\n",
    "    \n",
    "labels_test=test_data['label_test']\n",
    "emb_list_test_ = [np.asarray(s) for s in emb_list_test]\n",
    "df_emb_test_=pd.DataFrame(emb_list_test_)\n",
    "df_emb_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings were pre-saved:\n",
    "# fold='../data/data_for_binary_classification/'\n",
    "# df_emb_.to_csv(fold+'embeddings312_RuTiny2_train.csv', sep='|', encoding='utf-8', index=False)\n",
    "# df_emb_test_.to_csv(fold+'embeddings312_RuTiny2_test.csv', sep='|', encoding='utf-8', index=False)\n",
    "\n",
    "# so we can just load them:\n",
    "# df_emb_loaded=pd.read_csv(fold+'embeddings312_RuTiny2_train.csv', sep='|', encoding='utf-8')\n",
    "# df_emb_loaded_test=pd.read_csv(fold+'embeddings312_RuTiny2_test.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc39dc6",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b49d4ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76264768, 1.45184544])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1a89c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight={0: 0.7626476825204483,\n",
       "                                         1: 1.4518454440599768},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [1], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight={0: 0.7626476825204483,\n",
       "                                         1: 1.4518454440599768},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [1], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;poly&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7626476825204483, 1: 1.4518454440599768},\n",
       "    probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7626476825204483, 1: 1.4518454440599768},\n",
       "    probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight={0: 0.7626476825204483,\n",
       "                                         1: 1.4518454440599768},\n",
       "                           probability=True),\n",
       "             param_grid={'C': [1], 'gamma': [1], 'kernel': ['poly']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameteres = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "clf = GridSearchCV(SVC(class_weight={0:class_weight[0], 1:class_weight[1]}, probability=True), param_grid=parameteres , cv=5, scoring='f1_macro')\n",
    "clf.fit(df_emb_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40864039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(clf.best_params_))\n",
    "print(\"CV score=%0.3f\" % clf.best_score_)\n",
    "cv_results = clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b1c42c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=clf.predict_proba(df_emb_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c81e164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def TestCutoff(df):\n",
    "\n",
    "    cut_off_list_=np.arange(0.005, 0.901, 0.005)\n",
    "#     cut_off_list = itertools.chain([0.01], cut_off_list_)\n",
    "    \n",
    "    f1score_macro_list=[]\n",
    "    f1score_list=[]\n",
    "    recall_list=[]\n",
    "    \n",
    "    predict_list_list=[[]]\n",
    "    for i, cut_off in enumerate(cut_off_list_):\n",
    "        predict_list=np.where(df['predict_1']>cut_off, 1, 0)\n",
    "        predict_list_list.append(predict_list)\n",
    "        print (cut_off)\n",
    "        precision, recall, f1score = precision_recall_fscore_support(df['label_test'], predict_list)[:3]\n",
    "        print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')\n",
    "        f1score_list.append(f1score[1])\n",
    "        recall_list.append(recall[1])\n",
    "        print (\"macro:\")\n",
    "        precision, recall, f1score_macro = precision_recall_fscore_support(df['label_test'], predict_list, average='macro')[:3]\n",
    "        print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score_macro}')\n",
    "        f1score_macro_list.append(f1score_macro)\n",
    "        print (\" \")\n",
    "    \n",
    "    max_ind=f1score_macro_list.index(max(f1score_macro_list))   \n",
    "    print (\"macro\", f1score_macro_list[max_ind])\n",
    "    print (\"F1-valued:\", f1score_list[max_ind])\n",
    "    print (\"recall-valued:\", recall_list[max_ind])\n",
    "    print (cut_off_list_[max_ind])\n",
    "    \n",
    "    df['predict']=predict_list_list[max_ind+1]\n",
    "        \n",
    "    return (df)\n",
    "#         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de725b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "for res in y_predict:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9042cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.875      0.78461538], recall: [0.89473684 0.75      ], f1score: [0.88475836 0.76691729]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "383dd5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8298076923076922, recall: 0.8223684210526316, f1score_macro: 0.8258378287726752\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc3628",
   "metadata": {},
   "source": [
    "# Prediction for the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54b7b2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Анамалия близ Чернобыля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>и кто осмелится прекратить этот разбой? откров...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Никогда не выравайся от парня, если не уверенн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ураааа)))Я опять у Риты.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Может, она и приврала. Может, она и слабохарак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73276</th>\n",
       "      <td>Наши рубашки представлены на благотворительном...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73277</th>\n",
       "      <td>Айка итии ба5айы дьи!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73278</th>\n",
       "      <td>и все великие когда-то делали первые шаги на п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73279</th>\n",
       "      <td>#Repost with . ・・・ USSR ballet The Queens proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73280</th>\n",
       "      <td>По поступкам видно,как тебя ценят.По звонкам —...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73281 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                Анамалия близ Чернобыля\n",
       "1      и кто осмелится прекратить этот разбой? откров...\n",
       "2      Никогда не выравайся от парня, если не уверенн...\n",
       "3                               Ураааа)))Я опять у Риты.\n",
       "4      Может, она и приврала. Может, она и слабохарак...\n",
       "...                                                  ...\n",
       "73276  Наши рубашки представлены на благотворительном...\n",
       "73277                              Айка итии ба5айы дьи!\n",
       "73278  и все великие когда-то делали первые шаги на п...\n",
       "73279  #Repost with . ・・・ USSR ballet The Queens proj...\n",
       "73280  По поступкам видно,как тебя ценят.По звонкам —...\n",
       "\n",
       "[73281 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the best model\n",
    "# Load main dataset:\n",
    "f='../data/'\n",
    "file='data_for_labeling_cleaned.csv'\n",
    "data_full=pd.read_csv(f+file, sep=\"|\", encoding ='utf-8')[['text']]\n",
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dc85ffd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb64329674ae4057a612e82e7165e3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 31min 24s, sys: 23min 34s, total: 6h 54min 58s\n",
      "Wall time: 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "emb_list_full = list()\n",
    "it = 0\n",
    "for s in tqdm(data_full['text']):\n",
    "    emb_list_full.append(embed_bert_cls(s, model_emb, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "59fb326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_full=clf.predict_proba(emb_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3c82a0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predict_0</th>\n",
       "      <th>predict_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Анамалия близ Чернобыля</td>\n",
       "      <td>0.780301</td>\n",
       "      <td>0.219699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>и кто осмелится прекратить этот разбой? откров...</td>\n",
       "      <td>0.789129</td>\n",
       "      <td>0.210871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Никогда не выравайся от парня, если не уверенн...</td>\n",
       "      <td>0.400666</td>\n",
       "      <td>0.599334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ураааа)))Я опять у Риты.</td>\n",
       "      <td>0.943565</td>\n",
       "      <td>0.056435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Может, она и приврала. Может, она и слабохарак...</td>\n",
       "      <td>0.180333</td>\n",
       "      <td>0.819667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73280</th>\n",
       "      <td>Наши рубашки представлены на благотворительном...</td>\n",
       "      <td>0.801630</td>\n",
       "      <td>0.198370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73281</th>\n",
       "      <td>Айка итии ба5айы дьи!</td>\n",
       "      <td>0.936358</td>\n",
       "      <td>0.063642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73282</th>\n",
       "      <td>и все великие когда-то делали первые шаги на п...</td>\n",
       "      <td>0.343873</td>\n",
       "      <td>0.656127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73283</th>\n",
       "      <td>#Repost with . ・・・ USSR ballet The Queens proj...</td>\n",
       "      <td>0.940227</td>\n",
       "      <td>0.059773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73284</th>\n",
       "      <td>По поступкам видно,как тебя ценят.По звонкам —...</td>\n",
       "      <td>0.104769</td>\n",
       "      <td>0.895231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  predict_0  predict_1\n",
       "0                                Анамалия близ Чернобыля   0.780301   0.219699\n",
       "1      и кто осмелится прекратить этот разбой? откров...   0.789129   0.210871\n",
       "2      Никогда не выравайся от парня, если не уверенн...   0.400666   0.599334\n",
       "3                               Ураааа)))Я опять у Риты.   0.943565   0.056435\n",
       "4      Может, она и приврала. Может, она и слабохарак...   0.180333   0.819667\n",
       "...                                                  ...        ...        ...\n",
       "73280  Наши рубашки представлены на благотворительном...   0.801630   0.198370\n",
       "73281                              Айка итии ба5айы дьи!   0.936358   0.063642\n",
       "73282  и все великие когда-то делали первые шаги на п...   0.343873   0.656127\n",
       "73283  #Repost with . ・・・ USSR ballet The Queens proj...   0.940227   0.059773\n",
       "73284  По поступкам видно,как тебя ценят.По звонкам —...   0.104769   0.895231\n",
       "\n",
       "[73285 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_predict_full:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "data_full['predict_0']=predictions0\n",
    "data_full['predict_1']=predictions1\n",
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48bfe9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off=0.420\n",
    "predict_list=[]\n",
    "predict_list=np.where(data_full['predict_1']>cut_off, 1, 0)\n",
    "predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d8b4d59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49985\n",
       "1    23300\n",
       "Name: predict, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full['predict']=predict_list\n",
    "data_full.predict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5a278100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.682063\n",
       "1    0.317937\n",
       "Name: predict, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.predict.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d6da9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.to_csv(f+'predicted_73285_2classes', sep='|', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c4983",
   "metadata": {},
   "source": [
    "# Logit Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caa1f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "598a7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('LogitBoost', LogitBoost())]\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps) # define the pipeline object.\n",
    "\n",
    "parameteres = {'LogitBoost__n_estimators':range(10,100,10)}\n",
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e72a4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogitBoost</label><div class=\"sk-toggleable__content\"><pre>LogitBoost()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('LogitBoost', LogitBoost())]),\n",
       "             param_grid={'LogitBoost__n_estimators': range(10, 100, 10)})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_emb_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b589f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(grid.best_params_))\n",
    "print(\"CV score=%0.3f\" % grid.best_score_)\n",
    "cv_results = grid.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bdf883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict_proba(df_emb_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e695f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.87406015 0.75367647], recall: [0.87406015 0.75367647], f1score: [0.87406015 0.75367647]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d915b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8138683104820876, recall: 0.8138683104820876, f1score_macro: 0.8138683104820876\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015a2ad",
   "metadata": {},
   "source": [
    "# Logit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c2afd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb942417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76264768, 1.45184544])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f93cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 10, 50), \"penalty\":[\"l1\",\"l2\"]}  #high C means \"Trust this training data a lot\", while a low value says \"This data may not be fully representative of the real world data, so if it's telling you to make a parameter really large, don't listen to it\"\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight={0:class_weight[0], 1:class_weight[1]}), parameters, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(df_emb_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(grid_search.best_params_))\n",
    "print(\"CV score=%0.3f\" % grid_search.best_score_)\n",
    "cv_resultsl = grid_search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb5618f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict_proba(df_emb_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61960c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05439ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.87977099 0.74642857], recall: [0.86654135 0.76838235], f1score: [0.87310606 0.75724638]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92362b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8130997818974919, recall: 0.8174618531623176, f1score_macro: 0.8151762187088274\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c506b6",
   "metadata": {},
   "source": [
    "# 2. Train models based on 768-embeddings from rubert-base-cased-conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af6f483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\", model_max_length=512) \n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "51a11bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d47a6d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e113d8575dad41c693b3afef1e900ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5035 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 49min 11s, sys: 29.2 s, total: 1h 49min 41s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "emb_list = list()\n",
    "it = 0\n",
    "for s in tqdm(df.text):\n",
    "    emb_list.append(embed_bert_cls(s, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1436799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d05253ba2c4308ba71ad91629d8593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 33s, sys: 2.04 s, total: 15min 35s\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "emb_list_test = list()\n",
    "it = 0\n",
    "for s in tqdm(test_data.text):\n",
    "    emb_list_test.append(embed_bert_cls(s, model, tokenizer))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76cc17a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018975</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.036334</td>\n",
       "      <td>0.015108</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.070605</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.029897</td>\n",
       "      <td>-0.054324</td>\n",
       "      <td>0.017511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>-0.002973</td>\n",
       "      <td>-0.052835</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.025775</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.038878</td>\n",
       "      <td>0.027940</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>-0.037016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019812</td>\n",
       "      <td>-0.028492</td>\n",
       "      <td>-0.041963</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.050236</td>\n",
       "      <td>-0.015364</td>\n",
       "      <td>-0.011181</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.040616</td>\n",
       "      <td>-0.001826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.053429</td>\n",
       "      <td>-0.044758</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>-0.034485</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>-0.038578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.012166</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>-0.017159</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>-0.033347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>-0.054655</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>-0.014621</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>-0.017654</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025476</td>\n",
       "      <td>-0.018142</td>\n",
       "      <td>-0.087044</td>\n",
       "      <td>0.013581</td>\n",
       "      <td>0.045457</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>-0.006145</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>-0.035447</td>\n",
       "      <td>0.023708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.026365</td>\n",
       "      <td>-0.060281</td>\n",
       "      <td>-0.017085</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>-0.012635</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>-0.003479</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>-0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.067215</td>\n",
       "      <td>-0.015028</td>\n",
       "      <td>-0.102502</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.062075</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>-0.046282</td>\n",
       "      <td>0.038958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020768</td>\n",
       "      <td>0.039588</td>\n",
       "      <td>-0.055771</td>\n",
       "      <td>-0.049322</td>\n",
       "      <td>0.053859</td>\n",
       "      <td>-0.026940</td>\n",
       "      <td>0.021567</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>-0.065772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>-0.016395</td>\n",
       "      <td>-0.030579</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>-0.001894</td>\n",
       "      <td>0.033167</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>-0.084536</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.033067</td>\n",
       "      <td>-0.025002</td>\n",
       "      <td>-0.007566</td>\n",
       "      <td>0.049071</td>\n",
       "      <td>-0.008988</td>\n",
       "      <td>0.049975</td>\n",
       "      <td>0.048090</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>-0.061774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.005312</td>\n",
       "      <td>0.010221</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>-0.044771</td>\n",
       "      <td>0.064974</td>\n",
       "      <td>-0.050657</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.069418</td>\n",
       "      <td>-0.041314</td>\n",
       "      <td>-0.028628</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>0.040237</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>-0.065933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>-0.049334</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.075015</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.025788</td>\n",
       "      <td>0.034515</td>\n",
       "      <td>-0.013789</td>\n",
       "      <td>0.051053</td>\n",
       "      <td>-0.015268</td>\n",
       "      <td>0.065273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036013</td>\n",
       "      <td>0.036438</td>\n",
       "      <td>-0.067699</td>\n",
       "      <td>-0.045244</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.018512</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>-0.019662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.034859</td>\n",
       "      <td>-0.024992</td>\n",
       "      <td>-0.019697</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>-0.005210</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>-0.004088</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032225</td>\n",
       "      <td>-0.013915</td>\n",
       "      <td>-0.017380</td>\n",
       "      <td>-0.023246</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>-0.019785</td>\n",
       "      <td>-0.003043</td>\n",
       "      <td>-0.040094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>-0.001773</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>0.034181</td>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.034068</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>-0.046417</td>\n",
       "      <td>-0.004134</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.042404</td>\n",
       "      <td>-0.054164</td>\n",
       "      <td>0.028859</td>\n",
       "      <td>0.032703</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>-0.018504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5035 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     0.018975 -0.001351 -0.036334  0.015108  0.000549  0.070605  0.066554   \n",
       "1     0.019812 -0.028492 -0.041963  0.012508  0.050236 -0.015364 -0.011181   \n",
       "2    -0.012166  0.011635 -0.017159  0.002655  0.044597 -0.002403 -0.000588   \n",
       "3    -0.025476 -0.018142 -0.087044  0.013581  0.045457  0.025133 -0.006145   \n",
       "4    -0.067215 -0.015028 -0.102502  0.009260  0.062075  0.012592  0.008576   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5030 -0.016395 -0.030579 -0.011700 -0.002913 -0.001894  0.033167  0.025396   \n",
       "5031 -0.002448 -0.005312  0.010221  0.041342  0.038213  0.014441 -0.044771   \n",
       "5032 -0.049334  0.000191 -0.075015  0.012169  0.025788  0.034515 -0.013789   \n",
       "5033  0.008010  0.003892  0.034859 -0.024992 -0.019697  0.008717 -0.005210   \n",
       "5034 -0.001773  0.022180  0.034181 -0.013939  0.034068  0.003047  0.024510   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0     0.029897 -0.054324  0.017511  ...  0.016930 -0.002973 -0.052835   \n",
       "1     0.004569  0.040616 -0.001826  ...  0.007038  0.053429 -0.044758   \n",
       "2    -0.000590  0.006924 -0.033347  ... -0.000399 -0.016995 -0.054655   \n",
       "3     0.012807 -0.035447  0.023708  ...  0.007615  0.026365 -0.060281   \n",
       "4     0.021265 -0.046282  0.038958  ...  0.020768  0.039588 -0.055771   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5030 -0.002383 -0.084536  0.012031  ...  0.021289  0.033067 -0.025002   \n",
       "5031  0.064974 -0.050657  0.013742  ...  0.009452  0.069418 -0.041314   \n",
       "5032  0.051053 -0.015268  0.065273  ... -0.036013  0.036438 -0.067699   \n",
       "5033  0.037962 -0.004088  0.024534  ...  0.032225 -0.013915 -0.017380   \n",
       "5034 -0.046417 -0.004134 -0.000196  ...  0.008594  0.004026 -0.042404   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0     0.018066  0.025775  0.002032  0.038878  0.027940  0.015232 -0.037016  \n",
       "1    -0.001870  0.011583  0.002814 -0.034485 -0.001803  0.025618 -0.038578  \n",
       "2     0.000128 -0.000498 -0.014621  0.002692 -0.017654  0.016672  0.000137  \n",
       "3    -0.017085  0.006862 -0.012635  0.010918 -0.003479  0.002557 -0.004744  \n",
       "4    -0.049322  0.053859 -0.026940  0.021567  0.000866  0.027638 -0.065772  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5030 -0.007566  0.049071 -0.008988  0.049975  0.048090  0.001161 -0.061774  \n",
       "5031 -0.028628  0.010116 -0.002661  0.040237  0.023575  0.012390 -0.065933  \n",
       "5032 -0.045244  0.013065 -0.000260 -0.018512  0.005339  0.040650 -0.019662  \n",
       "5033 -0.023246  0.010574 -0.000123  0.009516 -0.019785 -0.003043 -0.040094  \n",
       "5034 -0.054164  0.028859  0.032703  0.011486  0.021293  0.029777 -0.018504  \n",
       "\n",
       "[5035 rows x 768 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df[\"label\"]\n",
    "\n",
    "emb_list_ = [np.asarray(s) for s in emb_list]\n",
    "df_emb_=pd.DataFrame(emb_list_)\n",
    "df_emb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d74beddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.054716</td>\n",
       "      <td>-0.045481</td>\n",
       "      <td>-0.023535</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>0.047523</td>\n",
       "      <td>-0.025077</td>\n",
       "      <td>-0.003400</td>\n",
       "      <td>-0.032581</td>\n",
       "      <td>-0.009139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010738</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>-0.068138</td>\n",
       "      <td>-0.055364</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>-0.006466</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>-0.048617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.028712</td>\n",
       "      <td>-0.043620</td>\n",
       "      <td>-0.051715</td>\n",
       "      <td>-0.027764</td>\n",
       "      <td>0.080676</td>\n",
       "      <td>-0.039356</td>\n",
       "      <td>-0.046797</td>\n",
       "      <td>0.057568</td>\n",
       "      <td>-0.024146</td>\n",
       "      <td>-0.034063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.058056</td>\n",
       "      <td>-0.054193</td>\n",
       "      <td>-0.101050</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>-0.029989</td>\n",
       "      <td>-0.019366</td>\n",
       "      <td>-0.080597</td>\n",
       "      <td>-0.002285</td>\n",
       "      <td>-0.030322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016238</td>\n",
       "      <td>-0.010530</td>\n",
       "      <td>0.011108</td>\n",
       "      <td>-0.004964</td>\n",
       "      <td>0.079042</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>-0.043167</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>-0.027746</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020584</td>\n",
       "      <td>0.043124</td>\n",
       "      <td>-0.041857</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>-0.021689</td>\n",
       "      <td>-0.022326</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>-0.060148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066568</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>-0.023566</td>\n",
       "      <td>-0.004859</td>\n",
       "      <td>0.039345</td>\n",
       "      <td>0.018339</td>\n",
       "      <td>-0.058902</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>-0.032561</td>\n",
       "      <td>-0.021920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002746</td>\n",
       "      <td>0.079601</td>\n",
       "      <td>-0.076817</td>\n",
       "      <td>-0.012250</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.024742</td>\n",
       "      <td>-0.002690</td>\n",
       "      <td>0.041313</td>\n",
       "      <td>0.074336</td>\n",
       "      <td>-0.044611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>-0.006678</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>0.065334</td>\n",
       "      <td>0.033174</td>\n",
       "      <td>-0.011546</td>\n",
       "      <td>0.049876</td>\n",
       "      <td>-0.026978</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018426</td>\n",
       "      <td>0.044450</td>\n",
       "      <td>-0.089290</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>0.091146</td>\n",
       "      <td>-0.035349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>-0.033637</td>\n",
       "      <td>-0.005506</td>\n",
       "      <td>0.038416</td>\n",
       "      <td>-0.018379</td>\n",
       "      <td>0.051197</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.017781</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>-0.037465</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>-0.067668</td>\n",
       "      <td>-0.011157</td>\n",
       "      <td>-0.031862</td>\n",
       "      <td>-0.024369</td>\n",
       "      <td>0.043494</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.051453</td>\n",
       "      <td>-0.036159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>-0.028547</td>\n",
       "      <td>-0.045570</td>\n",
       "      <td>-0.068305</td>\n",
       "      <td>-0.007125</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.057383</td>\n",
       "      <td>-0.019331</td>\n",
       "      <td>0.030423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014081</td>\n",
       "      <td>-0.007704</td>\n",
       "      <td>-0.040679</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.017199</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.029671</td>\n",
       "      <td>0.006060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>-0.025502</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>-0.003197</td>\n",
       "      <td>0.029201</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>-0.004197</td>\n",
       "      <td>-0.005269</td>\n",
       "      <td>0.046244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017122</td>\n",
       "      <td>-0.004484</td>\n",
       "      <td>-0.029274</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.028656</td>\n",
       "      <td>-0.014738</td>\n",
       "      <td>0.026732</td>\n",
       "      <td>0.028872</td>\n",
       "      <td>-0.014812</td>\n",
       "      <td>-0.007151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>-0.035723</td>\n",
       "      <td>0.011342</td>\n",
       "      <td>0.102803</td>\n",
       "      <td>-0.032850</td>\n",
       "      <td>-0.006633</td>\n",
       "      <td>-0.002737</td>\n",
       "      <td>-0.024466</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>-0.032806</td>\n",
       "      <td>0.058926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.057524</td>\n",
       "      <td>-0.003627</td>\n",
       "      <td>-0.007116</td>\n",
       "      <td>0.034572</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.015048</td>\n",
       "      <td>-0.005996</td>\n",
       "      <td>0.033237</td>\n",
       "      <td>-0.015909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.004340</td>\n",
       "      <td>-0.013808</td>\n",
       "      <td>0.025314</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.070841</td>\n",
       "      <td>-0.014354</td>\n",
       "      <td>-0.048107</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>-0.038268</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>-0.052095</td>\n",
       "      <td>-0.029709</td>\n",
       "      <td>0.023515</td>\n",
       "      <td>-0.012521</td>\n",
       "      <td>0.030994</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.052297</td>\n",
       "      <td>-0.054560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -0.054716 -0.045481 -0.023535 -0.000155 -0.006323  0.047523 -0.025077   \n",
       "1   -0.028712 -0.043620 -0.051715 -0.027764  0.080676 -0.039356 -0.046797   \n",
       "2   -0.016238 -0.010530  0.011108 -0.004964  0.079042  0.044689 -0.043167   \n",
       "3    0.066568  0.027526 -0.023566 -0.004859  0.039345  0.018339 -0.058902   \n",
       "4    0.019350  0.001813 -0.006678 -0.002628  0.065334  0.033174 -0.011546   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "799 -0.033637 -0.005506  0.038416 -0.018379  0.051197  0.009491 -0.017781   \n",
       "800 -0.028547 -0.045570 -0.068305 -0.007125  0.030637  0.000143  0.019804   \n",
       "801 -0.025502 -0.001768  0.025397  0.016272 -0.003197  0.029201  0.000391   \n",
       "802 -0.035723  0.011342  0.102803 -0.032850 -0.006633 -0.002737 -0.024466   \n",
       "803  0.004340 -0.013808  0.025314  0.002490  0.070841 -0.014354 -0.048107   \n",
       "\n",
       "          7         8         9    ...       758       759       760  \\\n",
       "0   -0.003400 -0.032581 -0.009139  ... -0.010738  0.006308 -0.068138   \n",
       "1    0.057568 -0.024146 -0.034063  ...  0.023295  0.058056 -0.054193   \n",
       "2   -0.001452 -0.027746  0.011876  ... -0.020584  0.043124 -0.041857   \n",
       "3    0.016316 -0.032561 -0.021920  ... -0.002746  0.079601 -0.076817   \n",
       "4    0.049876 -0.026978 -0.001274  ... -0.018426  0.044450 -0.089290   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "799  0.052079 -0.037465 -0.013878  ...  0.016810  0.075761 -0.067668   \n",
       "800  0.057383 -0.019331  0.030423  ... -0.014081 -0.007704 -0.040679   \n",
       "801 -0.004197 -0.005269  0.046244  ... -0.017122 -0.004484 -0.029274   \n",
       "802  0.003412 -0.032806  0.058926  ...  0.002785  0.057524 -0.003627   \n",
       "803  0.021246 -0.038268  0.000188  ... -0.001595  0.052417 -0.052095   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0   -0.055364  0.028434 -0.015068 -0.015639 -0.006466  0.031062 -0.048617  \n",
       "1   -0.101050  0.006665 -0.029989 -0.019366 -0.080597 -0.002285 -0.030322  \n",
       "2    0.006142 -0.021689 -0.022326  0.004118  0.018608  0.052731 -0.060148  \n",
       "3   -0.012250  0.004977  0.024742 -0.002690  0.041313  0.074336 -0.044611  \n",
       "4    0.004893  0.029819 -0.006972  0.000377 -0.013762  0.091146 -0.035349  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "799 -0.011157 -0.031862 -0.024369  0.043494  0.009058  0.051453 -0.036159  \n",
       "800  0.018558  0.017199  0.000757  0.007542  0.022014  0.029671  0.006060  \n",
       "801 -0.000227 -0.028656 -0.014738  0.026732  0.028872 -0.014812 -0.007151  \n",
       "802 -0.007116  0.034572  0.005385  0.015048 -0.005996  0.033237 -0.015909  \n",
       "803 -0.029709  0.023515 -0.012521  0.030994  0.008346  0.052297 -0.054560  \n",
       "\n",
       "[804 rows x 768 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test=test_data['label_test']\n",
    "\n",
    "emb_list_test_ = [np.asarray(s) for s in emb_list_test]\n",
    "df_emb_test_=pd.DataFrame(emb_list_test_)\n",
    "df_emb_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c12f6c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76264768, 1.45184544])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40870bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight={0: 0.7626476825204483,\n",
       "                                         1: 1.4518454440599768},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [10], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight={0: 0.7626476825204483,\n",
       "                                         1: 1.4518454440599768},\n",
       "                           probability=True),\n",
       "             param_grid={&#x27;C&#x27;: [10], &#x27;gamma&#x27;: [1], &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7626476825204483, 1: 1.4518454440599768},\n",
       "    probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.7626476825204483, 1: 1.4518454440599768},\n",
       "    probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=SVC(class_weight={0: 0.7626476825204483,\n",
       "                                         1: 1.4518454440599768},\n",
       "                           probability=True),\n",
       "             param_grid={'C': [10], 'gamma': [1], 'kernel': ['rbf']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameteres = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "clf = GridSearchCV(SVC(class_weight={0:class_weight[0], 1:class_weight[1]}, probability=True), param_grid=parameteres , cv=5, scoring='f1_macro')\n",
    "clf.fit(df_emb_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(clf.best_params_))\n",
    "print(\"CV score=%0.3f\" % clf.best_score_)\n",
    "cv_results = clf.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ce5d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=clf.predict_proba(df_emb_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "for res in y_predict:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b40ae6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.83361921 0.7918552 ], recall: [0.91353383 0.64338235], f1score: [0.87174888 0.70993915]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(labels_test, test_data_predict['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "154707f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8127372072988055, recall: 0.7784580937638214, f1score_macro: 0.7908440134983945\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(labels_test, test_data_predict['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d54aa",
   "metadata": {},
   "source": [
    "# Logit Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90e556d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('LogitBoost', LogitBoost())]\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps) # define the pipeline object.\n",
    "\n",
    "parameteres = {'LogitBoost__n_estimators':range(10,100,10)}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c981cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())]),\n",
       "             param_grid={&#x27;LogitBoost__n_estimators&#x27;: range(10, 100, 10)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;LogitBoost&#x27;, LogitBoost())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogitBoost</label><div class=\"sk-toggleable__content\"><pre>LogitBoost()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('LogitBoost', LogitBoost())]),\n",
       "             param_grid={'LogitBoost__n_estimators': range(10, 100, 10)})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_emb_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters from gridsearch: {}\".format(grid.best_params_))\n",
    "print(\"CV score=%0.3f\" % grid.best_score_)\n",
    "cv_results = grid.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ea5a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict_proba(df_emb_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5787bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.82068966 0.75      ], recall: [0.89473684 0.61764706], f1score: [0.85611511 0.67741935]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(test_data.label_test, test_data['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f7ccb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7853448275862069, recall: 0.7561919504643964, f1score_macro: 0.7667672313761894\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(labels_test, test_data_predict['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791af1a",
   "metadata": {},
   "source": [
    "# Logit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88134a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': np.linspace(0.0001, 10, 50), \"penalty\":[\"l1\",\"l2\"]}  #high C means \"Trust this training data a lot\", while a low value says \"This data may not be fully representative of the real world data, so if it's telling you to make a parameter really large, don't listen to it\"\n",
    "grid_search = GridSearchCV(LogisticRegression(class_weight={0:class_weight[0], 1:class_weight[1]}), parameters, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(df_emb_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14da1726",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict_proba(df_emb_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions0=[]\n",
    "predictions1=[]\n",
    "\n",
    "\n",
    "for res in y_pred:\n",
    "    predictions0.append(res[0])\n",
    "    predictions1.append(res[1])\n",
    "\n",
    "    \n",
    "test_data['predict_0']=predictions0\n",
    "test_data['predict_1']=predictions1\n",
    "\n",
    "test_data_predict=TestCutoff(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "354d900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.85514834 0.81818182], recall: [0.92105263 0.69485294], f1score: [0.88687783 0.75149105]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(labels_test, test_data_predict['predict'])[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "221a8fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8366650801205775, recall: 0.807952786377709, f1score_macro: 0.8191844408661155\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1score = precision_recall_fscore_support(labels_test, test_data_predict['predict'], average='macro')[:3]\n",
    "\n",
    "print(f'precision: {precision}, recall: {recall}, f1score_macro: {f1score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
